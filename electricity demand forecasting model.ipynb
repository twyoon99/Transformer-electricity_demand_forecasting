{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoaPVxKXehBD"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "import gdown\n",
        "import os\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4YCnILfen1a",
        "outputId": "60e2464e-48b9-48df-aa5b-588e63b6b69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/mx5nabcd/ai_project_2_final/raw/main/train_en.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv8uuh7Keoq1",
        "outputId": "264616d6-033d-442e-956c-0f18ce937b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-25 06:55:02--  https://github.com/mx5nabcd/ai_project_2_final/raw/main/train_en.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mx5nabcd/ai_project_2_final/main/train_en.csv [following]\n",
            "--2023-12-25 06:55:02--  https://raw.githubusercontent.com/mx5nabcd/ai_project_2_final/main/train_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5707494 (5.4M) [text/plain]\n",
            "Saving to: ‘train_en.csv’\n",
            "\n",
            "train_en.csv        100%[===================>]   5.44M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-12-25 06:55:03 (69.3 MB/s) - ‘train_en.csv’ saved [5707494/5707494]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 전처리"
      ],
      "metadata": {
        "id": "p0yQMz-OR80l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/train_en.csv', encoding='cp949')"
      ],
      "metadata": {
        "id": "HcpzNDrSjyHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['num'] = data['num'].astype('float64')\n",
        "\n",
        "data['date_time'] = pd.to_datetime(data['date_time'])\n",
        "\n",
        "data['month'] = data['date_time'].dt.month.astype('float64') #월\n",
        "data['day'] = data['date_time'].dt.day.astype('float64') #일\n",
        "data['hour'] = data['date_time'].dt.hour.astype('float64') #시간\n",
        "\n",
        "data['week'] = data['date_time'].dt.weekday #요일 0,1,2,3,4,5,6 -> 월,화,수,목,금,토,일\n",
        "# data['dayofyear'] = data['date_time'].dt.dayofyear.astype('float64')\n",
        "\n",
        "data.drop(columns=['date_time'], inplace=True)"
      ],
      "metadata": {
        "id": "HXwE_rX2Zogs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weekend열은 월화수목금이면 0, 토일이면 1임\n",
        "data.loc[(data['week']==0)|(data['week']==1)|(data['week']==2)|(data['week']==3)|(data['week']==4), 'weekend'] = 0\n",
        "data.loc[(data['week']==5)|(data['week']==6), 'weekend'] = 1"
      ],
      "metadata": {
        "id": "18a82JmTNjBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['non_elect_cool_sys'] = data['non_elect_cool_sys'].astype('float64') #비전기냉방시설 유무\n",
        "data['solar_pannel'] = data['solar_pannel'].astype('float64') # 태양광 패널 유무\n",
        "data['weekend'] = data['weekend'].astype('float64')\n",
        "data['week'] = data['week'].astype('float64')"
      ],
      "metadata": {
        "id": "xIMNZ-pnaoSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "4SG34kpZOUuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87f136a-6a1c-47f7-f63c-ae7dd03c17d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 122400 entries, 0 to 122399\n",
            "Data columns (total 14 columns):\n",
            " #   Column              Non-Null Count   Dtype  \n",
            "---  ------              --------------   -----  \n",
            " 0   num                 122400 non-null  float64\n",
            " 1   power(kWh)          122400 non-null  float64\n",
            " 2   temp(°C)            122400 non-null  float64\n",
            " 3   wind(m/s)           122400 non-null  float64\n",
            " 4   humidity(%)         122400 non-null  float64\n",
            " 5   rain(mm)            122400 non-null  float64\n",
            " 6   sunshine(hr)        122400 non-null  float64\n",
            " 7   non_elect_cool_sys  122400 non-null  float64\n",
            " 8   solar_pannel        122400 non-null  float64\n",
            " 9   month               122400 non-null  float64\n",
            " 10  day                 122400 non-null  float64\n",
            " 11  hour                122400 non-null  float64\n",
            " 12  week                122400 non-null  float64\n",
            " 13  weekend             122400 non-null  float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 13.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "U4YmoGT7OVvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7712f0f8-e2b6-4128-ab7a-710f05a18738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "num                   0\n",
              "power(kWh)            0\n",
              "temp(°C)              0\n",
              "wind(m/s)             0\n",
              "humidity(%)           0\n",
              "rain(mm)              0\n",
              "sunshine(hr)          0\n",
              "non_elect_cool_sys    0\n",
              "solar_pannel          0\n",
              "month                 0\n",
              "day                   0\n",
              "hour                  0\n",
              "week                  0\n",
              "weekend               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "nIVh2UV5lvcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b9d932-7311-4e71-d191-4da008ac6c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['num', 'power(kWh)', 'temp(°C)', 'wind(m/s)', 'humidity(%)', 'rain(mm)',\n",
              "       'sunshine(hr)', 'non_elect_cool_sys', 'solar_pannel', 'month', 'day',\n",
              "       'hour', 'week', 'weekend'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[['power(kWh)', 'num', 'temp(°C)', 'wind(m/s)', 'humidity(%)', 'rain(mm)',\n",
        "       'sunshine(hr)', 'non_elect_cool_sys', 'solar_pannel', 'month', 'day',\n",
        "       'hour','week','weekend']]"
      ],
      "metadata": {
        "id": "7WJ1XV7_ly1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "P8rRleTFqgPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8aaa878-8aff-4c81-9354-e372ead2f6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['power(kWh)', 'num', 'temp(°C)', 'wind(m/s)', 'humidity(%)', 'rain(mm)',\n",
              "       'sunshine(hr)', 'non_elect_cool_sys', 'solar_pannel', 'month', 'day',\n",
              "       'hour', 'week', 'weekend'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=['rain(mm)'], inplace=True) #강수량 필요없어보여서 삭제\n",
        "data.drop(columns=['sunshine(hr)'], inplace=True) #일조량 필요없어서 삭제"
      ],
      "metadata": {
        "id": "2p6tXI5zmFFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = data['num']"
      ],
      "metadata": {
        "id": "LFiLDZjxtKV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "3oi2HK3xaevy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns={'num':'Znum'}, inplace=True)"
      ],
      "metadata": {
        "id": "bhCGR5fEugs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "hTArm_Y1r0Cx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0f30bd06-b539-498f-939c-4f12655ff5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        power(kWh)  Znum  temp(°C)  wind(m/s)  humidity(%)  \\\n",
              "0         8179.056   1.0      17.6        2.5         92.0   \n",
              "1         8135.640   1.0      17.7        2.9         91.0   \n",
              "2         8107.128   1.0      17.5        3.2         91.0   \n",
              "3         8048.808   1.0      17.1        3.2         91.0   \n",
              "4         8043.624   1.0      17.0        3.3         92.0   \n",
              "...            ...   ...       ...        ...          ...   \n",
              "122395    4114.368  60.0      27.8        2.3         68.0   \n",
              "122396    3975.696  60.0      27.3        1.2         71.0   \n",
              "122397    3572.208  60.0      27.3        1.8         71.0   \n",
              "122398    3299.184  60.0      27.1        1.8         74.0   \n",
              "122399    3204.576  60.0      27.1        2.6         75.0   \n",
              "\n",
              "        non_elect_cool_sys  solar_pannel  month   day  hour  week  weekend  \n",
              "0                      0.0           0.0    6.0   1.0   0.0   0.0      0.0  \n",
              "1                      0.0           0.0    6.0   1.0   1.0   0.0      0.0  \n",
              "2                      0.0           0.0    6.0   1.0   2.0   0.0      0.0  \n",
              "3                      0.0           0.0    6.0   1.0   3.0   0.0      0.0  \n",
              "4                      0.0           0.0    6.0   1.0   4.0   0.0      0.0  \n",
              "...                    ...           ...    ...   ...   ...   ...      ...  \n",
              "122395                 1.0           1.0    8.0  24.0  19.0   0.0      0.0  \n",
              "122396                 1.0           1.0    8.0  24.0  20.0   0.0      0.0  \n",
              "122397                 1.0           1.0    8.0  24.0  21.0   0.0      0.0  \n",
              "122398                 1.0           1.0    8.0  24.0  22.0   0.0      0.0  \n",
              "122399                 1.0           1.0    8.0  24.0  23.0   0.0      0.0  \n",
              "\n",
              "[122400 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37f3d40d-0d63-445c-99b7-d67b20c12830\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>power(kWh)</th>\n",
              "      <th>Znum</th>\n",
              "      <th>temp(°C)</th>\n",
              "      <th>wind(m/s)</th>\n",
              "      <th>humidity(%)</th>\n",
              "      <th>non_elect_cool_sys</th>\n",
              "      <th>solar_pannel</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>week</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8179.056</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>2.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8135.640</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8107.128</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8048.808</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8043.624</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122395</th>\n",
              "      <td>4114.368</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.8</td>\n",
              "      <td>2.3</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122396</th>\n",
              "      <td>3975.696</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122397</th>\n",
              "      <td>3572.208</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122398</th>\n",
              "      <td>3299.184</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122399</th>\n",
              "      <td>3204.576</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>122400 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37f3d40d-0d63-445c-99b7-d67b20c12830')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37f3d40d-0d63-445c-99b7-d67b20c12830 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37f3d40d-0d63-445c-99b7-d67b20c12830');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6e3e5c0e-59f5-4aa3-8319-8a4595b81d98\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e3e5c0e-59f5-4aa3-8319-8a4595b81d98')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6e3e5c0e-59f5-4aa3-8319-8a4595b81d98 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d203df04-32ed-444f-b40c-c8ccf1bcf5b1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d203df04-32ed-444f-b40c-c8ccf1bcf5b1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([num, data], axis=1)"
      ],
      "metadata": {
        "id": "ssUXi6Q-uG0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "WBpLjHpVuP8p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4febb7b4-d773-418c-a1c4-e93daa1f4e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         num  power(kWh)  Znum  temp(°C)  wind(m/s)  humidity(%)  \\\n",
              "0        1.0    8179.056   1.0      17.6        2.5         92.0   \n",
              "1        1.0    8135.640   1.0      17.7        2.9         91.0   \n",
              "2        1.0    8107.128   1.0      17.5        3.2         91.0   \n",
              "3        1.0    8048.808   1.0      17.1        3.2         91.0   \n",
              "4        1.0    8043.624   1.0      17.0        3.3         92.0   \n",
              "...      ...         ...   ...       ...        ...          ...   \n",
              "122395  60.0    4114.368  60.0      27.8        2.3         68.0   \n",
              "122396  60.0    3975.696  60.0      27.3        1.2         71.0   \n",
              "122397  60.0    3572.208  60.0      27.3        1.8         71.0   \n",
              "122398  60.0    3299.184  60.0      27.1        1.8         74.0   \n",
              "122399  60.0    3204.576  60.0      27.1        2.6         75.0   \n",
              "\n",
              "        non_elect_cool_sys  solar_pannel  month   day  hour  week  weekend  \n",
              "0                      0.0           0.0    6.0   1.0   0.0   0.0      0.0  \n",
              "1                      0.0           0.0    6.0   1.0   1.0   0.0      0.0  \n",
              "2                      0.0           0.0    6.0   1.0   2.0   0.0      0.0  \n",
              "3                      0.0           0.0    6.0   1.0   3.0   0.0      0.0  \n",
              "4                      0.0           0.0    6.0   1.0   4.0   0.0      0.0  \n",
              "...                    ...           ...    ...   ...   ...   ...      ...  \n",
              "122395                 1.0           1.0    8.0  24.0  19.0   0.0      0.0  \n",
              "122396                 1.0           1.0    8.0  24.0  20.0   0.0      0.0  \n",
              "122397                 1.0           1.0    8.0  24.0  21.0   0.0      0.0  \n",
              "122398                 1.0           1.0    8.0  24.0  22.0   0.0      0.0  \n",
              "122399                 1.0           1.0    8.0  24.0  23.0   0.0      0.0  \n",
              "\n",
              "[122400 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b52147a3-629c-497f-bb9a-118a9e111571\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>power(kWh)</th>\n",
              "      <th>Znum</th>\n",
              "      <th>temp(°C)</th>\n",
              "      <th>wind(m/s)</th>\n",
              "      <th>humidity(%)</th>\n",
              "      <th>non_elect_cool_sys</th>\n",
              "      <th>solar_pannel</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>week</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8179.056</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>2.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8135.640</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8107.128</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8048.808</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8043.624</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122395</th>\n",
              "      <td>60.0</td>\n",
              "      <td>4114.368</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.8</td>\n",
              "      <td>2.3</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122396</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3975.696</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122397</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3572.208</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122398</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3299.184</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122399</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3204.576</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>122400 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b52147a3-629c-497f-bb9a-118a9e111571')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b52147a3-629c-497f-bb9a-118a9e111571 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b52147a3-629c-497f-bb9a-118a9e111571');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b302b935-3d42-4f9b-b667-81add750729f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b302b935-3d42-4f9b-b667-81add750729f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b302b935-3d42-4f9b-b667-81add750729f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e0c46fab-2858-4f33-9ba8-034cda16fed8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e0c46fab-2858-4f33-9ba8-034cda16fed8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVV4dPt2h90H",
        "outputId": "1e5ed0db-346f-4ed3-86ed-8b64b6e9a81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['num', 'power(kWh)', 'Znum', 'temp(°C)', 'wind(m/s)', 'humidity(%)',\n",
              "       'non_elect_cool_sys', 'solar_pannel', 'month', 'day', 'hour', 'week',\n",
              "       'weekend'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asd = pd.DataFrame(np.zeros((5100,12)))"
      ],
      "metadata": {
        "id": "CtLiTsj9ihig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asd.columns = ['num','power(kWh)', 'Znum', 'temp(°C)', 'wind(m/s)', 'humidity(%)',\n",
        "       'non_elect_cool_sys', 'solar_pannel', 'month', 'day', 'week',\n",
        "       'weekend']"
      ],
      "metadata": {
        "id": "kFpLhubzjb__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asd # 원래 data는 1시간씩 데이터인데 24시간을 평균내서 1일씩 데이터로 만들어주기위해\n",
        "#먼저 빈 데이터프레임을 만듬 원래는 122400개인데 24로 나누면 5100개"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "k8LoupPxiuxX",
        "outputId": "9cc6bef6-4903-45fb-c032-2087c5128f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      num  power(kWh)  Znum  temp(°C)  wind(m/s)  humidity(%)  \\\n",
              "0     0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "1     0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "2     0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "3     0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "4     0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "...   ...         ...   ...       ...        ...          ...   \n",
              "5095  0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "5096  0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "5097  0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "5098  0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "5099  0.0         0.0   0.0       0.0        0.0          0.0   \n",
              "\n",
              "      non_elect_cool_sys  solar_pannel  month  day  week  weekend  \n",
              "0                    0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "1                    0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "2                    0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "3                    0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "4                    0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "...                  ...           ...    ...  ...   ...      ...  \n",
              "5095                 0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "5096                 0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "5097                 0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "5098                 0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "5099                 0.0           0.0    0.0  0.0   0.0      0.0  \n",
              "\n",
              "[5100 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52b24c7e-afd2-4e07-b03b-6b252736e6ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>power(kWh)</th>\n",
              "      <th>Znum</th>\n",
              "      <th>temp(°C)</th>\n",
              "      <th>wind(m/s)</th>\n",
              "      <th>humidity(%)</th>\n",
              "      <th>non_elect_cool_sys</th>\n",
              "      <th>solar_pannel</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>week</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5100 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52b24c7e-afd2-4e07-b03b-6b252736e6ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52b24c7e-afd2-4e07-b03b-6b252736e6ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52b24c7e-afd2-4e07-b03b-6b252736e6ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e62614a-8221-433b-be43-6fa20532ae00\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e62614a-8221-433b-be43-6fa20532ae00')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e62614a-8221-433b-be43-6fa20532ae00 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e9a54d7c-8a7a-49a1-90a7-39fe53760c60\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('asd')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e9a54d7c-8a7a-49a1-90a7-39fe53760c60 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('asd');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#온도, 풍속, 습도만 평균을 내주고 나머지 feature는 평균 안내도 되기 때문에 24시간 평균내준 것들과 잘 붙여줌\n",
        "i1=0\n",
        "i2=24\n",
        "for i in range(5100):\n",
        "  asd['num'][i] = data['num'][i1]\n",
        "  asd['power(kWh)'][i] = data['power(kWh)'][i1]\n",
        "  asd['Znum'][i] = data['Znum'][i1]\n",
        "  asd['temp(°C)'][i] = data[i1:i2]['temp(°C)'].mean()\n",
        "  asd['wind(m/s)'][i] = data[i1:i2]['wind(m/s)'].mean()\n",
        "  asd['humidity(%)'][i] = data[i1:i2]['humidity(%)'].mean()\n",
        "  asd['non_elect_cool_sys'][i] = data['non_elect_cool_sys'][i1]\n",
        "  asd['solar_pannel'][i] = data['solar_pannel'][i1]\n",
        "  asd['month'][i] = data['month'][i1]\n",
        "  asd['day'][i] = data['day'][i1]\n",
        "  asd['week'][i] = data['week'][i1]\n",
        "  asd['weekend'][i] = data['weekend'][i1]\n",
        "  i1 += 24\n",
        "  i2 += 24\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJufOnTTjsX_",
        "outputId": "7e9d3b95-d926-4543-a70c-de6949be042e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n",
            "1293\n",
            "1294\n",
            "1295\n",
            "1296\n",
            "1297\n",
            "1298\n",
            "1299\n",
            "1300\n",
            "1301\n",
            "1302\n",
            "1303\n",
            "1304\n",
            "1305\n",
            "1306\n",
            "1307\n",
            "1308\n",
            "1309\n",
            "1310\n",
            "1311\n",
            "1312\n",
            "1313\n",
            "1314\n",
            "1315\n",
            "1316\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1320\n",
            "1321\n",
            "1322\n",
            "1323\n",
            "1324\n",
            "1325\n",
            "1326\n",
            "1327\n",
            "1328\n",
            "1329\n",
            "1330\n",
            "1331\n",
            "1332\n",
            "1333\n",
            "1334\n",
            "1335\n",
            "1336\n",
            "1337\n",
            "1338\n",
            "1339\n",
            "1340\n",
            "1341\n",
            "1342\n",
            "1343\n",
            "1344\n",
            "1345\n",
            "1346\n",
            "1347\n",
            "1348\n",
            "1349\n",
            "1350\n",
            "1351\n",
            "1352\n",
            "1353\n",
            "1354\n",
            "1355\n",
            "1356\n",
            "1357\n",
            "1358\n",
            "1359\n",
            "1360\n",
            "1361\n",
            "1362\n",
            "1363\n",
            "1364\n",
            "1365\n",
            "1366\n",
            "1367\n",
            "1368\n",
            "1369\n",
            "1370\n",
            "1371\n",
            "1372\n",
            "1373\n",
            "1374\n",
            "1375\n",
            "1376\n",
            "1377\n",
            "1378\n",
            "1379\n",
            "1380\n",
            "1381\n",
            "1382\n",
            "1383\n",
            "1384\n",
            "1385\n",
            "1386\n",
            "1387\n",
            "1388\n",
            "1389\n",
            "1390\n",
            "1391\n",
            "1392\n",
            "1393\n",
            "1394\n",
            "1395\n",
            "1396\n",
            "1397\n",
            "1398\n",
            "1399\n",
            "1400\n",
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n",
            "1441\n",
            "1442\n",
            "1443\n",
            "1444\n",
            "1445\n",
            "1446\n",
            "1447\n",
            "1448\n",
            "1449\n",
            "1450\n",
            "1451\n",
            "1452\n",
            "1453\n",
            "1454\n",
            "1455\n",
            "1456\n",
            "1457\n",
            "1458\n",
            "1459\n",
            "1460\n",
            "1461\n",
            "1462\n",
            "1463\n",
            "1464\n",
            "1465\n",
            "1466\n",
            "1467\n",
            "1468\n",
            "1469\n",
            "1470\n",
            "1471\n",
            "1472\n",
            "1473\n",
            "1474\n",
            "1475\n",
            "1476\n",
            "1477\n",
            "1478\n",
            "1479\n",
            "1480\n",
            "1481\n",
            "1482\n",
            "1483\n",
            "1484\n",
            "1485\n",
            "1486\n",
            "1487\n",
            "1488\n",
            "1489\n",
            "1490\n",
            "1491\n",
            "1492\n",
            "1493\n",
            "1494\n",
            "1495\n",
            "1496\n",
            "1497\n",
            "1498\n",
            "1499\n",
            "1500\n",
            "1501\n",
            "1502\n",
            "1503\n",
            "1504\n",
            "1505\n",
            "1506\n",
            "1507\n",
            "1508\n",
            "1509\n",
            "1510\n",
            "1511\n",
            "1512\n",
            "1513\n",
            "1514\n",
            "1515\n",
            "1516\n",
            "1517\n",
            "1518\n",
            "1519\n",
            "1520\n",
            "1521\n",
            "1522\n",
            "1523\n",
            "1524\n",
            "1525\n",
            "1526\n",
            "1527\n",
            "1528\n",
            "1529\n",
            "1530\n",
            "1531\n",
            "1532\n",
            "1533\n",
            "1534\n",
            "1535\n",
            "1536\n",
            "1537\n",
            "1538\n",
            "1539\n",
            "1540\n",
            "1541\n",
            "1542\n",
            "1543\n",
            "1544\n",
            "1545\n",
            "1546\n",
            "1547\n",
            "1548\n",
            "1549\n",
            "1550\n",
            "1551\n",
            "1552\n",
            "1553\n",
            "1554\n",
            "1555\n",
            "1556\n",
            "1557\n",
            "1558\n",
            "1559\n",
            "1560\n",
            "1561\n",
            "1562\n",
            "1563\n",
            "1564\n",
            "1565\n",
            "1566\n",
            "1567\n",
            "1568\n",
            "1569\n",
            "1570\n",
            "1571\n",
            "1572\n",
            "1573\n",
            "1574\n",
            "1575\n",
            "1576\n",
            "1577\n",
            "1578\n",
            "1579\n",
            "1580\n",
            "1581\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1585\n",
            "1586\n",
            "1587\n",
            "1588\n",
            "1589\n",
            "1590\n",
            "1591\n",
            "1592\n",
            "1593\n",
            "1594\n",
            "1595\n",
            "1596\n",
            "1597\n",
            "1598\n",
            "1599\n",
            "1600\n",
            "1601\n",
            "1602\n",
            "1603\n",
            "1604\n",
            "1605\n",
            "1606\n",
            "1607\n",
            "1608\n",
            "1609\n",
            "1610\n",
            "1611\n",
            "1612\n",
            "1613\n",
            "1614\n",
            "1615\n",
            "1616\n",
            "1617\n",
            "1618\n",
            "1619\n",
            "1620\n",
            "1621\n",
            "1622\n",
            "1623\n",
            "1624\n",
            "1625\n",
            "1626\n",
            "1627\n",
            "1628\n",
            "1629\n",
            "1630\n",
            "1631\n",
            "1632\n",
            "1633\n",
            "1634\n",
            "1635\n",
            "1636\n",
            "1637\n",
            "1638\n",
            "1639\n",
            "1640\n",
            "1641\n",
            "1642\n",
            "1643\n",
            "1644\n",
            "1645\n",
            "1646\n",
            "1647\n",
            "1648\n",
            "1649\n",
            "1650\n",
            "1651\n",
            "1652\n",
            "1653\n",
            "1654\n",
            "1655\n",
            "1656\n",
            "1657\n",
            "1658\n",
            "1659\n",
            "1660\n",
            "1661\n",
            "1662\n",
            "1663\n",
            "1664\n",
            "1665\n",
            "1666\n",
            "1667\n",
            "1668\n",
            "1669\n",
            "1670\n",
            "1671\n",
            "1672\n",
            "1673\n",
            "1674\n",
            "1675\n",
            "1676\n",
            "1677\n",
            "1678\n",
            "1679\n",
            "1680\n",
            "1681\n",
            "1682\n",
            "1683\n",
            "1684\n",
            "1685\n",
            "1686\n",
            "1687\n",
            "1688\n",
            "1689\n",
            "1690\n",
            "1691\n",
            "1692\n",
            "1693\n",
            "1694\n",
            "1695\n",
            "1696\n",
            "1697\n",
            "1698\n",
            "1699\n",
            "1700\n",
            "1701\n",
            "1702\n",
            "1703\n",
            "1704\n",
            "1705\n",
            "1706\n",
            "1707\n",
            "1708\n",
            "1709\n",
            "1710\n",
            "1711\n",
            "1712\n",
            "1713\n",
            "1714\n",
            "1715\n",
            "1716\n",
            "1717\n",
            "1718\n",
            "1719\n",
            "1720\n",
            "1721\n",
            "1722\n",
            "1723\n",
            "1724\n",
            "1725\n",
            "1726\n",
            "1727\n",
            "1728\n",
            "1729\n",
            "1730\n",
            "1731\n",
            "1732\n",
            "1733\n",
            "1734\n",
            "1735\n",
            "1736\n",
            "1737\n",
            "1738\n",
            "1739\n",
            "1740\n",
            "1741\n",
            "1742\n",
            "1743\n",
            "1744\n",
            "1745\n",
            "1746\n",
            "1747\n",
            "1748\n",
            "1749\n",
            "1750\n",
            "1751\n",
            "1752\n",
            "1753\n",
            "1754\n",
            "1755\n",
            "1756\n",
            "1757\n",
            "1758\n",
            "1759\n",
            "1760\n",
            "1761\n",
            "1762\n",
            "1763\n",
            "1764\n",
            "1765\n",
            "1766\n",
            "1767\n",
            "1768\n",
            "1769\n",
            "1770\n",
            "1771\n",
            "1772\n",
            "1773\n",
            "1774\n",
            "1775\n",
            "1776\n",
            "1777\n",
            "1778\n",
            "1779\n",
            "1780\n",
            "1781\n",
            "1782\n",
            "1783\n",
            "1784\n",
            "1785\n",
            "1786\n",
            "1787\n",
            "1788\n",
            "1789\n",
            "1790\n",
            "1791\n",
            "1792\n",
            "1793\n",
            "1794\n",
            "1795\n",
            "1796\n",
            "1797\n",
            "1798\n",
            "1799\n",
            "1800\n",
            "1801\n",
            "1802\n",
            "1803\n",
            "1804\n",
            "1805\n",
            "1806\n",
            "1807\n",
            "1808\n",
            "1809\n",
            "1810\n",
            "1811\n",
            "1812\n",
            "1813\n",
            "1814\n",
            "1815\n",
            "1816\n",
            "1817\n",
            "1818\n",
            "1819\n",
            "1820\n",
            "1821\n",
            "1822\n",
            "1823\n",
            "1824\n",
            "1825\n",
            "1826\n",
            "1827\n",
            "1828\n",
            "1829\n",
            "1830\n",
            "1831\n",
            "1832\n",
            "1833\n",
            "1834\n",
            "1835\n",
            "1836\n",
            "1837\n",
            "1838\n",
            "1839\n",
            "1840\n",
            "1841\n",
            "1842\n",
            "1843\n",
            "1844\n",
            "1845\n",
            "1846\n",
            "1847\n",
            "1848\n",
            "1849\n",
            "1850\n",
            "1851\n",
            "1852\n",
            "1853\n",
            "1854\n",
            "1855\n",
            "1856\n",
            "1857\n",
            "1858\n",
            "1859\n",
            "1860\n",
            "1861\n",
            "1862\n",
            "1863\n",
            "1864\n",
            "1865\n",
            "1866\n",
            "1867\n",
            "1868\n",
            "1869\n",
            "1870\n",
            "1871\n",
            "1872\n",
            "1873\n",
            "1874\n",
            "1875\n",
            "1876\n",
            "1877\n",
            "1878\n",
            "1879\n",
            "1880\n",
            "1881\n",
            "1882\n",
            "1883\n",
            "1884\n",
            "1885\n",
            "1886\n",
            "1887\n",
            "1888\n",
            "1889\n",
            "1890\n",
            "1891\n",
            "1892\n",
            "1893\n",
            "1894\n",
            "1895\n",
            "1896\n",
            "1897\n",
            "1898\n",
            "1899\n",
            "1900\n",
            "1901\n",
            "1902\n",
            "1903\n",
            "1904\n",
            "1905\n",
            "1906\n",
            "1907\n",
            "1908\n",
            "1909\n",
            "1910\n",
            "1911\n",
            "1912\n",
            "1913\n",
            "1914\n",
            "1915\n",
            "1916\n",
            "1917\n",
            "1918\n",
            "1919\n",
            "1920\n",
            "1921\n",
            "1922\n",
            "1923\n",
            "1924\n",
            "1925\n",
            "1926\n",
            "1927\n",
            "1928\n",
            "1929\n",
            "1930\n",
            "1931\n",
            "1932\n",
            "1933\n",
            "1934\n",
            "1935\n",
            "1936\n",
            "1937\n",
            "1938\n",
            "1939\n",
            "1940\n",
            "1941\n",
            "1942\n",
            "1943\n",
            "1944\n",
            "1945\n",
            "1946\n",
            "1947\n",
            "1948\n",
            "1949\n",
            "1950\n",
            "1951\n",
            "1952\n",
            "1953\n",
            "1954\n",
            "1955\n",
            "1956\n",
            "1957\n",
            "1958\n",
            "1959\n",
            "1960\n",
            "1961\n",
            "1962\n",
            "1963\n",
            "1964\n",
            "1965\n",
            "1966\n",
            "1967\n",
            "1968\n",
            "1969\n",
            "1970\n",
            "1971\n",
            "1972\n",
            "1973\n",
            "1974\n",
            "1975\n",
            "1976\n",
            "1977\n",
            "1978\n",
            "1979\n",
            "1980\n",
            "1981\n",
            "1982\n",
            "1983\n",
            "1984\n",
            "1985\n",
            "1986\n",
            "1987\n",
            "1988\n",
            "1989\n",
            "1990\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "2021\n",
            "2022\n",
            "2023\n",
            "2024\n",
            "2025\n",
            "2026\n",
            "2027\n",
            "2028\n",
            "2029\n",
            "2030\n",
            "2031\n",
            "2032\n",
            "2033\n",
            "2034\n",
            "2035\n",
            "2036\n",
            "2037\n",
            "2038\n",
            "2039\n",
            "2040\n",
            "2041\n",
            "2042\n",
            "2043\n",
            "2044\n",
            "2045\n",
            "2046\n",
            "2047\n",
            "2048\n",
            "2049\n",
            "2050\n",
            "2051\n",
            "2052\n",
            "2053\n",
            "2054\n",
            "2055\n",
            "2056\n",
            "2057\n",
            "2058\n",
            "2059\n",
            "2060\n",
            "2061\n",
            "2062\n",
            "2063\n",
            "2064\n",
            "2065\n",
            "2066\n",
            "2067\n",
            "2068\n",
            "2069\n",
            "2070\n",
            "2071\n",
            "2072\n",
            "2073\n",
            "2074\n",
            "2075\n",
            "2076\n",
            "2077\n",
            "2078\n",
            "2079\n",
            "2080\n",
            "2081\n",
            "2082\n",
            "2083\n",
            "2084\n",
            "2085\n",
            "2086\n",
            "2087\n",
            "2088\n",
            "2089\n",
            "2090\n",
            "2091\n",
            "2092\n",
            "2093\n",
            "2094\n",
            "2095\n",
            "2096\n",
            "2097\n",
            "2098\n",
            "2099\n",
            "2100\n",
            "2101\n",
            "2102\n",
            "2103\n",
            "2104\n",
            "2105\n",
            "2106\n",
            "2107\n",
            "2108\n",
            "2109\n",
            "2110\n",
            "2111\n",
            "2112\n",
            "2113\n",
            "2114\n",
            "2115\n",
            "2116\n",
            "2117\n",
            "2118\n",
            "2119\n",
            "2120\n",
            "2121\n",
            "2122\n",
            "2123\n",
            "2124\n",
            "2125\n",
            "2126\n",
            "2127\n",
            "2128\n",
            "2129\n",
            "2130\n",
            "2131\n",
            "2132\n",
            "2133\n",
            "2134\n",
            "2135\n",
            "2136\n",
            "2137\n",
            "2138\n",
            "2139\n",
            "2140\n",
            "2141\n",
            "2142\n",
            "2143\n",
            "2144\n",
            "2145\n",
            "2146\n",
            "2147\n",
            "2148\n",
            "2149\n",
            "2150\n",
            "2151\n",
            "2152\n",
            "2153\n",
            "2154\n",
            "2155\n",
            "2156\n",
            "2157\n",
            "2158\n",
            "2159\n",
            "2160\n",
            "2161\n",
            "2162\n",
            "2163\n",
            "2164\n",
            "2165\n",
            "2166\n",
            "2167\n",
            "2168\n",
            "2169\n",
            "2170\n",
            "2171\n",
            "2172\n",
            "2173\n",
            "2174\n",
            "2175\n",
            "2176\n",
            "2177\n",
            "2178\n",
            "2179\n",
            "2180\n",
            "2181\n",
            "2182\n",
            "2183\n",
            "2184\n",
            "2185\n",
            "2186\n",
            "2187\n",
            "2188\n",
            "2189\n",
            "2190\n",
            "2191\n",
            "2192\n",
            "2193\n",
            "2194\n",
            "2195\n",
            "2196\n",
            "2197\n",
            "2198\n",
            "2199\n",
            "2200\n",
            "2201\n",
            "2202\n",
            "2203\n",
            "2204\n",
            "2205\n",
            "2206\n",
            "2207\n",
            "2208\n",
            "2209\n",
            "2210\n",
            "2211\n",
            "2212\n",
            "2213\n",
            "2214\n",
            "2215\n",
            "2216\n",
            "2217\n",
            "2218\n",
            "2219\n",
            "2220\n",
            "2221\n",
            "2222\n",
            "2223\n",
            "2224\n",
            "2225\n",
            "2226\n",
            "2227\n",
            "2228\n",
            "2229\n",
            "2230\n",
            "2231\n",
            "2232\n",
            "2233\n",
            "2234\n",
            "2235\n",
            "2236\n",
            "2237\n",
            "2238\n",
            "2239\n",
            "2240\n",
            "2241\n",
            "2242\n",
            "2243\n",
            "2244\n",
            "2245\n",
            "2246\n",
            "2247\n",
            "2248\n",
            "2249\n",
            "2250\n",
            "2251\n",
            "2252\n",
            "2253\n",
            "2254\n",
            "2255\n",
            "2256\n",
            "2257\n",
            "2258\n",
            "2259\n",
            "2260\n",
            "2261\n",
            "2262\n",
            "2263\n",
            "2264\n",
            "2265\n",
            "2266\n",
            "2267\n",
            "2268\n",
            "2269\n",
            "2270\n",
            "2271\n",
            "2272\n",
            "2273\n",
            "2274\n",
            "2275\n",
            "2276\n",
            "2277\n",
            "2278\n",
            "2279\n",
            "2280\n",
            "2281\n",
            "2282\n",
            "2283\n",
            "2284\n",
            "2285\n",
            "2286\n",
            "2287\n",
            "2288\n",
            "2289\n",
            "2290\n",
            "2291\n",
            "2292\n",
            "2293\n",
            "2294\n",
            "2295\n",
            "2296\n",
            "2297\n",
            "2298\n",
            "2299\n",
            "2300\n",
            "2301\n",
            "2302\n",
            "2303\n",
            "2304\n",
            "2305\n",
            "2306\n",
            "2307\n",
            "2308\n",
            "2309\n",
            "2310\n",
            "2311\n",
            "2312\n",
            "2313\n",
            "2314\n",
            "2315\n",
            "2316\n",
            "2317\n",
            "2318\n",
            "2319\n",
            "2320\n",
            "2321\n",
            "2322\n",
            "2323\n",
            "2324\n",
            "2325\n",
            "2326\n",
            "2327\n",
            "2328\n",
            "2329\n",
            "2330\n",
            "2331\n",
            "2332\n",
            "2333\n",
            "2334\n",
            "2335\n",
            "2336\n",
            "2337\n",
            "2338\n",
            "2339\n",
            "2340\n",
            "2341\n",
            "2342\n",
            "2343\n",
            "2344\n",
            "2345\n",
            "2346\n",
            "2347\n",
            "2348\n",
            "2349\n",
            "2350\n",
            "2351\n",
            "2352\n",
            "2353\n",
            "2354\n",
            "2355\n",
            "2356\n",
            "2357\n",
            "2358\n",
            "2359\n",
            "2360\n",
            "2361\n",
            "2362\n",
            "2363\n",
            "2364\n",
            "2365\n",
            "2366\n",
            "2367\n",
            "2368\n",
            "2369\n",
            "2370\n",
            "2371\n",
            "2372\n",
            "2373\n",
            "2374\n",
            "2375\n",
            "2376\n",
            "2377\n",
            "2378\n",
            "2379\n",
            "2380\n",
            "2381\n",
            "2382\n",
            "2383\n",
            "2384\n",
            "2385\n",
            "2386\n",
            "2387\n",
            "2388\n",
            "2389\n",
            "2390\n",
            "2391\n",
            "2392\n",
            "2393\n",
            "2394\n",
            "2395\n",
            "2396\n",
            "2397\n",
            "2398\n",
            "2399\n",
            "2400\n",
            "2401\n",
            "2402\n",
            "2403\n",
            "2404\n",
            "2405\n",
            "2406\n",
            "2407\n",
            "2408\n",
            "2409\n",
            "2410\n",
            "2411\n",
            "2412\n",
            "2413\n",
            "2414\n",
            "2415\n",
            "2416\n",
            "2417\n",
            "2418\n",
            "2419\n",
            "2420\n",
            "2421\n",
            "2422\n",
            "2423\n",
            "2424\n",
            "2425\n",
            "2426\n",
            "2427\n",
            "2428\n",
            "2429\n",
            "2430\n",
            "2431\n",
            "2432\n",
            "2433\n",
            "2434\n",
            "2435\n",
            "2436\n",
            "2437\n",
            "2438\n",
            "2439\n",
            "2440\n",
            "2441\n",
            "2442\n",
            "2443\n",
            "2444\n",
            "2445\n",
            "2446\n",
            "2447\n",
            "2448\n",
            "2449\n",
            "2450\n",
            "2451\n",
            "2452\n",
            "2453\n",
            "2454\n",
            "2455\n",
            "2456\n",
            "2457\n",
            "2458\n",
            "2459\n",
            "2460\n",
            "2461\n",
            "2462\n",
            "2463\n",
            "2464\n",
            "2465\n",
            "2466\n",
            "2467\n",
            "2468\n",
            "2469\n",
            "2470\n",
            "2471\n",
            "2472\n",
            "2473\n",
            "2474\n",
            "2475\n",
            "2476\n",
            "2477\n",
            "2478\n",
            "2479\n",
            "2480\n",
            "2481\n",
            "2482\n",
            "2483\n",
            "2484\n",
            "2485\n",
            "2486\n",
            "2487\n",
            "2488\n",
            "2489\n",
            "2490\n",
            "2491\n",
            "2492\n",
            "2493\n",
            "2494\n",
            "2495\n",
            "2496\n",
            "2497\n",
            "2498\n",
            "2499\n",
            "2500\n",
            "2501\n",
            "2502\n",
            "2503\n",
            "2504\n",
            "2505\n",
            "2506\n",
            "2507\n",
            "2508\n",
            "2509\n",
            "2510\n",
            "2511\n",
            "2512\n",
            "2513\n",
            "2514\n",
            "2515\n",
            "2516\n",
            "2517\n",
            "2518\n",
            "2519\n",
            "2520\n",
            "2521\n",
            "2522\n",
            "2523\n",
            "2524\n",
            "2525\n",
            "2526\n",
            "2527\n",
            "2528\n",
            "2529\n",
            "2530\n",
            "2531\n",
            "2532\n",
            "2533\n",
            "2534\n",
            "2535\n",
            "2536\n",
            "2537\n",
            "2538\n",
            "2539\n",
            "2540\n",
            "2541\n",
            "2542\n",
            "2543\n",
            "2544\n",
            "2545\n",
            "2546\n",
            "2547\n",
            "2548\n",
            "2549\n",
            "2550\n",
            "2551\n",
            "2552\n",
            "2553\n",
            "2554\n",
            "2555\n",
            "2556\n",
            "2557\n",
            "2558\n",
            "2559\n",
            "2560\n",
            "2561\n",
            "2562\n",
            "2563\n",
            "2564\n",
            "2565\n",
            "2566\n",
            "2567\n",
            "2568\n",
            "2569\n",
            "2570\n",
            "2571\n",
            "2572\n",
            "2573\n",
            "2574\n",
            "2575\n",
            "2576\n",
            "2577\n",
            "2578\n",
            "2579\n",
            "2580\n",
            "2581\n",
            "2582\n",
            "2583\n",
            "2584\n",
            "2585\n",
            "2586\n",
            "2587\n",
            "2588\n",
            "2589\n",
            "2590\n",
            "2591\n",
            "2592\n",
            "2593\n",
            "2594\n",
            "2595\n",
            "2596\n",
            "2597\n",
            "2598\n",
            "2599\n",
            "2600\n",
            "2601\n",
            "2602\n",
            "2603\n",
            "2604\n",
            "2605\n",
            "2606\n",
            "2607\n",
            "2608\n",
            "2609\n",
            "2610\n",
            "2611\n",
            "2612\n",
            "2613\n",
            "2614\n",
            "2615\n",
            "2616\n",
            "2617\n",
            "2618\n",
            "2619\n",
            "2620\n",
            "2621\n",
            "2622\n",
            "2623\n",
            "2624\n",
            "2625\n",
            "2626\n",
            "2627\n",
            "2628\n",
            "2629\n",
            "2630\n",
            "2631\n",
            "2632\n",
            "2633\n",
            "2634\n",
            "2635\n",
            "2636\n",
            "2637\n",
            "2638\n",
            "2639\n",
            "2640\n",
            "2641\n",
            "2642\n",
            "2643\n",
            "2644\n",
            "2645\n",
            "2646\n",
            "2647\n",
            "2648\n",
            "2649\n",
            "2650\n",
            "2651\n",
            "2652\n",
            "2653\n",
            "2654\n",
            "2655\n",
            "2656\n",
            "2657\n",
            "2658\n",
            "2659\n",
            "2660\n",
            "2661\n",
            "2662\n",
            "2663\n",
            "2664\n",
            "2665\n",
            "2666\n",
            "2667\n",
            "2668\n",
            "2669\n",
            "2670\n",
            "2671\n",
            "2672\n",
            "2673\n",
            "2674\n",
            "2675\n",
            "2676\n",
            "2677\n",
            "2678\n",
            "2679\n",
            "2680\n",
            "2681\n",
            "2682\n",
            "2683\n",
            "2684\n",
            "2685\n",
            "2686\n",
            "2687\n",
            "2688\n",
            "2689\n",
            "2690\n",
            "2691\n",
            "2692\n",
            "2693\n",
            "2694\n",
            "2695\n",
            "2696\n",
            "2697\n",
            "2698\n",
            "2699\n",
            "2700\n",
            "2701\n",
            "2702\n",
            "2703\n",
            "2704\n",
            "2705\n",
            "2706\n",
            "2707\n",
            "2708\n",
            "2709\n",
            "2710\n",
            "2711\n",
            "2712\n",
            "2713\n",
            "2714\n",
            "2715\n",
            "2716\n",
            "2717\n",
            "2718\n",
            "2719\n",
            "2720\n",
            "2721\n",
            "2722\n",
            "2723\n",
            "2724\n",
            "2725\n",
            "2726\n",
            "2727\n",
            "2728\n",
            "2729\n",
            "2730\n",
            "2731\n",
            "2732\n",
            "2733\n",
            "2734\n",
            "2735\n",
            "2736\n",
            "2737\n",
            "2738\n",
            "2739\n",
            "2740\n",
            "2741\n",
            "2742\n",
            "2743\n",
            "2744\n",
            "2745\n",
            "2746\n",
            "2747\n",
            "2748\n",
            "2749\n",
            "2750\n",
            "2751\n",
            "2752\n",
            "2753\n",
            "2754\n",
            "2755\n",
            "2756\n",
            "2757\n",
            "2758\n",
            "2759\n",
            "2760\n",
            "2761\n",
            "2762\n",
            "2763\n",
            "2764\n",
            "2765\n",
            "2766\n",
            "2767\n",
            "2768\n",
            "2769\n",
            "2770\n",
            "2771\n",
            "2772\n",
            "2773\n",
            "2774\n",
            "2775\n",
            "2776\n",
            "2777\n",
            "2778\n",
            "2779\n",
            "2780\n",
            "2781\n",
            "2782\n",
            "2783\n",
            "2784\n",
            "2785\n",
            "2786\n",
            "2787\n",
            "2788\n",
            "2789\n",
            "2790\n",
            "2791\n",
            "2792\n",
            "2793\n",
            "2794\n",
            "2795\n",
            "2796\n",
            "2797\n",
            "2798\n",
            "2799\n",
            "2800\n",
            "2801\n",
            "2802\n",
            "2803\n",
            "2804\n",
            "2805\n",
            "2806\n",
            "2807\n",
            "2808\n",
            "2809\n",
            "2810\n",
            "2811\n",
            "2812\n",
            "2813\n",
            "2814\n",
            "2815\n",
            "2816\n",
            "2817\n",
            "2818\n",
            "2819\n",
            "2820\n",
            "2821\n",
            "2822\n",
            "2823\n",
            "2824\n",
            "2825\n",
            "2826\n",
            "2827\n",
            "2828\n",
            "2829\n",
            "2830\n",
            "2831\n",
            "2832\n",
            "2833\n",
            "2834\n",
            "2835\n",
            "2836\n",
            "2837\n",
            "2838\n",
            "2839\n",
            "2840\n",
            "2841\n",
            "2842\n",
            "2843\n",
            "2844\n",
            "2845\n",
            "2846\n",
            "2847\n",
            "2848\n",
            "2849\n",
            "2850\n",
            "2851\n",
            "2852\n",
            "2853\n",
            "2854\n",
            "2855\n",
            "2856\n",
            "2857\n",
            "2858\n",
            "2859\n",
            "2860\n",
            "2861\n",
            "2862\n",
            "2863\n",
            "2864\n",
            "2865\n",
            "2866\n",
            "2867\n",
            "2868\n",
            "2869\n",
            "2870\n",
            "2871\n",
            "2872\n",
            "2873\n",
            "2874\n",
            "2875\n",
            "2876\n",
            "2877\n",
            "2878\n",
            "2879\n",
            "2880\n",
            "2881\n",
            "2882\n",
            "2883\n",
            "2884\n",
            "2885\n",
            "2886\n",
            "2887\n",
            "2888\n",
            "2889\n",
            "2890\n",
            "2891\n",
            "2892\n",
            "2893\n",
            "2894\n",
            "2895\n",
            "2896\n",
            "2897\n",
            "2898\n",
            "2899\n",
            "2900\n",
            "2901\n",
            "2902\n",
            "2903\n",
            "2904\n",
            "2905\n",
            "2906\n",
            "2907\n",
            "2908\n",
            "2909\n",
            "2910\n",
            "2911\n",
            "2912\n",
            "2913\n",
            "2914\n",
            "2915\n",
            "2916\n",
            "2917\n",
            "2918\n",
            "2919\n",
            "2920\n",
            "2921\n",
            "2922\n",
            "2923\n",
            "2924\n",
            "2925\n",
            "2926\n",
            "2927\n",
            "2928\n",
            "2929\n",
            "2930\n",
            "2931\n",
            "2932\n",
            "2933\n",
            "2934\n",
            "2935\n",
            "2936\n",
            "2937\n",
            "2938\n",
            "2939\n",
            "2940\n",
            "2941\n",
            "2942\n",
            "2943\n",
            "2944\n",
            "2945\n",
            "2946\n",
            "2947\n",
            "2948\n",
            "2949\n",
            "2950\n",
            "2951\n",
            "2952\n",
            "2953\n",
            "2954\n",
            "2955\n",
            "2956\n",
            "2957\n",
            "2958\n",
            "2959\n",
            "2960\n",
            "2961\n",
            "2962\n",
            "2963\n",
            "2964\n",
            "2965\n",
            "2966\n",
            "2967\n",
            "2968\n",
            "2969\n",
            "2970\n",
            "2971\n",
            "2972\n",
            "2973\n",
            "2974\n",
            "2975\n",
            "2976\n",
            "2977\n",
            "2978\n",
            "2979\n",
            "2980\n",
            "2981\n",
            "2982\n",
            "2983\n",
            "2984\n",
            "2985\n",
            "2986\n",
            "2987\n",
            "2988\n",
            "2989\n",
            "2990\n",
            "2991\n",
            "2992\n",
            "2993\n",
            "2994\n",
            "2995\n",
            "2996\n",
            "2997\n",
            "2998\n",
            "2999\n",
            "3000\n",
            "3001\n",
            "3002\n",
            "3003\n",
            "3004\n",
            "3005\n",
            "3006\n",
            "3007\n",
            "3008\n",
            "3009\n",
            "3010\n",
            "3011\n",
            "3012\n",
            "3013\n",
            "3014\n",
            "3015\n",
            "3016\n",
            "3017\n",
            "3018\n",
            "3019\n",
            "3020\n",
            "3021\n",
            "3022\n",
            "3023\n",
            "3024\n",
            "3025\n",
            "3026\n",
            "3027\n",
            "3028\n",
            "3029\n",
            "3030\n",
            "3031\n",
            "3032\n",
            "3033\n",
            "3034\n",
            "3035\n",
            "3036\n",
            "3037\n",
            "3038\n",
            "3039\n",
            "3040\n",
            "3041\n",
            "3042\n",
            "3043\n",
            "3044\n",
            "3045\n",
            "3046\n",
            "3047\n",
            "3048\n",
            "3049\n",
            "3050\n",
            "3051\n",
            "3052\n",
            "3053\n",
            "3054\n",
            "3055\n",
            "3056\n",
            "3057\n",
            "3058\n",
            "3059\n",
            "3060\n",
            "3061\n",
            "3062\n",
            "3063\n",
            "3064\n",
            "3065\n",
            "3066\n",
            "3067\n",
            "3068\n",
            "3069\n",
            "3070\n",
            "3071\n",
            "3072\n",
            "3073\n",
            "3074\n",
            "3075\n",
            "3076\n",
            "3077\n",
            "3078\n",
            "3079\n",
            "3080\n",
            "3081\n",
            "3082\n",
            "3083\n",
            "3084\n",
            "3085\n",
            "3086\n",
            "3087\n",
            "3088\n",
            "3089\n",
            "3090\n",
            "3091\n",
            "3092\n",
            "3093\n",
            "3094\n",
            "3095\n",
            "3096\n",
            "3097\n",
            "3098\n",
            "3099\n",
            "3100\n",
            "3101\n",
            "3102\n",
            "3103\n",
            "3104\n",
            "3105\n",
            "3106\n",
            "3107\n",
            "3108\n",
            "3109\n",
            "3110\n",
            "3111\n",
            "3112\n",
            "3113\n",
            "3114\n",
            "3115\n",
            "3116\n",
            "3117\n",
            "3118\n",
            "3119\n",
            "3120\n",
            "3121\n",
            "3122\n",
            "3123\n",
            "3124\n",
            "3125\n",
            "3126\n",
            "3127\n",
            "3128\n",
            "3129\n",
            "3130\n",
            "3131\n",
            "3132\n",
            "3133\n",
            "3134\n",
            "3135\n",
            "3136\n",
            "3137\n",
            "3138\n",
            "3139\n",
            "3140\n",
            "3141\n",
            "3142\n",
            "3143\n",
            "3144\n",
            "3145\n",
            "3146\n",
            "3147\n",
            "3148\n",
            "3149\n",
            "3150\n",
            "3151\n",
            "3152\n",
            "3153\n",
            "3154\n",
            "3155\n",
            "3156\n",
            "3157\n",
            "3158\n",
            "3159\n",
            "3160\n",
            "3161\n",
            "3162\n",
            "3163\n",
            "3164\n",
            "3165\n",
            "3166\n",
            "3167\n",
            "3168\n",
            "3169\n",
            "3170\n",
            "3171\n",
            "3172\n",
            "3173\n",
            "3174\n",
            "3175\n",
            "3176\n",
            "3177\n",
            "3178\n",
            "3179\n",
            "3180\n",
            "3181\n",
            "3182\n",
            "3183\n",
            "3184\n",
            "3185\n",
            "3186\n",
            "3187\n",
            "3188\n",
            "3189\n",
            "3190\n",
            "3191\n",
            "3192\n",
            "3193\n",
            "3194\n",
            "3195\n",
            "3196\n",
            "3197\n",
            "3198\n",
            "3199\n",
            "3200\n",
            "3201\n",
            "3202\n",
            "3203\n",
            "3204\n",
            "3205\n",
            "3206\n",
            "3207\n",
            "3208\n",
            "3209\n",
            "3210\n",
            "3211\n",
            "3212\n",
            "3213\n",
            "3214\n",
            "3215\n",
            "3216\n",
            "3217\n",
            "3218\n",
            "3219\n",
            "3220\n",
            "3221\n",
            "3222\n",
            "3223\n",
            "3224\n",
            "3225\n",
            "3226\n",
            "3227\n",
            "3228\n",
            "3229\n",
            "3230\n",
            "3231\n",
            "3232\n",
            "3233\n",
            "3234\n",
            "3235\n",
            "3236\n",
            "3237\n",
            "3238\n",
            "3239\n",
            "3240\n",
            "3241\n",
            "3242\n",
            "3243\n",
            "3244\n",
            "3245\n",
            "3246\n",
            "3247\n",
            "3248\n",
            "3249\n",
            "3250\n",
            "3251\n",
            "3252\n",
            "3253\n",
            "3254\n",
            "3255\n",
            "3256\n",
            "3257\n",
            "3258\n",
            "3259\n",
            "3260\n",
            "3261\n",
            "3262\n",
            "3263\n",
            "3264\n",
            "3265\n",
            "3266\n",
            "3267\n",
            "3268\n",
            "3269\n",
            "3270\n",
            "3271\n",
            "3272\n",
            "3273\n",
            "3274\n",
            "3275\n",
            "3276\n",
            "3277\n",
            "3278\n",
            "3279\n",
            "3280\n",
            "3281\n",
            "3282\n",
            "3283\n",
            "3284\n",
            "3285\n",
            "3286\n",
            "3287\n",
            "3288\n",
            "3289\n",
            "3290\n",
            "3291\n",
            "3292\n",
            "3293\n",
            "3294\n",
            "3295\n",
            "3296\n",
            "3297\n",
            "3298\n",
            "3299\n",
            "3300\n",
            "3301\n",
            "3302\n",
            "3303\n",
            "3304\n",
            "3305\n",
            "3306\n",
            "3307\n",
            "3308\n",
            "3309\n",
            "3310\n",
            "3311\n",
            "3312\n",
            "3313\n",
            "3314\n",
            "3315\n",
            "3316\n",
            "3317\n",
            "3318\n",
            "3319\n",
            "3320\n",
            "3321\n",
            "3322\n",
            "3323\n",
            "3324\n",
            "3325\n",
            "3326\n",
            "3327\n",
            "3328\n",
            "3329\n",
            "3330\n",
            "3331\n",
            "3332\n",
            "3333\n",
            "3334\n",
            "3335\n",
            "3336\n",
            "3337\n",
            "3338\n",
            "3339\n",
            "3340\n",
            "3341\n",
            "3342\n",
            "3343\n",
            "3344\n",
            "3345\n",
            "3346\n",
            "3347\n",
            "3348\n",
            "3349\n",
            "3350\n",
            "3351\n",
            "3352\n",
            "3353\n",
            "3354\n",
            "3355\n",
            "3356\n",
            "3357\n",
            "3358\n",
            "3359\n",
            "3360\n",
            "3361\n",
            "3362\n",
            "3363\n",
            "3364\n",
            "3365\n",
            "3366\n",
            "3367\n",
            "3368\n",
            "3369\n",
            "3370\n",
            "3371\n",
            "3372\n",
            "3373\n",
            "3374\n",
            "3375\n",
            "3376\n",
            "3377\n",
            "3378\n",
            "3379\n",
            "3380\n",
            "3381\n",
            "3382\n",
            "3383\n",
            "3384\n",
            "3385\n",
            "3386\n",
            "3387\n",
            "3388\n",
            "3389\n",
            "3390\n",
            "3391\n",
            "3392\n",
            "3393\n",
            "3394\n",
            "3395\n",
            "3396\n",
            "3397\n",
            "3398\n",
            "3399\n",
            "3400\n",
            "3401\n",
            "3402\n",
            "3403\n",
            "3404\n",
            "3405\n",
            "3406\n",
            "3407\n",
            "3408\n",
            "3409\n",
            "3410\n",
            "3411\n",
            "3412\n",
            "3413\n",
            "3414\n",
            "3415\n",
            "3416\n",
            "3417\n",
            "3418\n",
            "3419\n",
            "3420\n",
            "3421\n",
            "3422\n",
            "3423\n",
            "3424\n",
            "3425\n",
            "3426\n",
            "3427\n",
            "3428\n",
            "3429\n",
            "3430\n",
            "3431\n",
            "3432\n",
            "3433\n",
            "3434\n",
            "3435\n",
            "3436\n",
            "3437\n",
            "3438\n",
            "3439\n",
            "3440\n",
            "3441\n",
            "3442\n",
            "3443\n",
            "3444\n",
            "3445\n",
            "3446\n",
            "3447\n",
            "3448\n",
            "3449\n",
            "3450\n",
            "3451\n",
            "3452\n",
            "3453\n",
            "3454\n",
            "3455\n",
            "3456\n",
            "3457\n",
            "3458\n",
            "3459\n",
            "3460\n",
            "3461\n",
            "3462\n",
            "3463\n",
            "3464\n",
            "3465\n",
            "3466\n",
            "3467\n",
            "3468\n",
            "3469\n",
            "3470\n",
            "3471\n",
            "3472\n",
            "3473\n",
            "3474\n",
            "3475\n",
            "3476\n",
            "3477\n",
            "3478\n",
            "3479\n",
            "3480\n",
            "3481\n",
            "3482\n",
            "3483\n",
            "3484\n",
            "3485\n",
            "3486\n",
            "3487\n",
            "3488\n",
            "3489\n",
            "3490\n",
            "3491\n",
            "3492\n",
            "3493\n",
            "3494\n",
            "3495\n",
            "3496\n",
            "3497\n",
            "3498\n",
            "3499\n",
            "3500\n",
            "3501\n",
            "3502\n",
            "3503\n",
            "3504\n",
            "3505\n",
            "3506\n",
            "3507\n",
            "3508\n",
            "3509\n",
            "3510\n",
            "3511\n",
            "3512\n",
            "3513\n",
            "3514\n",
            "3515\n",
            "3516\n",
            "3517\n",
            "3518\n",
            "3519\n",
            "3520\n",
            "3521\n",
            "3522\n",
            "3523\n",
            "3524\n",
            "3525\n",
            "3526\n",
            "3527\n",
            "3528\n",
            "3529\n",
            "3530\n",
            "3531\n",
            "3532\n",
            "3533\n",
            "3534\n",
            "3535\n",
            "3536\n",
            "3537\n",
            "3538\n",
            "3539\n",
            "3540\n",
            "3541\n",
            "3542\n",
            "3543\n",
            "3544\n",
            "3545\n",
            "3546\n",
            "3547\n",
            "3548\n",
            "3549\n",
            "3550\n",
            "3551\n",
            "3552\n",
            "3553\n",
            "3554\n",
            "3555\n",
            "3556\n",
            "3557\n",
            "3558\n",
            "3559\n",
            "3560\n",
            "3561\n",
            "3562\n",
            "3563\n",
            "3564\n",
            "3565\n",
            "3566\n",
            "3567\n",
            "3568\n",
            "3569\n",
            "3570\n",
            "3571\n",
            "3572\n",
            "3573\n",
            "3574\n",
            "3575\n",
            "3576\n",
            "3577\n",
            "3578\n",
            "3579\n",
            "3580\n",
            "3581\n",
            "3582\n",
            "3583\n",
            "3584\n",
            "3585\n",
            "3586\n",
            "3587\n",
            "3588\n",
            "3589\n",
            "3590\n",
            "3591\n",
            "3592\n",
            "3593\n",
            "3594\n",
            "3595\n",
            "3596\n",
            "3597\n",
            "3598\n",
            "3599\n",
            "3600\n",
            "3601\n",
            "3602\n",
            "3603\n",
            "3604\n",
            "3605\n",
            "3606\n",
            "3607\n",
            "3608\n",
            "3609\n",
            "3610\n",
            "3611\n",
            "3612\n",
            "3613\n",
            "3614\n",
            "3615\n",
            "3616\n",
            "3617\n",
            "3618\n",
            "3619\n",
            "3620\n",
            "3621\n",
            "3622\n",
            "3623\n",
            "3624\n",
            "3625\n",
            "3626\n",
            "3627\n",
            "3628\n",
            "3629\n",
            "3630\n",
            "3631\n",
            "3632\n",
            "3633\n",
            "3634\n",
            "3635\n",
            "3636\n",
            "3637\n",
            "3638\n",
            "3639\n",
            "3640\n",
            "3641\n",
            "3642\n",
            "3643\n",
            "3644\n",
            "3645\n",
            "3646\n",
            "3647\n",
            "3648\n",
            "3649\n",
            "3650\n",
            "3651\n",
            "3652\n",
            "3653\n",
            "3654\n",
            "3655\n",
            "3656\n",
            "3657\n",
            "3658\n",
            "3659\n",
            "3660\n",
            "3661\n",
            "3662\n",
            "3663\n",
            "3664\n",
            "3665\n",
            "3666\n",
            "3667\n",
            "3668\n",
            "3669\n",
            "3670\n",
            "3671\n",
            "3672\n",
            "3673\n",
            "3674\n",
            "3675\n",
            "3676\n",
            "3677\n",
            "3678\n",
            "3679\n",
            "3680\n",
            "3681\n",
            "3682\n",
            "3683\n",
            "3684\n",
            "3685\n",
            "3686\n",
            "3687\n",
            "3688\n",
            "3689\n",
            "3690\n",
            "3691\n",
            "3692\n",
            "3693\n",
            "3694\n",
            "3695\n",
            "3696\n",
            "3697\n",
            "3698\n",
            "3699\n",
            "3700\n",
            "3701\n",
            "3702\n",
            "3703\n",
            "3704\n",
            "3705\n",
            "3706\n",
            "3707\n",
            "3708\n",
            "3709\n",
            "3710\n",
            "3711\n",
            "3712\n",
            "3713\n",
            "3714\n",
            "3715\n",
            "3716\n",
            "3717\n",
            "3718\n",
            "3719\n",
            "3720\n",
            "3721\n",
            "3722\n",
            "3723\n",
            "3724\n",
            "3725\n",
            "3726\n",
            "3727\n",
            "3728\n",
            "3729\n",
            "3730\n",
            "3731\n",
            "3732\n",
            "3733\n",
            "3734\n",
            "3735\n",
            "3736\n",
            "3737\n",
            "3738\n",
            "3739\n",
            "3740\n",
            "3741\n",
            "3742\n",
            "3743\n",
            "3744\n",
            "3745\n",
            "3746\n",
            "3747\n",
            "3748\n",
            "3749\n",
            "3750\n",
            "3751\n",
            "3752\n",
            "3753\n",
            "3754\n",
            "3755\n",
            "3756\n",
            "3757\n",
            "3758\n",
            "3759\n",
            "3760\n",
            "3761\n",
            "3762\n",
            "3763\n",
            "3764\n",
            "3765\n",
            "3766\n",
            "3767\n",
            "3768\n",
            "3769\n",
            "3770\n",
            "3771\n",
            "3772\n",
            "3773\n",
            "3774\n",
            "3775\n",
            "3776\n",
            "3777\n",
            "3778\n",
            "3779\n",
            "3780\n",
            "3781\n",
            "3782\n",
            "3783\n",
            "3784\n",
            "3785\n",
            "3786\n",
            "3787\n",
            "3788\n",
            "3789\n",
            "3790\n",
            "3791\n",
            "3792\n",
            "3793\n",
            "3794\n",
            "3795\n",
            "3796\n",
            "3797\n",
            "3798\n",
            "3799\n",
            "3800\n",
            "3801\n",
            "3802\n",
            "3803\n",
            "3804\n",
            "3805\n",
            "3806\n",
            "3807\n",
            "3808\n",
            "3809\n",
            "3810\n",
            "3811\n",
            "3812\n",
            "3813\n",
            "3814\n",
            "3815\n",
            "3816\n",
            "3817\n",
            "3818\n",
            "3819\n",
            "3820\n",
            "3821\n",
            "3822\n",
            "3823\n",
            "3824\n",
            "3825\n",
            "3826\n",
            "3827\n",
            "3828\n",
            "3829\n",
            "3830\n",
            "3831\n",
            "3832\n",
            "3833\n",
            "3834\n",
            "3835\n",
            "3836\n",
            "3837\n",
            "3838\n",
            "3839\n",
            "3840\n",
            "3841\n",
            "3842\n",
            "3843\n",
            "3844\n",
            "3845\n",
            "3846\n",
            "3847\n",
            "3848\n",
            "3849\n",
            "3850\n",
            "3851\n",
            "3852\n",
            "3853\n",
            "3854\n",
            "3855\n",
            "3856\n",
            "3857\n",
            "3858\n",
            "3859\n",
            "3860\n",
            "3861\n",
            "3862\n",
            "3863\n",
            "3864\n",
            "3865\n",
            "3866\n",
            "3867\n",
            "3868\n",
            "3869\n",
            "3870\n",
            "3871\n",
            "3872\n",
            "3873\n",
            "3874\n",
            "3875\n",
            "3876\n",
            "3877\n",
            "3878\n",
            "3879\n",
            "3880\n",
            "3881\n",
            "3882\n",
            "3883\n",
            "3884\n",
            "3885\n",
            "3886\n",
            "3887\n",
            "3888\n",
            "3889\n",
            "3890\n",
            "3891\n",
            "3892\n",
            "3893\n",
            "3894\n",
            "3895\n",
            "3896\n",
            "3897\n",
            "3898\n",
            "3899\n",
            "3900\n",
            "3901\n",
            "3902\n",
            "3903\n",
            "3904\n",
            "3905\n",
            "3906\n",
            "3907\n",
            "3908\n",
            "3909\n",
            "3910\n",
            "3911\n",
            "3912\n",
            "3913\n",
            "3914\n",
            "3915\n",
            "3916\n",
            "3917\n",
            "3918\n",
            "3919\n",
            "3920\n",
            "3921\n",
            "3922\n",
            "3923\n",
            "3924\n",
            "3925\n",
            "3926\n",
            "3927\n",
            "3928\n",
            "3929\n",
            "3930\n",
            "3931\n",
            "3932\n",
            "3933\n",
            "3934\n",
            "3935\n",
            "3936\n",
            "3937\n",
            "3938\n",
            "3939\n",
            "3940\n",
            "3941\n",
            "3942\n",
            "3943\n",
            "3944\n",
            "3945\n",
            "3946\n",
            "3947\n",
            "3948\n",
            "3949\n",
            "3950\n",
            "3951\n",
            "3952\n",
            "3953\n",
            "3954\n",
            "3955\n",
            "3956\n",
            "3957\n",
            "3958\n",
            "3959\n",
            "3960\n",
            "3961\n",
            "3962\n",
            "3963\n",
            "3964\n",
            "3965\n",
            "3966\n",
            "3967\n",
            "3968\n",
            "3969\n",
            "3970\n",
            "3971\n",
            "3972\n",
            "3973\n",
            "3974\n",
            "3975\n",
            "3976\n",
            "3977\n",
            "3978\n",
            "3979\n",
            "3980\n",
            "3981\n",
            "3982\n",
            "3983\n",
            "3984\n",
            "3985\n",
            "3986\n",
            "3987\n",
            "3988\n",
            "3989\n",
            "3990\n",
            "3991\n",
            "3992\n",
            "3993\n",
            "3994\n",
            "3995\n",
            "3996\n",
            "3997\n",
            "3998\n",
            "3999\n",
            "4000\n",
            "4001\n",
            "4002\n",
            "4003\n",
            "4004\n",
            "4005\n",
            "4006\n",
            "4007\n",
            "4008\n",
            "4009\n",
            "4010\n",
            "4011\n",
            "4012\n",
            "4013\n",
            "4014\n",
            "4015\n",
            "4016\n",
            "4017\n",
            "4018\n",
            "4019\n",
            "4020\n",
            "4021\n",
            "4022\n",
            "4023\n",
            "4024\n",
            "4025\n",
            "4026\n",
            "4027\n",
            "4028\n",
            "4029\n",
            "4030\n",
            "4031\n",
            "4032\n",
            "4033\n",
            "4034\n",
            "4035\n",
            "4036\n",
            "4037\n",
            "4038\n",
            "4039\n",
            "4040\n",
            "4041\n",
            "4042\n",
            "4043\n",
            "4044\n",
            "4045\n",
            "4046\n",
            "4047\n",
            "4048\n",
            "4049\n",
            "4050\n",
            "4051\n",
            "4052\n",
            "4053\n",
            "4054\n",
            "4055\n",
            "4056\n",
            "4057\n",
            "4058\n",
            "4059\n",
            "4060\n",
            "4061\n",
            "4062\n",
            "4063\n",
            "4064\n",
            "4065\n",
            "4066\n",
            "4067\n",
            "4068\n",
            "4069\n",
            "4070\n",
            "4071\n",
            "4072\n",
            "4073\n",
            "4074\n",
            "4075\n",
            "4076\n",
            "4077\n",
            "4078\n",
            "4079\n",
            "4080\n",
            "4081\n",
            "4082\n",
            "4083\n",
            "4084\n",
            "4085\n",
            "4086\n",
            "4087\n",
            "4088\n",
            "4089\n",
            "4090\n",
            "4091\n",
            "4092\n",
            "4093\n",
            "4094\n",
            "4095\n",
            "4096\n",
            "4097\n",
            "4098\n",
            "4099\n",
            "4100\n",
            "4101\n",
            "4102\n",
            "4103\n",
            "4104\n",
            "4105\n",
            "4106\n",
            "4107\n",
            "4108\n",
            "4109\n",
            "4110\n",
            "4111\n",
            "4112\n",
            "4113\n",
            "4114\n",
            "4115\n",
            "4116\n",
            "4117\n",
            "4118\n",
            "4119\n",
            "4120\n",
            "4121\n",
            "4122\n",
            "4123\n",
            "4124\n",
            "4125\n",
            "4126\n",
            "4127\n",
            "4128\n",
            "4129\n",
            "4130\n",
            "4131\n",
            "4132\n",
            "4133\n",
            "4134\n",
            "4135\n",
            "4136\n",
            "4137\n",
            "4138\n",
            "4139\n",
            "4140\n",
            "4141\n",
            "4142\n",
            "4143\n",
            "4144\n",
            "4145\n",
            "4146\n",
            "4147\n",
            "4148\n",
            "4149\n",
            "4150\n",
            "4151\n",
            "4152\n",
            "4153\n",
            "4154\n",
            "4155\n",
            "4156\n",
            "4157\n",
            "4158\n",
            "4159\n",
            "4160\n",
            "4161\n",
            "4162\n",
            "4163\n",
            "4164\n",
            "4165\n",
            "4166\n",
            "4167\n",
            "4168\n",
            "4169\n",
            "4170\n",
            "4171\n",
            "4172\n",
            "4173\n",
            "4174\n",
            "4175\n",
            "4176\n",
            "4177\n",
            "4178\n",
            "4179\n",
            "4180\n",
            "4181\n",
            "4182\n",
            "4183\n",
            "4184\n",
            "4185\n",
            "4186\n",
            "4187\n",
            "4188\n",
            "4189\n",
            "4190\n",
            "4191\n",
            "4192\n",
            "4193\n",
            "4194\n",
            "4195\n",
            "4196\n",
            "4197\n",
            "4198\n",
            "4199\n",
            "4200\n",
            "4201\n",
            "4202\n",
            "4203\n",
            "4204\n",
            "4205\n",
            "4206\n",
            "4207\n",
            "4208\n",
            "4209\n",
            "4210\n",
            "4211\n",
            "4212\n",
            "4213\n",
            "4214\n",
            "4215\n",
            "4216\n",
            "4217\n",
            "4218\n",
            "4219\n",
            "4220\n",
            "4221\n",
            "4222\n",
            "4223\n",
            "4224\n",
            "4225\n",
            "4226\n",
            "4227\n",
            "4228\n",
            "4229\n",
            "4230\n",
            "4231\n",
            "4232\n",
            "4233\n",
            "4234\n",
            "4235\n",
            "4236\n",
            "4237\n",
            "4238\n",
            "4239\n",
            "4240\n",
            "4241\n",
            "4242\n",
            "4243\n",
            "4244\n",
            "4245\n",
            "4246\n",
            "4247\n",
            "4248\n",
            "4249\n",
            "4250\n",
            "4251\n",
            "4252\n",
            "4253\n",
            "4254\n",
            "4255\n",
            "4256\n",
            "4257\n",
            "4258\n",
            "4259\n",
            "4260\n",
            "4261\n",
            "4262\n",
            "4263\n",
            "4264\n",
            "4265\n",
            "4266\n",
            "4267\n",
            "4268\n",
            "4269\n",
            "4270\n",
            "4271\n",
            "4272\n",
            "4273\n",
            "4274\n",
            "4275\n",
            "4276\n",
            "4277\n",
            "4278\n",
            "4279\n",
            "4280\n",
            "4281\n",
            "4282\n",
            "4283\n",
            "4284\n",
            "4285\n",
            "4286\n",
            "4287\n",
            "4288\n",
            "4289\n",
            "4290\n",
            "4291\n",
            "4292\n",
            "4293\n",
            "4294\n",
            "4295\n",
            "4296\n",
            "4297\n",
            "4298\n",
            "4299\n",
            "4300\n",
            "4301\n",
            "4302\n",
            "4303\n",
            "4304\n",
            "4305\n",
            "4306\n",
            "4307\n",
            "4308\n",
            "4309\n",
            "4310\n",
            "4311\n",
            "4312\n",
            "4313\n",
            "4314\n",
            "4315\n",
            "4316\n",
            "4317\n",
            "4318\n",
            "4319\n",
            "4320\n",
            "4321\n",
            "4322\n",
            "4323\n",
            "4324\n",
            "4325\n",
            "4326\n",
            "4327\n",
            "4328\n",
            "4329\n",
            "4330\n",
            "4331\n",
            "4332\n",
            "4333\n",
            "4334\n",
            "4335\n",
            "4336\n",
            "4337\n",
            "4338\n",
            "4339\n",
            "4340\n",
            "4341\n",
            "4342\n",
            "4343\n",
            "4344\n",
            "4345\n",
            "4346\n",
            "4347\n",
            "4348\n",
            "4349\n",
            "4350\n",
            "4351\n",
            "4352\n",
            "4353\n",
            "4354\n",
            "4355\n",
            "4356\n",
            "4357\n",
            "4358\n",
            "4359\n",
            "4360\n",
            "4361\n",
            "4362\n",
            "4363\n",
            "4364\n",
            "4365\n",
            "4366\n",
            "4367\n",
            "4368\n",
            "4369\n",
            "4370\n",
            "4371\n",
            "4372\n",
            "4373\n",
            "4374\n",
            "4375\n",
            "4376\n",
            "4377\n",
            "4378\n",
            "4379\n",
            "4380\n",
            "4381\n",
            "4382\n",
            "4383\n",
            "4384\n",
            "4385\n",
            "4386\n",
            "4387\n",
            "4388\n",
            "4389\n",
            "4390\n",
            "4391\n",
            "4392\n",
            "4393\n",
            "4394\n",
            "4395\n",
            "4396\n",
            "4397\n",
            "4398\n",
            "4399\n",
            "4400\n",
            "4401\n",
            "4402\n",
            "4403\n",
            "4404\n",
            "4405\n",
            "4406\n",
            "4407\n",
            "4408\n",
            "4409\n",
            "4410\n",
            "4411\n",
            "4412\n",
            "4413\n",
            "4414\n",
            "4415\n",
            "4416\n",
            "4417\n",
            "4418\n",
            "4419\n",
            "4420\n",
            "4421\n",
            "4422\n",
            "4423\n",
            "4424\n",
            "4425\n",
            "4426\n",
            "4427\n",
            "4428\n",
            "4429\n",
            "4430\n",
            "4431\n",
            "4432\n",
            "4433\n",
            "4434\n",
            "4435\n",
            "4436\n",
            "4437\n",
            "4438\n",
            "4439\n",
            "4440\n",
            "4441\n",
            "4442\n",
            "4443\n",
            "4444\n",
            "4445\n",
            "4446\n",
            "4447\n",
            "4448\n",
            "4449\n",
            "4450\n",
            "4451\n",
            "4452\n",
            "4453\n",
            "4454\n",
            "4455\n",
            "4456\n",
            "4457\n",
            "4458\n",
            "4459\n",
            "4460\n",
            "4461\n",
            "4462\n",
            "4463\n",
            "4464\n",
            "4465\n",
            "4466\n",
            "4467\n",
            "4468\n",
            "4469\n",
            "4470\n",
            "4471\n",
            "4472\n",
            "4473\n",
            "4474\n",
            "4475\n",
            "4476\n",
            "4477\n",
            "4478\n",
            "4479\n",
            "4480\n",
            "4481\n",
            "4482\n",
            "4483\n",
            "4484\n",
            "4485\n",
            "4486\n",
            "4487\n",
            "4488\n",
            "4489\n",
            "4490\n",
            "4491\n",
            "4492\n",
            "4493\n",
            "4494\n",
            "4495\n",
            "4496\n",
            "4497\n",
            "4498\n",
            "4499\n",
            "4500\n",
            "4501\n",
            "4502\n",
            "4503\n",
            "4504\n",
            "4505\n",
            "4506\n",
            "4507\n",
            "4508\n",
            "4509\n",
            "4510\n",
            "4511\n",
            "4512\n",
            "4513\n",
            "4514\n",
            "4515\n",
            "4516\n",
            "4517\n",
            "4518\n",
            "4519\n",
            "4520\n",
            "4521\n",
            "4522\n",
            "4523\n",
            "4524\n",
            "4525\n",
            "4526\n",
            "4527\n",
            "4528\n",
            "4529\n",
            "4530\n",
            "4531\n",
            "4532\n",
            "4533\n",
            "4534\n",
            "4535\n",
            "4536\n",
            "4537\n",
            "4538\n",
            "4539\n",
            "4540\n",
            "4541\n",
            "4542\n",
            "4543\n",
            "4544\n",
            "4545\n",
            "4546\n",
            "4547\n",
            "4548\n",
            "4549\n",
            "4550\n",
            "4551\n",
            "4552\n",
            "4553\n",
            "4554\n",
            "4555\n",
            "4556\n",
            "4557\n",
            "4558\n",
            "4559\n",
            "4560\n",
            "4561\n",
            "4562\n",
            "4563\n",
            "4564\n",
            "4565\n",
            "4566\n",
            "4567\n",
            "4568\n",
            "4569\n",
            "4570\n",
            "4571\n",
            "4572\n",
            "4573\n",
            "4574\n",
            "4575\n",
            "4576\n",
            "4577\n",
            "4578\n",
            "4579\n",
            "4580\n",
            "4581\n",
            "4582\n",
            "4583\n",
            "4584\n",
            "4585\n",
            "4586\n",
            "4587\n",
            "4588\n",
            "4589\n",
            "4590\n",
            "4591\n",
            "4592\n",
            "4593\n",
            "4594\n",
            "4595\n",
            "4596\n",
            "4597\n",
            "4598\n",
            "4599\n",
            "4600\n",
            "4601\n",
            "4602\n",
            "4603\n",
            "4604\n",
            "4605\n",
            "4606\n",
            "4607\n",
            "4608\n",
            "4609\n",
            "4610\n",
            "4611\n",
            "4612\n",
            "4613\n",
            "4614\n",
            "4615\n",
            "4616\n",
            "4617\n",
            "4618\n",
            "4619\n",
            "4620\n",
            "4621\n",
            "4622\n",
            "4623\n",
            "4624\n",
            "4625\n",
            "4626\n",
            "4627\n",
            "4628\n",
            "4629\n",
            "4630\n",
            "4631\n",
            "4632\n",
            "4633\n",
            "4634\n",
            "4635\n",
            "4636\n",
            "4637\n",
            "4638\n",
            "4639\n",
            "4640\n",
            "4641\n",
            "4642\n",
            "4643\n",
            "4644\n",
            "4645\n",
            "4646\n",
            "4647\n",
            "4648\n",
            "4649\n",
            "4650\n",
            "4651\n",
            "4652\n",
            "4653\n",
            "4654\n",
            "4655\n",
            "4656\n",
            "4657\n",
            "4658\n",
            "4659\n",
            "4660\n",
            "4661\n",
            "4662\n",
            "4663\n",
            "4664\n",
            "4665\n",
            "4666\n",
            "4667\n",
            "4668\n",
            "4669\n",
            "4670\n",
            "4671\n",
            "4672\n",
            "4673\n",
            "4674\n",
            "4675\n",
            "4676\n",
            "4677\n",
            "4678\n",
            "4679\n",
            "4680\n",
            "4681\n",
            "4682\n",
            "4683\n",
            "4684\n",
            "4685\n",
            "4686\n",
            "4687\n",
            "4688\n",
            "4689\n",
            "4690\n",
            "4691\n",
            "4692\n",
            "4693\n",
            "4694\n",
            "4695\n",
            "4696\n",
            "4697\n",
            "4698\n",
            "4699\n",
            "4700\n",
            "4701\n",
            "4702\n",
            "4703\n",
            "4704\n",
            "4705\n",
            "4706\n",
            "4707\n",
            "4708\n",
            "4709\n",
            "4710\n",
            "4711\n",
            "4712\n",
            "4713\n",
            "4714\n",
            "4715\n",
            "4716\n",
            "4717\n",
            "4718\n",
            "4719\n",
            "4720\n",
            "4721\n",
            "4722\n",
            "4723\n",
            "4724\n",
            "4725\n",
            "4726\n",
            "4727\n",
            "4728\n",
            "4729\n",
            "4730\n",
            "4731\n",
            "4732\n",
            "4733\n",
            "4734\n",
            "4735\n",
            "4736\n",
            "4737\n",
            "4738\n",
            "4739\n",
            "4740\n",
            "4741\n",
            "4742\n",
            "4743\n",
            "4744\n",
            "4745\n",
            "4746\n",
            "4747\n",
            "4748\n",
            "4749\n",
            "4750\n",
            "4751\n",
            "4752\n",
            "4753\n",
            "4754\n",
            "4755\n",
            "4756\n",
            "4757\n",
            "4758\n",
            "4759\n",
            "4760\n",
            "4761\n",
            "4762\n",
            "4763\n",
            "4764\n",
            "4765\n",
            "4766\n",
            "4767\n",
            "4768\n",
            "4769\n",
            "4770\n",
            "4771\n",
            "4772\n",
            "4773\n",
            "4774\n",
            "4775\n",
            "4776\n",
            "4777\n",
            "4778\n",
            "4779\n",
            "4780\n",
            "4781\n",
            "4782\n",
            "4783\n",
            "4784\n",
            "4785\n",
            "4786\n",
            "4787\n",
            "4788\n",
            "4789\n",
            "4790\n",
            "4791\n",
            "4792\n",
            "4793\n",
            "4794\n",
            "4795\n",
            "4796\n",
            "4797\n",
            "4798\n",
            "4799\n",
            "4800\n",
            "4801\n",
            "4802\n",
            "4803\n",
            "4804\n",
            "4805\n",
            "4806\n",
            "4807\n",
            "4808\n",
            "4809\n",
            "4810\n",
            "4811\n",
            "4812\n",
            "4813\n",
            "4814\n",
            "4815\n",
            "4816\n",
            "4817\n",
            "4818\n",
            "4819\n",
            "4820\n",
            "4821\n",
            "4822\n",
            "4823\n",
            "4824\n",
            "4825\n",
            "4826\n",
            "4827\n",
            "4828\n",
            "4829\n",
            "4830\n",
            "4831\n",
            "4832\n",
            "4833\n",
            "4834\n",
            "4835\n",
            "4836\n",
            "4837\n",
            "4838\n",
            "4839\n",
            "4840\n",
            "4841\n",
            "4842\n",
            "4843\n",
            "4844\n",
            "4845\n",
            "4846\n",
            "4847\n",
            "4848\n",
            "4849\n",
            "4850\n",
            "4851\n",
            "4852\n",
            "4853\n",
            "4854\n",
            "4855\n",
            "4856\n",
            "4857\n",
            "4858\n",
            "4859\n",
            "4860\n",
            "4861\n",
            "4862\n",
            "4863\n",
            "4864\n",
            "4865\n",
            "4866\n",
            "4867\n",
            "4868\n",
            "4869\n",
            "4870\n",
            "4871\n",
            "4872\n",
            "4873\n",
            "4874\n",
            "4875\n",
            "4876\n",
            "4877\n",
            "4878\n",
            "4879\n",
            "4880\n",
            "4881\n",
            "4882\n",
            "4883\n",
            "4884\n",
            "4885\n",
            "4886\n",
            "4887\n",
            "4888\n",
            "4889\n",
            "4890\n",
            "4891\n",
            "4892\n",
            "4893\n",
            "4894\n",
            "4895\n",
            "4896\n",
            "4897\n",
            "4898\n",
            "4899\n",
            "4900\n",
            "4901\n",
            "4902\n",
            "4903\n",
            "4904\n",
            "4905\n",
            "4906\n",
            "4907\n",
            "4908\n",
            "4909\n",
            "4910\n",
            "4911\n",
            "4912\n",
            "4913\n",
            "4914\n",
            "4915\n",
            "4916\n",
            "4917\n",
            "4918\n",
            "4919\n",
            "4920\n",
            "4921\n",
            "4922\n",
            "4923\n",
            "4924\n",
            "4925\n",
            "4926\n",
            "4927\n",
            "4928\n",
            "4929\n",
            "4930\n",
            "4931\n",
            "4932\n",
            "4933\n",
            "4934\n",
            "4935\n",
            "4936\n",
            "4937\n",
            "4938\n",
            "4939\n",
            "4940\n",
            "4941\n",
            "4942\n",
            "4943\n",
            "4944\n",
            "4945\n",
            "4946\n",
            "4947\n",
            "4948\n",
            "4949\n",
            "4950\n",
            "4951\n",
            "4952\n",
            "4953\n",
            "4954\n",
            "4955\n",
            "4956\n",
            "4957\n",
            "4958\n",
            "4959\n",
            "4960\n",
            "4961\n",
            "4962\n",
            "4963\n",
            "4964\n",
            "4965\n",
            "4966\n",
            "4967\n",
            "4968\n",
            "4969\n",
            "4970\n",
            "4971\n",
            "4972\n",
            "4973\n",
            "4974\n",
            "4975\n",
            "4976\n",
            "4977\n",
            "4978\n",
            "4979\n",
            "4980\n",
            "4981\n",
            "4982\n",
            "4983\n",
            "4984\n",
            "4985\n",
            "4986\n",
            "4987\n",
            "4988\n",
            "4989\n",
            "4990\n",
            "4991\n",
            "4992\n",
            "4993\n",
            "4994\n",
            "4995\n",
            "4996\n",
            "4997\n",
            "4998\n",
            "4999\n",
            "5000\n",
            "5001\n",
            "5002\n",
            "5003\n",
            "5004\n",
            "5005\n",
            "5006\n",
            "5007\n",
            "5008\n",
            "5009\n",
            "5010\n",
            "5011\n",
            "5012\n",
            "5013\n",
            "5014\n",
            "5015\n",
            "5016\n",
            "5017\n",
            "5018\n",
            "5019\n",
            "5020\n",
            "5021\n",
            "5022\n",
            "5023\n",
            "5024\n",
            "5025\n",
            "5026\n",
            "5027\n",
            "5028\n",
            "5029\n",
            "5030\n",
            "5031\n",
            "5032\n",
            "5033\n",
            "5034\n",
            "5035\n",
            "5036\n",
            "5037\n",
            "5038\n",
            "5039\n",
            "5040\n",
            "5041\n",
            "5042\n",
            "5043\n",
            "5044\n",
            "5045\n",
            "5046\n",
            "5047\n",
            "5048\n",
            "5049\n",
            "5050\n",
            "5051\n",
            "5052\n",
            "5053\n",
            "5054\n",
            "5055\n",
            "5056\n",
            "5057\n",
            "5058\n",
            "5059\n",
            "5060\n",
            "5061\n",
            "5062\n",
            "5063\n",
            "5064\n",
            "5065\n",
            "5066\n",
            "5067\n",
            "5068\n",
            "5069\n",
            "5070\n",
            "5071\n",
            "5072\n",
            "5073\n",
            "5074\n",
            "5075\n",
            "5076\n",
            "5077\n",
            "5078\n",
            "5079\n",
            "5080\n",
            "5081\n",
            "5082\n",
            "5083\n",
            "5084\n",
            "5085\n",
            "5086\n",
            "5087\n",
            "5088\n",
            "5089\n",
            "5090\n",
            "5091\n",
            "5092\n",
            "5093\n",
            "5094\n",
            "5095\n",
            "5096\n",
            "5097\n",
            "5098\n",
            "5099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asd #이게 온도, 풍속, 습도 평균을 내준 z-score로 변환하기 전의 데이터임\n",
        "#즉 이걸 기반으로 모델을 돌림 여기서 z-score로만 바꾸면 됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-CuNUkOdncLI",
        "outputId": "5a3317af-8f58-4606-aa6e-94d97f390182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       num  power(kWh)  Znum   temp(°C)  wind(m/s)  humidity(%)  \\\n",
              "0      1.0    8179.056   1.0  19.841667   3.375000    65.208333   \n",
              "1      1.0    7920.504   1.0  17.900000   2.112500    69.041667   \n",
              "2      1.0    8114.904   1.0  21.841667   2.375000    73.416667   \n",
              "3      1.0    8254.872   1.0  21.908333   2.679167    79.875000   \n",
              "4      1.0    8598.960   1.0  22.862500   1.962500    71.458333   \n",
              "...    ...         ...   ...        ...        ...          ...   \n",
              "5095  60.0    3149.280  60.0  26.525000   2.087500    78.750000   \n",
              "5096  60.0    3320.352  60.0  26.283333   2.216667    81.416667   \n",
              "5097  60.0    2993.760  60.0  25.283333   2.345833    80.375000   \n",
              "5098  60.0    3166.560  60.0  25.254167   2.137500    72.875000   \n",
              "5099  60.0    3050.352  60.0  26.966667   2.012500    70.000000   \n",
              "\n",
              "      non_elect_cool_sys  solar_pannel  month   day  week  weekend  \n",
              "0                    0.0           0.0    6.0   1.0   0.0      0.0  \n",
              "1                    0.0           0.0    6.0   2.0   1.0      0.0  \n",
              "2                    0.0           0.0    6.0   3.0   2.0      0.0  \n",
              "3                    0.0           0.0    6.0   4.0   3.0      0.0  \n",
              "4                    0.0           0.0    6.0   5.0   4.0      0.0  \n",
              "...                  ...           ...    ...   ...   ...      ...  \n",
              "5095                 1.0           1.0    8.0  20.0   3.0      0.0  \n",
              "5096                 1.0           1.0    8.0  21.0   4.0      0.0  \n",
              "5097                 1.0           1.0    8.0  22.0   5.0      1.0  \n",
              "5098                 1.0           1.0    8.0  23.0   6.0      1.0  \n",
              "5099                 1.0           1.0    8.0  24.0   0.0      0.0  \n",
              "\n",
              "[5100 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96453b09-dd24-4c1f-9ca3-4662ff4826c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>power(kWh)</th>\n",
              "      <th>Znum</th>\n",
              "      <th>temp(°C)</th>\n",
              "      <th>wind(m/s)</th>\n",
              "      <th>humidity(%)</th>\n",
              "      <th>non_elect_cool_sys</th>\n",
              "      <th>solar_pannel</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>week</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8179.056</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.841667</td>\n",
              "      <td>3.375000</td>\n",
              "      <td>65.208333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7920.504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.900000</td>\n",
              "      <td>2.112500</td>\n",
              "      <td>69.041667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8114.904</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.841667</td>\n",
              "      <td>2.375000</td>\n",
              "      <td>73.416667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8254.872</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.908333</td>\n",
              "      <td>2.679167</td>\n",
              "      <td>79.875000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8598.960</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.862500</td>\n",
              "      <td>1.962500</td>\n",
              "      <td>71.458333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3149.280</td>\n",
              "      <td>60.0</td>\n",
              "      <td>26.525000</td>\n",
              "      <td>2.087500</td>\n",
              "      <td>78.750000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3320.352</td>\n",
              "      <td>60.0</td>\n",
              "      <td>26.283333</td>\n",
              "      <td>2.216667</td>\n",
              "      <td>81.416667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>60.0</td>\n",
              "      <td>2993.760</td>\n",
              "      <td>60.0</td>\n",
              "      <td>25.283333</td>\n",
              "      <td>2.345833</td>\n",
              "      <td>80.375000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3166.560</td>\n",
              "      <td>60.0</td>\n",
              "      <td>25.254167</td>\n",
              "      <td>2.137500</td>\n",
              "      <td>72.875000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3050.352</td>\n",
              "      <td>60.0</td>\n",
              "      <td>26.966667</td>\n",
              "      <td>2.012500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5100 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96453b09-dd24-4c1f-9ca3-4662ff4826c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96453b09-dd24-4c1f-9ca3-4662ff4826c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96453b09-dd24-4c1f-9ca3-4662ff4826c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-58e31f7e-3ef7-469e-8d93-1a32d982c891\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58e31f7e-3ef7-469e-8d93-1a32d982c891')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-58e31f7e-3ef7-469e-8d93-1a32d982c891 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_289fa8e8-ce69-45d4-bfe8-c6d66df7b42d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('asd')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_289fa8e8-ce69-45d4-bfe8-c6d66df7b42d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('asd');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = asd['num']"
      ],
      "metadata": {
        "id": "EFZf-yzMr_WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asd.drop(columns=['num'], inplace=True)"
      ],
      "metadata": {
        "id": "1gyI1bGrs6Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#z-score로 바꿔줌\n",
        "mu = asd.mean(axis=0)\n",
        "sig = asd.std(axis=0)\n",
        "\n",
        "asd = (asd - mu)/sig"
      ],
      "metadata": {
        "id": "JWMl37slqjfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data[['num', 'temp(°C)']].mean(axis=0)"
      ],
      "metadata": {
        "id": "XMad8VKTnhBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mu data[['num', 'temp(°C)', 'wind(m/s)', 'humidity(%)', 'rain(mm)',\n",
        "#        'sunshine(hr)', 'non_elect_cool_sys', 'solar_pannel', 'month', 'day',\n",
        "#        'hour']]"
      ],
      "metadata": {
        "id": "-9w8S8DsqoWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mu = data[['num', 'temp(°C)']].mean(axis=0)\n",
        "# sig = data[['num', 'temp(°C)']].std(axis=0)\n",
        "\n",
        "# data[['num', 'temp(°C)']] = (data[['num', 'temp(°C)']] - mu)/sig"
      ],
      "metadata": {
        "id": "NXt-hyhIosGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asd = pd.concat([num, asd], axis=1)"
      ],
      "metadata": {
        "id": "kg-IYyDAr8Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asd #이게 최종 전처리된 데이터고 제일 첫번째 열 'num'은 바로 밑에줄에서 drop하기 때문에\n",
        "#첫번쨰열만 빼고 보면 됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QVavgj7utJ7i",
        "outputId": "ad7611c3-84d1-47e2-eca6-550322af3e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       num  power(kWh)      Znum  temp(°C)  wind(m/s)  humidity(%)  \\\n",
              "0      1.0    3.951721 -1.703253 -1.838402   1.071540    -1.340184   \n",
              "1      1.0    3.790377 -1.703253 -2.647819  -0.034283    -0.996812   \n",
              "2      1.0    3.911688 -1.703253 -1.004669   0.195640    -0.604919   \n",
              "3      1.0    3.999033 -1.703253 -0.976877   0.462060    -0.026411   \n",
              "4      1.0    4.213754 -1.703253 -0.579117  -0.165668    -0.780338   \n",
              "...    ...         ...       ...       ...        ...          ...   \n",
              "5095  60.0    0.812992  1.703253  0.947658  -0.056181    -0.127183   \n",
              "5096  60.0    0.919746  1.703253  0.846915   0.056956     0.111684   \n",
              "5097  60.0    0.715943  1.703253  0.430048   0.170093     0.018377   \n",
              "5098  60.0    0.823776  1.703253  0.417890  -0.012386    -0.653439   \n",
              "5099  60.0    0.751258  1.703253  1.131774  -0.121873    -0.910968   \n",
              "\n",
              "      non_elect_cool_sys  solar_pannel     month       day      week   weekend  \n",
              "0              -1.468833     -0.967109 -1.170545 -1.637897 -1.471654 -0.627189  \n",
              "1              -1.468833     -0.967109 -1.170545 -1.519512 -0.975263 -0.627189  \n",
              "2              -1.468833     -0.967109 -1.170545 -1.401126 -0.478871 -0.627189  \n",
              "3              -1.468833     -0.967109 -1.170545 -1.282741  0.017520 -0.627189  \n",
              "4              -1.468833     -0.967109 -1.170545 -1.164355  0.513911 -0.627189  \n",
              "...                  ...           ...       ...       ...       ...       ...  \n",
              "5095            0.680679      1.033807  1.348349  0.611426  0.017520 -0.627189  \n",
              "5096            0.680679      1.033807  1.348349  0.729811  0.513911 -0.627189  \n",
              "5097            0.680679      1.033807  1.348349  0.848197  1.010302  1.594104  \n",
              "5098            0.680679      1.033807  1.348349  0.966582  1.506693  1.594104  \n",
              "5099            0.680679      1.033807  1.348349  1.084968 -1.471654 -0.627189  \n",
              "\n",
              "[5100 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b75cc7d-cbbe-4b89-9a38-2e14cec4f311\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>power(kWh)</th>\n",
              "      <th>Znum</th>\n",
              "      <th>temp(°C)</th>\n",
              "      <th>wind(m/s)</th>\n",
              "      <th>humidity(%)</th>\n",
              "      <th>non_elect_cool_sys</th>\n",
              "      <th>solar_pannel</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>week</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.951721</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-1.838402</td>\n",
              "      <td>1.071540</td>\n",
              "      <td>-1.340184</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.637897</td>\n",
              "      <td>-1.471654</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.790377</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-2.647819</td>\n",
              "      <td>-0.034283</td>\n",
              "      <td>-0.996812</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.519512</td>\n",
              "      <td>-0.975263</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.911688</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-1.004669</td>\n",
              "      <td>0.195640</td>\n",
              "      <td>-0.604919</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.401126</td>\n",
              "      <td>-0.478871</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.999033</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-0.976877</td>\n",
              "      <td>0.462060</td>\n",
              "      <td>-0.026411</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.282741</td>\n",
              "      <td>0.017520</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.213754</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-0.579117</td>\n",
              "      <td>-0.165668</td>\n",
              "      <td>-0.780338</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.164355</td>\n",
              "      <td>0.513911</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.812992</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>0.947658</td>\n",
              "      <td>-0.056181</td>\n",
              "      <td>-0.127183</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.611426</td>\n",
              "      <td>0.017520</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.919746</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>0.846915</td>\n",
              "      <td>0.056956</td>\n",
              "      <td>0.111684</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.729811</td>\n",
              "      <td>0.513911</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.715943</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>0.430048</td>\n",
              "      <td>0.170093</td>\n",
              "      <td>0.018377</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.848197</td>\n",
              "      <td>1.010302</td>\n",
              "      <td>1.594104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.823776</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>0.417890</td>\n",
              "      <td>-0.012386</td>\n",
              "      <td>-0.653439</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.966582</td>\n",
              "      <td>1.506693</td>\n",
              "      <td>1.594104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.751258</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>1.131774</td>\n",
              "      <td>-0.121873</td>\n",
              "      <td>-0.910968</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>1.084968</td>\n",
              "      <td>-1.471654</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5100 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b75cc7d-cbbe-4b89-9a38-2e14cec4f311')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b75cc7d-cbbe-4b89-9a38-2e14cec4f311 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b75cc7d-cbbe-4b89-9a38-2e14cec4f311');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ce2e25b-7212-4c80-90b6-e671b5070af3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ce2e25b-7212-4c80-90b6-e671b5070af3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ce2e25b-7212-4c80-90b6-e671b5070af3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_86fb3048-ef95-44b4-964e-f2e1ee8eef7d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('asd')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_86fb3048-ef95-44b4-964e-f2e1ee8eef7d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('asd');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_num=[]\n",
        "for i in range(60):\n",
        "  split_num.append(asd[asd['num']==i+1].drop(labels='num',axis=1))"
      ],
      "metadata": {
        "id": "-C9Y1PttGRX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(split_num).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G1YV_-VoXDp",
        "outputId": "7fe3a3bf-ffc3-4255-9f06-ea66e8a56256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 85, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(split_num[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9DE73_JYl5Zr",
        "outputId": "4e6a5e8c-a627-4b9a-8fbb-861794ceb2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    power(kWh)      Znum  temp(°C)  wind(m/s)  humidity(%)  \\\n",
              "0     3.951721 -1.703253 -1.838402   1.071540    -1.340184   \n",
              "1     3.790377 -1.703253 -2.647819  -0.034283    -0.996812   \n",
              "2     3.911688 -1.703253 -1.004669   0.195640    -0.604919   \n",
              "3     3.999033 -1.703253 -0.976877   0.462060    -0.026411   \n",
              "4     4.213754 -1.703253 -0.579117  -0.165668    -0.780338   \n",
              "..         ...       ...       ...        ...          ...   \n",
              "80    4.280879 -1.703253  1.376683  -0.370045    -0.272744   \n",
              "81    4.260256 -1.703253  0.982397  -0.530626     0.246047   \n",
              "82    4.243273 -1.703253  0.061816   0.002213     0.671531   \n",
              "83    4.183830 -1.703253  0.320621  -0.194865    -0.041340   \n",
              "84    4.202431 -1.703253  1.366262   0.093452    -0.720621   \n",
              "\n",
              "    non_elect_cool_sys  solar_pannel     month       day      week   weekend  \n",
              "0            -1.468833     -0.967109 -1.170545 -1.637897 -1.471654 -0.627189  \n",
              "1            -1.468833     -0.967109 -1.170545 -1.519512 -0.975263 -0.627189  \n",
              "2            -1.468833     -0.967109 -1.170545 -1.401126 -0.478871 -0.627189  \n",
              "3            -1.468833     -0.967109 -1.170545 -1.282741  0.017520 -0.627189  \n",
              "4            -1.468833     -0.967109 -1.170545 -1.164355  0.513911 -0.627189  \n",
              "..                 ...           ...       ...       ...       ...       ...  \n",
              "80           -1.468833     -0.967109  1.348349  0.611426  0.017520 -0.627189  \n",
              "81           -1.468833     -0.967109  1.348349  0.729811  0.513911 -0.627189  \n",
              "82           -1.468833     -0.967109  1.348349  0.848197  1.010302  1.594104  \n",
              "83           -1.468833     -0.967109  1.348349  0.966582  1.506693  1.594104  \n",
              "84           -1.468833     -0.967109  1.348349  1.084968 -1.471654 -0.627189  \n",
              "\n",
              "[85 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8988286d-310f-469b-a404-1ae983238611\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>power(kWh)</th>\n",
              "      <th>Znum</th>\n",
              "      <th>temp(°C)</th>\n",
              "      <th>wind(m/s)</th>\n",
              "      <th>humidity(%)</th>\n",
              "      <th>non_elect_cool_sys</th>\n",
              "      <th>solar_pannel</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>week</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.951721</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-1.838402</td>\n",
              "      <td>1.071540</td>\n",
              "      <td>-1.340184</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.637897</td>\n",
              "      <td>-1.471654</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.790377</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-2.647819</td>\n",
              "      <td>-0.034283</td>\n",
              "      <td>-0.996812</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.519512</td>\n",
              "      <td>-0.975263</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.911688</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-1.004669</td>\n",
              "      <td>0.195640</td>\n",
              "      <td>-0.604919</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.401126</td>\n",
              "      <td>-0.478871</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.999033</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-0.976877</td>\n",
              "      <td>0.462060</td>\n",
              "      <td>-0.026411</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.282741</td>\n",
              "      <td>0.017520</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.213754</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-0.579117</td>\n",
              "      <td>-0.165668</td>\n",
              "      <td>-0.780338</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.164355</td>\n",
              "      <td>0.513911</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>4.280879</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>1.376683</td>\n",
              "      <td>-0.370045</td>\n",
              "      <td>-0.272744</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.611426</td>\n",
              "      <td>0.017520</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>4.260256</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>0.982397</td>\n",
              "      <td>-0.530626</td>\n",
              "      <td>0.246047</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.729811</td>\n",
              "      <td>0.513911</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>4.243273</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>0.061816</td>\n",
              "      <td>0.002213</td>\n",
              "      <td>0.671531</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.848197</td>\n",
              "      <td>1.010302</td>\n",
              "      <td>1.594104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>4.183830</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>0.320621</td>\n",
              "      <td>-0.194865</td>\n",
              "      <td>-0.041340</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.966582</td>\n",
              "      <td>1.506693</td>\n",
              "      <td>1.594104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>4.202431</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>1.366262</td>\n",
              "      <td>0.093452</td>\n",
              "      <td>-0.720621</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>1.084968</td>\n",
              "      <td>-1.471654</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>85 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8988286d-310f-469b-a404-1ae983238611')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8988286d-310f-469b-a404-1ae983238611 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8988286d-310f-469b-a404-1ae983238611');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-50da9d5d-bbd5-4a4d-b073-f1045f3f7649\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50da9d5d-bbd5-4a4d-b073-f1045f3f7649')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-50da9d5d-bbd5-4a4d-b073-f1045f3f7649 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.array(split_num[0])[:, 2:5]"
      ],
      "metadata": {
        "id": "KJ7utBxSmQIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asd # input에 들어가는 feature는 Znum(num이라고 부르면 됨 아래에서 Znum을 num으로 이름을 바꿈)부터 weekend까지 사용함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uHJ9N-0fqtex",
        "outputId": "110edff1-9fe6-4a60-f3c3-53a985b5ef30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       num  power(kWh)      Znum  temp(°C)  wind(m/s)  humidity(%)  \\\n",
              "0      1.0    3.951721 -1.703253 -1.838402   1.071540    -1.340184   \n",
              "1      1.0    3.790377 -1.703253 -2.647819  -0.034283    -0.996812   \n",
              "2      1.0    3.911688 -1.703253 -1.004669   0.195640    -0.604919   \n",
              "3      1.0    3.999033 -1.703253 -0.976877   0.462060    -0.026411   \n",
              "4      1.0    4.213754 -1.703253 -0.579117  -0.165668    -0.780338   \n",
              "...    ...         ...       ...       ...        ...          ...   \n",
              "5095  60.0    0.812992  1.703253  0.947658  -0.056181    -0.127183   \n",
              "5096  60.0    0.919746  1.703253  0.846915   0.056956     0.111684   \n",
              "5097  60.0    0.715943  1.703253  0.430048   0.170093     0.018377   \n",
              "5098  60.0    0.823776  1.703253  0.417890  -0.012386    -0.653439   \n",
              "5099  60.0    0.751258  1.703253  1.131774  -0.121873    -0.910968   \n",
              "\n",
              "      non_elect_cool_sys  solar_pannel     month       day      week   weekend  \n",
              "0              -1.468833     -0.967109 -1.170545 -1.637897 -1.471654 -0.627189  \n",
              "1              -1.468833     -0.967109 -1.170545 -1.519512 -0.975263 -0.627189  \n",
              "2              -1.468833     -0.967109 -1.170545 -1.401126 -0.478871 -0.627189  \n",
              "3              -1.468833     -0.967109 -1.170545 -1.282741  0.017520 -0.627189  \n",
              "4              -1.468833     -0.967109 -1.170545 -1.164355  0.513911 -0.627189  \n",
              "...                  ...           ...       ...       ...       ...       ...  \n",
              "5095            0.680679      1.033807  1.348349  0.611426  0.017520 -0.627189  \n",
              "5096            0.680679      1.033807  1.348349  0.729811  0.513911 -0.627189  \n",
              "5097            0.680679      1.033807  1.348349  0.848197  1.010302  1.594104  \n",
              "5098            0.680679      1.033807  1.348349  0.966582  1.506693  1.594104  \n",
              "5099            0.680679      1.033807  1.348349  1.084968 -1.471654 -0.627189  \n",
              "\n",
              "[5100 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24c5261a-59fc-4e72-896c-357c64014c65\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>power(kWh)</th>\n",
              "      <th>Znum</th>\n",
              "      <th>temp(°C)</th>\n",
              "      <th>wind(m/s)</th>\n",
              "      <th>humidity(%)</th>\n",
              "      <th>non_elect_cool_sys</th>\n",
              "      <th>solar_pannel</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>week</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.951721</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-1.838402</td>\n",
              "      <td>1.071540</td>\n",
              "      <td>-1.340184</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.637897</td>\n",
              "      <td>-1.471654</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.790377</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-2.647819</td>\n",
              "      <td>-0.034283</td>\n",
              "      <td>-0.996812</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.519512</td>\n",
              "      <td>-0.975263</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.911688</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-1.004669</td>\n",
              "      <td>0.195640</td>\n",
              "      <td>-0.604919</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.401126</td>\n",
              "      <td>-0.478871</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.999033</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-0.976877</td>\n",
              "      <td>0.462060</td>\n",
              "      <td>-0.026411</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.282741</td>\n",
              "      <td>0.017520</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.213754</td>\n",
              "      <td>-1.703253</td>\n",
              "      <td>-0.579117</td>\n",
              "      <td>-0.165668</td>\n",
              "      <td>-0.780338</td>\n",
              "      <td>-1.468833</td>\n",
              "      <td>-0.967109</td>\n",
              "      <td>-1.170545</td>\n",
              "      <td>-1.164355</td>\n",
              "      <td>0.513911</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.812992</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>0.947658</td>\n",
              "      <td>-0.056181</td>\n",
              "      <td>-0.127183</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.611426</td>\n",
              "      <td>0.017520</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.919746</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>0.846915</td>\n",
              "      <td>0.056956</td>\n",
              "      <td>0.111684</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.729811</td>\n",
              "      <td>0.513911</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.715943</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>0.430048</td>\n",
              "      <td>0.170093</td>\n",
              "      <td>0.018377</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.848197</td>\n",
              "      <td>1.010302</td>\n",
              "      <td>1.594104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.823776</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>0.417890</td>\n",
              "      <td>-0.012386</td>\n",
              "      <td>-0.653439</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>0.966582</td>\n",
              "      <td>1.506693</td>\n",
              "      <td>1.594104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0.751258</td>\n",
              "      <td>1.703253</td>\n",
              "      <td>1.131774</td>\n",
              "      <td>-0.121873</td>\n",
              "      <td>-0.910968</td>\n",
              "      <td>0.680679</td>\n",
              "      <td>1.033807</td>\n",
              "      <td>1.348349</td>\n",
              "      <td>1.084968</td>\n",
              "      <td>-1.471654</td>\n",
              "      <td>-0.627189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5100 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24c5261a-59fc-4e72-896c-357c64014c65')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24c5261a-59fc-4e72-896c-357c64014c65 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24c5261a-59fc-4e72-896c-357c64014c65');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5e0e0fa2-bdd8-4df2-92c3-6c5ba80afa36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e0e0fa2-bdd8-4df2-92c3-6c5ba80afa36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5e0e0fa2-bdd8-4df2-92c3-6c5ba80afa36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_148cff89-cd23-454d-8802-3130ad432e31\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('asd')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_148cff89-cd23-454d-8802-3130ad432e31 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('asd');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split_num = np.array(split_num)[:,:-14,:]"
      ],
      "metadata": {
        "id": "7tJD5mrO9LWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split_num.shape"
      ],
      "metadata": {
        "id": "jcxMlZvhMttj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이 코드는 sliding window로 데이터를 슬라이싱한 코드 window size는 1\n",
        "#쉽게 얘기해서 1~7일 데이터 1개 그다음 2~8개 데이터 1개 그다음 3~9개 데이터 1개 이렇게 만드는 코드\n",
        "#우리가 예측할건 7일에 대한 피쳐를 넣어서 7+1일에 대한 전력을 얻고 싶기 떄문에\n",
        "#y_data는 x_data index의 +1의 것을 가져옴\n",
        "#즉 x_data에서 1~7일 데이터를 쓰면 y_data는 2~8을 가져옴\n",
        "seqLength = 7\n",
        "feature_dim = 10\n",
        "split_num_count = np.array(split_num[0]).shape[0] # 한 건물당 85개씩 있음\n",
        "\n",
        "x_data = np.zeros(((split_num_count-seqLength)*60,seqLength,feature_dim))\n",
        "# xx_data = np.zeros(((split_num_count-seqLength)*60,seqLength,feature_dim))\n",
        "y_data = np.zeros(((split_num_count-seqLength)*60,seqLength))\n",
        "\n",
        "all_index = 0\n",
        "for i in range(60):\n",
        "  # split_num_feature = np.array(split_num[i])[:, 1:]\n",
        "  # split_num_power = np.array(split_num[i])[:, 0]\n",
        "  for j in range(85-seqLength):\n",
        "    split_num_feature = np.array(split_num[i])[:, 1:]\n",
        "    split_num_power = np.array(split_num[i])[:, 0]\n",
        "    x_data[all_index] = split_num_feature[j:j+seqLength, :]\n",
        "    # xx_data[all_index] = split_num_feature[j+1:j+1+seqLength, :]\n",
        "    y_data[all_index] = split_num_power[j+1:j+1+seqLength]\n",
        "    all_index += 1"
      ],
      "metadata": {
        "id": "WH9KmlXrXqfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, validaion, test 나눠줌\n",
        "np.random.seed(721)\n",
        "np.random.shuffle(x_data)\n",
        "\n",
        "np.random.seed(721)\n",
        "np.random.shuffle(y_data)\n",
        "\n",
        "x_data_train = x_data[:3880]\n",
        "x_data_val = x_data[3880:4280]\n",
        "x_data_test = x_data[4280:]\n",
        "\n",
        "y_data_train = y_data[:3880]\n",
        "y_data_val = y_data[3880:4280]\n",
        "y_data_test = y_data[4280:]"
      ],
      "metadata": {
        "id": "E0cmz7HEl5b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, validation, test 개수\n",
        "print(x_data_train.shape)\n",
        "print(y_data_train.shape)\n",
        "print('-------------------')\n",
        "print(x_data_val.shape)\n",
        "print(y_data_val.shape)\n",
        "print('-------------------')\n",
        "print(x_data_test.shape)\n",
        "print(y_data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RWWuZNBbQXl",
        "outputId": "f0c0732e-2b84-42af-f7d0-a3f484c6ab63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3880, 7, 10)\n",
            "(3880, 7)\n",
            "-------------------\n",
            "(400, 7, 10)\n",
            "(400, 7)\n",
            "-------------------\n",
            "(400, 7, 10)\n",
            "(400, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#-------"
      ],
      "metadata": {
        "id": "T8YMXIypqnMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#에포크마다 모델을 저장하고 loss를 기록한 csv 저장을 위한 코드\n",
        "root = '/content/drive/MyDrive/ai_project_2/transformer_model_save/'\n",
        "folder_name = '20231214_1999-1modelsave'\n",
        "os.mkdir(root+folder_name)\n",
        "csv_logger = CSVLogger(root+folder_name+'/training.csv', separator=\",\", append=True)\n",
        "mcp_save_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "    root+folder_name+'/{epoch:02d}-{val_loss:.5f}_best', save_best_only=True,\n",
        "    monitor='val_loss', verbose=1, mode='min')\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint(\n",
        "    root+folder_name+'/{epoch:02d}-{val_loss:.5f}', save_best_only=False,\n",
        "    monitor='val_loss', verbose=1, mode='min')"
      ],
      "metadata": {
        "id": "ue9iurDpqFGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 코드\n",
        "input = keras.Input((7,10),name='input') # input time series length, feature dimension\n",
        "x = keras.layers.MultiHeadAttention(num_heads=16, key_dim=1, dropout=0.1, name='MHA')(input, input, return_attention_scores=False)\n",
        "x = x + input\n",
        "x = keras.layers.LayerNormalization(name='LN1')(x)\n",
        "x2 = keras.layers.Dense(10, name='Dense1',activation='relu')(x)\n",
        "x2 = x + x2\n",
        "x3 = keras.layers.LayerNormalization(name='LN2')(x2)\n",
        "x3 = tf.transpose(x3, perm=[0,2,1])\n",
        "output = keras.layers.GlobalAveragePooling1D()(x3)\n",
        "\n",
        "myMdl = keras.Model(input,output, name='myMdl')\n",
        "myMdl.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DyKFLUpp8FR",
        "outputId": "65c80730-cb0d-47c8-92b8-8f60e0670db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"myMdl\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input (InputLayer)          [(None, 7, 10)]              0         []                            \n",
            "                                                                                                  \n",
            " MHA (MultiHeadAttention)    (None, 7, 10)                698       ['input[0][0]',               \n",
            "                                                                     'input[0][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TF  (None, 7, 10)                0         ['MHA[0][0]',                 \n",
            " OpLambda)                                                           'input[0][0]']               \n",
            "                                                                                                  \n",
            " LN1 (LayerNormalization)    (None, 7, 10)                20        ['tf.__operators__.add_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " Dense1 (Dense)              (None, 7, 10)                110       ['LN1[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_9 (TF  (None, 7, 10)                0         ['LN1[0][0]',                 \n",
            " OpLambda)                                                           'Dense1[0][0]']              \n",
            "                                                                                                  \n",
            " LN2 (LayerNormalization)    (None, 7, 10)                20        ['tf.__operators__.add_9[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_4 (  (None, 10, 7)                0         ['LN2[0][0]']                 \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " global_average_pooling1d_4  (None, 7)                    0         ['tf.compat.v1.transpose_4[0][\n",
            "  (GlobalAveragePooling1D)                                          0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 848 (3.31 KB)\n",
            "Trainable params: 848 (3.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#총 268에포크 돌림\n",
        "myMdl.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-2),\n",
        "              loss=[keras.losses.MSE], metrics=[keras.losses.MAE])\n",
        "\n",
        "history = myMdl.fit(x_data_train, y_data_train, batch_size=64, epochs=9999999, validation_data=(x_data_val,y_data_val), callbacks=[mcp_save_best, mcp_save, csv_logger])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fYLINPqqLuR",
        "outputId": "ea0e399e-8657-4fe5-b348-6a5d46bc21c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.9852 - mean_absolute_error: 0.7080\n",
            "Epoch 1: val_loss improved from inf to 0.91765, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/01-0.91765_best\n",
            "\n",
            "Epoch 1: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/01-0.91765\n",
            "61/61 [==============================] - 8s 79ms/step - loss: 0.9752 - mean_absolute_error: 0.7057 - val_loss: 0.9177 - val_mean_absolute_error: 0.6695\n",
            "Epoch 2/9999999\n",
            "53/61 [=========================>....] - ETA: 0s - loss: 0.9212 - mean_absolute_error: 0.6751\n",
            "Epoch 2: val_loss improved from 0.91765 to 0.84789, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/02-0.84789_best\n",
            "\n",
            "Epoch 2: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/02-0.84789\n",
            "61/61 [==============================] - 3s 51ms/step - loss: 0.9121 - mean_absolute_error: 0.6744 - val_loss: 0.8479 - val_mean_absolute_error: 0.6598\n",
            "Epoch 3/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.8503 - mean_absolute_error: 0.6514\n",
            "Epoch 3: val_loss improved from 0.84789 to 0.75115, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/03-0.75115_best\n",
            "\n",
            "Epoch 3: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/03-0.75115\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.8415 - mean_absolute_error: 0.6485 - val_loss: 0.7512 - val_mean_absolute_error: 0.6097\n",
            "Epoch 4/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.7589 - mean_absolute_error: 0.6111\n",
            "Epoch 4: val_loss improved from 0.75115 to 0.71062, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/04-0.71062_best\n",
            "\n",
            "Epoch 4: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/04-0.71062\n",
            "61/61 [==============================] - 4s 60ms/step - loss: 0.7536 - mean_absolute_error: 0.6105 - val_loss: 0.7106 - val_mean_absolute_error: 0.5966\n",
            "Epoch 5/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.6539 - mean_absolute_error: 0.5746\n",
            "Epoch 5: val_loss improved from 0.71062 to 0.62914, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/05-0.62914_best\n",
            "\n",
            "Epoch 5: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/05-0.62914\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6586 - mean_absolute_error: 0.5758 - val_loss: 0.6291 - val_mean_absolute_error: 0.5621\n",
            "Epoch 6/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.6020 - mean_absolute_error: 0.5585\n",
            "Epoch 6: val_loss improved from 0.62914 to 0.58807, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/06-0.58807_best\n",
            "\n",
            "Epoch 6: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/06-0.58807\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.5956 - mean_absolute_error: 0.5553 - val_loss: 0.5881 - val_mean_absolute_error: 0.5362\n",
            "Epoch 7/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.5411 - mean_absolute_error: 0.5333\n",
            "Epoch 7: val_loss improved from 0.58807 to 0.55215, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/07-0.55215_best\n",
            "\n",
            "Epoch 7: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/07-0.55215\n",
            "61/61 [==============================] - 3s 51ms/step - loss: 0.5400 - mean_absolute_error: 0.5321 - val_loss: 0.5521 - val_mean_absolute_error: 0.5196\n",
            "Epoch 8/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.4887 - mean_absolute_error: 0.5145\n",
            "Epoch 8: val_loss improved from 0.55215 to 0.51692, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/08-0.51692_best\n",
            "\n",
            "Epoch 8: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/08-0.51692\n",
            "61/61 [==============================] - 3s 56ms/step - loss: 0.4887 - mean_absolute_error: 0.5145 - val_loss: 0.5169 - val_mean_absolute_error: 0.4969\n",
            "Epoch 9/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.4662 - mean_absolute_error: 0.5011\n",
            "Epoch 9: val_loss improved from 0.51692 to 0.49086, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/09-0.49086_best\n",
            "\n",
            "Epoch 9: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/09-0.49086\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4613 - mean_absolute_error: 0.4992 - val_loss: 0.4909 - val_mean_absolute_error: 0.4991\n",
            "Epoch 10/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.4409 - mean_absolute_error: 0.4885\n",
            "Epoch 10: val_loss improved from 0.49086 to 0.47468, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/10-0.47468_best\n",
            "\n",
            "Epoch 10: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/10-0.47468\n",
            "61/61 [==============================] - 3s 54ms/step - loss: 0.4388 - mean_absolute_error: 0.4862 - val_loss: 0.4747 - val_mean_absolute_error: 0.4991\n",
            "Epoch 11/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.4225 - mean_absolute_error: 0.4812\n",
            "Epoch 11: val_loss improved from 0.47468 to 0.46451, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/11-0.46451_best\n",
            "\n",
            "Epoch 11: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/11-0.46451\n",
            "61/61 [==============================] - 3s 51ms/step - loss: 0.4275 - mean_absolute_error: 0.4830 - val_loss: 0.4645 - val_mean_absolute_error: 0.4922\n",
            "Epoch 12/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.4101 - mean_absolute_error: 0.4742\n",
            "Epoch 12: val_loss did not improve from 0.46451\n",
            "\n",
            "Epoch 12: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/12-0.46992\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.4101 - mean_absolute_error: 0.4742 - val_loss: 0.4699 - val_mean_absolute_error: 0.4839\n",
            "Epoch 13/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.3959 - mean_absolute_error: 0.4643\n",
            "Epoch 13: val_loss improved from 0.46451 to 0.44673, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/13-0.44673_best\n",
            "\n",
            "Epoch 13: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/13-0.44673\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3965 - mean_absolute_error: 0.4645 - val_loss: 0.4467 - val_mean_absolute_error: 0.4746\n",
            "Epoch 14/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.3797 - mean_absolute_error: 0.4549\n",
            "Epoch 14: val_loss improved from 0.44673 to 0.44486, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/14-0.44486_best\n",
            "\n",
            "Epoch 14: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/14-0.44486\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.3830 - mean_absolute_error: 0.4561 - val_loss: 0.4449 - val_mean_absolute_error: 0.4816\n",
            "Epoch 15/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.3790 - mean_absolute_error: 0.4534\n",
            "Epoch 15: val_loss did not improve from 0.44486\n",
            "\n",
            "Epoch 15: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/15-0.46768\n",
            "61/61 [==============================] - 3s 42ms/step - loss: 0.3778 - mean_absolute_error: 0.4533 - val_loss: 0.4677 - val_mean_absolute_error: 0.4712\n",
            "Epoch 16/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.3735 - mean_absolute_error: 0.4482\n",
            "Epoch 16: val_loss did not improve from 0.44486\n",
            "\n",
            "Epoch 16: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/16-0.45512\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.3760 - mean_absolute_error: 0.4500 - val_loss: 0.4551 - val_mean_absolute_error: 0.4828\n",
            "Epoch 17/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.3727 - mean_absolute_error: 0.4489\n",
            "Epoch 17: val_loss improved from 0.44486 to 0.42091, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/17-0.42091_best\n",
            "\n",
            "Epoch 17: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/17-0.42091\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.3727 - mean_absolute_error: 0.4489 - val_loss: 0.4209 - val_mean_absolute_error: 0.4612\n",
            "Epoch 18/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.3535 - mean_absolute_error: 0.4398\n",
            "Epoch 18: val_loss improved from 0.42091 to 0.41951, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/18-0.41951_best\n",
            "\n",
            "Epoch 18: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/18-0.41951\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.3542 - mean_absolute_error: 0.4399 - val_loss: 0.4195 - val_mean_absolute_error: 0.4548\n",
            "Epoch 19/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.3550 - mean_absolute_error: 0.4370\n",
            "Epoch 19: val_loss did not improve from 0.41951\n",
            "\n",
            "Epoch 19: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/19-0.43651\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.3543 - mean_absolute_error: 0.4369 - val_loss: 0.4365 - val_mean_absolute_error: 0.4562\n",
            "Epoch 20/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.3446 - mean_absolute_error: 0.4321\n",
            "Epoch 20: val_loss did not improve from 0.41951\n",
            "\n",
            "Epoch 20: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/20-0.42295\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.3459 - mean_absolute_error: 0.4327 - val_loss: 0.4230 - val_mean_absolute_error: 0.4551\n",
            "Epoch 21/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.3333 - mean_absolute_error: 0.4263\n",
            "Epoch 21: val_loss did not improve from 0.41951\n",
            "\n",
            "Epoch 21: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/21-0.42574\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.3363 - mean_absolute_error: 0.4282 - val_loss: 0.4257 - val_mean_absolute_error: 0.4537\n",
            "Epoch 22/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.3286 - mean_absolute_error: 0.4200\n",
            "Epoch 22: val_loss improved from 0.41951 to 0.40753, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/22-0.40753_best\n",
            "\n",
            "Epoch 22: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/22-0.40753\n",
            "61/61 [==============================] - 4s 66ms/step - loss: 0.3314 - mean_absolute_error: 0.4213 - val_loss: 0.4075 - val_mean_absolute_error: 0.4367\n",
            "Epoch 23/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.3290 - mean_absolute_error: 0.4196\n",
            "Epoch 23: val_loss improved from 0.40753 to 0.40002, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/23-0.40002_best\n",
            "\n",
            "Epoch 23: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/23-0.40002\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.3244 - mean_absolute_error: 0.4183 - val_loss: 0.4000 - val_mean_absolute_error: 0.4306\n",
            "Epoch 24/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.3186 - mean_absolute_error: 0.4126\n",
            "Epoch 24: val_loss improved from 0.40002 to 0.39236, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/24-0.39236_best\n",
            "\n",
            "Epoch 24: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/24-0.39236\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.3159 - mean_absolute_error: 0.4119 - val_loss: 0.3924 - val_mean_absolute_error: 0.4385\n",
            "Epoch 25/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.3207 - mean_absolute_error: 0.4132\n",
            "Epoch 25: val_loss did not improve from 0.39236\n",
            "\n",
            "Epoch 25: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/25-0.42028\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.3194 - mean_absolute_error: 0.4125 - val_loss: 0.4203 - val_mean_absolute_error: 0.4445\n",
            "Epoch 26/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.3165 - mean_absolute_error: 0.4096\n",
            "Epoch 26: val_loss improved from 0.39236 to 0.38969, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/26-0.38969_best\n",
            "\n",
            "Epoch 26: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/26-0.38969\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.3143 - mean_absolute_error: 0.4082 - val_loss: 0.3897 - val_mean_absolute_error: 0.4294\n",
            "Epoch 27/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.3120 - mean_absolute_error: 0.4072\n",
            "Epoch 27: val_loss did not improve from 0.38969\n",
            "\n",
            "Epoch 27: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/27-0.39856\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.3109 - mean_absolute_error: 0.4051 - val_loss: 0.3986 - val_mean_absolute_error: 0.4325\n",
            "Epoch 28/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.3020 - mean_absolute_error: 0.4004\n",
            "Epoch 28: val_loss improved from 0.38969 to 0.38461, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/28-0.38461_best\n",
            "\n",
            "Epoch 28: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/28-0.38461\n",
            "61/61 [==============================] - 4s 58ms/step - loss: 0.3041 - mean_absolute_error: 0.4013 - val_loss: 0.3846 - val_mean_absolute_error: 0.4239\n",
            "Epoch 29/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2969 - mean_absolute_error: 0.3964\n",
            "Epoch 29: val_loss improved from 0.38461 to 0.33954, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/29-0.33954_best\n",
            "\n",
            "Epoch 29: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/29-0.33954\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.2969 - mean_absolute_error: 0.3964 - val_loss: 0.3395 - val_mean_absolute_error: 0.4099\n",
            "Epoch 30/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2879 - mean_absolute_error: 0.3878\n",
            "Epoch 30: val_loss improved from 0.33954 to 0.32542, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/30-0.32542_best\n",
            "\n",
            "Epoch 30: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/30-0.32542\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.2920 - mean_absolute_error: 0.3912 - val_loss: 0.3254 - val_mean_absolute_error: 0.4044\n",
            "Epoch 31/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.2798 - mean_absolute_error: 0.3833\n",
            "Epoch 31: val_loss did not improve from 0.32542\n",
            "\n",
            "Epoch 31: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/31-0.32746\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.2797 - mean_absolute_error: 0.3826 - val_loss: 0.3275 - val_mean_absolute_error: 0.3862\n",
            "Epoch 32/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.2838 - mean_absolute_error: 0.3821\n",
            "Epoch 32: val_loss improved from 0.32542 to 0.30627, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/32-0.30627_best\n",
            "\n",
            "Epoch 32: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/32-0.30627\n",
            "61/61 [==============================] - 3s 55ms/step - loss: 0.2829 - mean_absolute_error: 0.3818 - val_loss: 0.3063 - val_mean_absolute_error: 0.3817\n",
            "Epoch 33/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2632 - mean_absolute_error: 0.3677\n",
            "Epoch 33: val_loss improved from 0.30627 to 0.29434, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/33-0.29434_best\n",
            "\n",
            "Epoch 33: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/33-0.29434\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 0.2644 - mean_absolute_error: 0.3683 - val_loss: 0.2943 - val_mean_absolute_error: 0.3733\n",
            "Epoch 34/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2604 - mean_absolute_error: 0.3641\n",
            "Epoch 34: val_loss improved from 0.29434 to 0.28622, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/34-0.28622_best\n",
            "\n",
            "Epoch 34: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/34-0.28622\n",
            "61/61 [==============================] - 4s 61ms/step - loss: 0.2604 - mean_absolute_error: 0.3641 - val_loss: 0.2862 - val_mean_absolute_error: 0.3675\n",
            "Epoch 35/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.2645 - mean_absolute_error: 0.3684\n",
            "Epoch 35: val_loss improved from 0.28622 to 0.27372, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/35-0.27372_best\n",
            "\n",
            "Epoch 35: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/35-0.27372\n",
            "61/61 [==============================] - 4s 66ms/step - loss: 0.2627 - mean_absolute_error: 0.3684 - val_loss: 0.2737 - val_mean_absolute_error: 0.3520\n",
            "Epoch 36/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2549 - mean_absolute_error: 0.3599\n",
            "Epoch 36: val_loss did not improve from 0.27372\n",
            "\n",
            "Epoch 36: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/36-0.28137\n",
            "61/61 [==============================] - 2s 29ms/step - loss: 0.2552 - mean_absolute_error: 0.3603 - val_loss: 0.2814 - val_mean_absolute_error: 0.3591\n",
            "Epoch 37/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.2552 - mean_absolute_error: 0.3602\n",
            "Epoch 37: val_loss improved from 0.27372 to 0.26326, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/37-0.26326_best\n",
            "\n",
            "Epoch 37: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/37-0.26326\n",
            "61/61 [==============================] - 4s 59ms/step - loss: 0.2545 - mean_absolute_error: 0.3598 - val_loss: 0.2633 - val_mean_absolute_error: 0.3424\n",
            "Epoch 38/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.2486 - mean_absolute_error: 0.3552\n",
            "Epoch 38: val_loss improved from 0.26326 to 0.26117, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/38-0.26117_best\n",
            "\n",
            "Epoch 38: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/38-0.26117\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 0.2478 - mean_absolute_error: 0.3541 - val_loss: 0.2612 - val_mean_absolute_error: 0.3439\n",
            "Epoch 39/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2355 - mean_absolute_error: 0.3444\n",
            "Epoch 39: val_loss improved from 0.26117 to 0.25088, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/39-0.25088_best\n",
            "\n",
            "Epoch 39: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/39-0.25088\n",
            "61/61 [==============================] - 3s 51ms/step - loss: 0.2404 - mean_absolute_error: 0.3468 - val_loss: 0.2509 - val_mean_absolute_error: 0.3361\n",
            "Epoch 40/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2375 - mean_absolute_error: 0.3470\n",
            "Epoch 40: val_loss improved from 0.25088 to 0.24770, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/40-0.24770_best\n",
            "\n",
            "Epoch 40: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/40-0.24770\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.2394 - mean_absolute_error: 0.3477 - val_loss: 0.2477 - val_mean_absolute_error: 0.3426\n",
            "Epoch 41/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.2360 - mean_absolute_error: 0.3456\n",
            "Epoch 41: val_loss improved from 0.24770 to 0.23892, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/41-0.23892_best\n",
            "\n",
            "Epoch 41: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/41-0.23892\n",
            "61/61 [==============================] - 3s 54ms/step - loss: 0.2369 - mean_absolute_error: 0.3456 - val_loss: 0.2389 - val_mean_absolute_error: 0.3345\n",
            "Epoch 42/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2398 - mean_absolute_error: 0.3491\n",
            "Epoch 42: val_loss did not improve from 0.23892\n",
            "\n",
            "Epoch 42: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/42-0.24430\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.2398 - mean_absolute_error: 0.3491 - val_loss: 0.2443 - val_mean_absolute_error: 0.3268\n",
            "Epoch 43/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2283 - mean_absolute_error: 0.3417\n",
            "Epoch 43: val_loss did not improve from 0.23892\n",
            "\n",
            "Epoch 43: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/43-0.24358\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.2283 - mean_absolute_error: 0.3417 - val_loss: 0.2436 - val_mean_absolute_error: 0.3425\n",
            "Epoch 44/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2260 - mean_absolute_error: 0.3392\n",
            "Epoch 44: val_loss improved from 0.23892 to 0.23097, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/44-0.23097_best\n",
            "\n",
            "Epoch 44: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/44-0.23097\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.2272 - mean_absolute_error: 0.3404 - val_loss: 0.2310 - val_mean_absolute_error: 0.3273\n",
            "Epoch 45/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.2275 - mean_absolute_error: 0.3396\n",
            "Epoch 45: val_loss did not improve from 0.23097\n",
            "\n",
            "Epoch 45: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/45-0.23798\n",
            "61/61 [==============================] - 2s 29ms/step - loss: 0.2276 - mean_absolute_error: 0.3395 - val_loss: 0.2380 - val_mean_absolute_error: 0.3289\n",
            "Epoch 46/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2238 - mean_absolute_error: 0.3381\n",
            "Epoch 46: val_loss improved from 0.23097 to 0.22680, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/46-0.22680_best\n",
            "\n",
            "Epoch 46: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/46-0.22680\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.2265 - mean_absolute_error: 0.3395 - val_loss: 0.2268 - val_mean_absolute_error: 0.3375\n",
            "Epoch 47/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2168 - mean_absolute_error: 0.3353\n",
            "Epoch 47: val_loss improved from 0.22680 to 0.22649, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/47-0.22649_best\n",
            "\n",
            "Epoch 47: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/47-0.22649\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.2177 - mean_absolute_error: 0.3351 - val_loss: 0.2265 - val_mean_absolute_error: 0.3332\n",
            "Epoch 48/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.2129 - mean_absolute_error: 0.3334\n",
            "Epoch 48: val_loss improved from 0.22649 to 0.21927, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/48-0.21927_best\n",
            "\n",
            "Epoch 48: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/48-0.21927\n",
            "61/61 [==============================] - 4s 62ms/step - loss: 0.2143 - mean_absolute_error: 0.3339 - val_loss: 0.2193 - val_mean_absolute_error: 0.3191\n",
            "Epoch 49/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.2146 - mean_absolute_error: 0.3333\n",
            "Epoch 49: val_loss improved from 0.21927 to 0.21374, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/49-0.21374_best\n",
            "\n",
            "Epoch 49: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/49-0.21374\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.2145 - mean_absolute_error: 0.3332 - val_loss: 0.2137 - val_mean_absolute_error: 0.3215\n",
            "Epoch 50/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.2100 - mean_absolute_error: 0.3268\n",
            "Epoch 50: val_loss improved from 0.21374 to 0.20739, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/50-0.20739_best\n",
            "\n",
            "Epoch 50: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/50-0.20739\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.2108 - mean_absolute_error: 0.3279 - val_loss: 0.2074 - val_mean_absolute_error: 0.3192\n",
            "Epoch 51/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.2092 - mean_absolute_error: 0.3296\n",
            "Epoch 51: val_loss did not improve from 0.20739\n",
            "\n",
            "Epoch 51: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/51-0.21061\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.2093 - mean_absolute_error: 0.3298 - val_loss: 0.2106 - val_mean_absolute_error: 0.3219\n",
            "Epoch 52/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.2064 - mean_absolute_error: 0.3279\n",
            "Epoch 52: val_loss did not improve from 0.20739\n",
            "\n",
            "Epoch 52: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/52-0.21030\n",
            "61/61 [==============================] - 3s 43ms/step - loss: 0.2057 - mean_absolute_error: 0.3275 - val_loss: 0.2103 - val_mean_absolute_error: 0.3201\n",
            "Epoch 53/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2050 - mean_absolute_error: 0.3253\n",
            "Epoch 53: val_loss did not improve from 0.20739\n",
            "\n",
            "Epoch 53: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/53-0.21526\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.2050 - mean_absolute_error: 0.3253 - val_loss: 0.2153 - val_mean_absolute_error: 0.3218\n",
            "Epoch 54/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.2091 - mean_absolute_error: 0.3298\n",
            "Epoch 54: val_loss improved from 0.20739 to 0.20230, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/54-0.20230_best\n",
            "\n",
            "Epoch 54: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/54-0.20230\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.2077 - mean_absolute_error: 0.3313 - val_loss: 0.2023 - val_mean_absolute_error: 0.3161\n",
            "Epoch 55/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.2039 - mean_absolute_error: 0.3272\n",
            "Epoch 55: val_loss did not improve from 0.20230\n",
            "\n",
            "Epoch 55: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/55-0.20763\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.2038 - mean_absolute_error: 0.3272 - val_loss: 0.2076 - val_mean_absolute_error: 0.3139\n",
            "Epoch 56/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1983 - mean_absolute_error: 0.3232\n",
            "Epoch 56: val_loss did not improve from 0.20230\n",
            "\n",
            "Epoch 56: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/56-0.20247\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1988 - mean_absolute_error: 0.3237 - val_loss: 0.2025 - val_mean_absolute_error: 0.3180\n",
            "Epoch 57/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1945 - mean_absolute_error: 0.3215\n",
            "Epoch 57: val_loss improved from 0.20230 to 0.18680, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/57-0.18680_best\n",
            "\n",
            "Epoch 57: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/57-0.18680\n",
            "61/61 [==============================] - 4s 59ms/step - loss: 0.1947 - mean_absolute_error: 0.3214 - val_loss: 0.1868 - val_mean_absolute_error: 0.3183\n",
            "Epoch 58/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1898 - mean_absolute_error: 0.3186\n",
            "Epoch 58: val_loss did not improve from 0.18680\n",
            "\n",
            "Epoch 58: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/58-0.20163\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.1892 - mean_absolute_error: 0.3181 - val_loss: 0.2016 - val_mean_absolute_error: 0.3243\n",
            "Epoch 59/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1974 - mean_absolute_error: 0.3247\n",
            "Epoch 59: val_loss improved from 0.18680 to 0.17599, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/59-0.17599_best\n",
            "\n",
            "Epoch 59: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/59-0.17599\n",
            "61/61 [==============================] - 4s 61ms/step - loss: 0.1970 - mean_absolute_error: 0.3243 - val_loss: 0.1760 - val_mean_absolute_error: 0.3037\n",
            "Epoch 60/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1833 - mean_absolute_error: 0.3145\n",
            "Epoch 60: val_loss did not improve from 0.17599\n",
            "\n",
            "Epoch 60: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/60-0.18302\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1829 - mean_absolute_error: 0.3148 - val_loss: 0.1830 - val_mean_absolute_error: 0.3086\n",
            "Epoch 61/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.1789 - mean_absolute_error: 0.3107\n",
            "Epoch 61: val_loss improved from 0.17599 to 0.16154, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/61-0.16154_best\n",
            "\n",
            "Epoch 61: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/61-0.16154\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.1811 - mean_absolute_error: 0.3124 - val_loss: 0.1615 - val_mean_absolute_error: 0.2968\n",
            "Epoch 62/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1760 - mean_absolute_error: 0.3084\n",
            "Epoch 62: val_loss did not improve from 0.16154\n",
            "\n",
            "Epoch 62: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/62-0.16724\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.1796 - mean_absolute_error: 0.3108 - val_loss: 0.1672 - val_mean_absolute_error: 0.3048\n",
            "Epoch 63/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1741 - mean_absolute_error: 0.3081\n",
            "Epoch 63: val_loss improved from 0.16154 to 0.15911, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/63-0.15911_best\n",
            "\n",
            "Epoch 63: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/63-0.15911\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.1753 - mean_absolute_error: 0.3090 - val_loss: 0.1591 - val_mean_absolute_error: 0.2986\n",
            "Epoch 64/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1737 - mean_absolute_error: 0.3073\n",
            "Epoch 64: val_loss improved from 0.15911 to 0.15042, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/64-0.15042_best\n",
            "\n",
            "Epoch 64: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/64-0.15042\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.1737 - mean_absolute_error: 0.3073 - val_loss: 0.1504 - val_mean_absolute_error: 0.2927\n",
            "Epoch 65/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1741 - mean_absolute_error: 0.3075\n",
            "Epoch 65: val_loss did not improve from 0.15042\n",
            "\n",
            "Epoch 65: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/65-0.15153\n",
            "61/61 [==============================] - 2s 29ms/step - loss: 0.1739 - mean_absolute_error: 0.3072 - val_loss: 0.1515 - val_mean_absolute_error: 0.2893\n",
            "Epoch 66/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1780 - mean_absolute_error: 0.3085\n",
            "Epoch 66: val_loss did not improve from 0.15042\n",
            "\n",
            "Epoch 66: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/66-0.16673\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1776 - mean_absolute_error: 0.3091 - val_loss: 0.1667 - val_mean_absolute_error: 0.3015\n",
            "Epoch 67/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1636 - mean_absolute_error: 0.2972\n",
            "Epoch 67: val_loss improved from 0.15042 to 0.14884, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/67-0.14884_best\n",
            "\n",
            "Epoch 67: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/67-0.14884\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.1647 - mean_absolute_error: 0.2975 - val_loss: 0.1488 - val_mean_absolute_error: 0.2841\n",
            "Epoch 68/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1691 - mean_absolute_error: 0.3011\n",
            "Epoch 68: val_loss improved from 0.14884 to 0.14283, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/68-0.14283_best\n",
            "\n",
            "Epoch 68: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/68-0.14283\n",
            "61/61 [==============================] - 5s 76ms/step - loss: 0.1687 - mean_absolute_error: 0.3009 - val_loss: 0.1428 - val_mean_absolute_error: 0.2785\n",
            "Epoch 69/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1608 - mean_absolute_error: 0.2952\n",
            "Epoch 69: val_loss did not improve from 0.14283\n",
            "\n",
            "Epoch 69: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/69-0.15326\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.1608 - mean_absolute_error: 0.2952 - val_loss: 0.1533 - val_mean_absolute_error: 0.2959\n",
            "Epoch 70/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1642 - mean_absolute_error: 0.2975\n",
            "Epoch 70: val_loss did not improve from 0.14283\n",
            "\n",
            "Epoch 70: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/70-0.14349\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.1643 - mean_absolute_error: 0.2976 - val_loss: 0.1435 - val_mean_absolute_error: 0.2857\n",
            "Epoch 71/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1569 - mean_absolute_error: 0.2926\n",
            "Epoch 71: val_loss did not improve from 0.14283\n",
            "\n",
            "Epoch 71: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/71-0.14657\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1598 - mean_absolute_error: 0.2946 - val_loss: 0.1466 - val_mean_absolute_error: 0.2835\n",
            "Epoch 72/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1606 - mean_absolute_error: 0.2942\n",
            "Epoch 72: val_loss did not improve from 0.14283\n",
            "\n",
            "Epoch 72: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/72-0.14462\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.1606 - mean_absolute_error: 0.2942 - val_loss: 0.1446 - val_mean_absolute_error: 0.2860\n",
            "Epoch 73/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1631 - mean_absolute_error: 0.2960\n",
            "Epoch 73: val_loss improved from 0.14283 to 0.13740, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/73-0.13740_best\n",
            "\n",
            "Epoch 73: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/73-0.13740\n",
            "61/61 [==============================] - 5s 91ms/step - loss: 0.1631 - mean_absolute_error: 0.2960 - val_loss: 0.1374 - val_mean_absolute_error: 0.2810\n",
            "Epoch 74/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1582 - mean_absolute_error: 0.2931\n",
            "Epoch 74: val_loss did not improve from 0.13740\n",
            "\n",
            "Epoch 74: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/74-0.14526\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.1551 - mean_absolute_error: 0.2901 - val_loss: 0.1453 - val_mean_absolute_error: 0.2814\n",
            "Epoch 75/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.1500 - mean_absolute_error: 0.2835\n",
            "Epoch 75: val_loss did not improve from 0.13740\n",
            "\n",
            "Epoch 75: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/75-0.13766\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1538 - mean_absolute_error: 0.2875 - val_loss: 0.1377 - val_mean_absolute_error: 0.2776\n",
            "Epoch 76/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1481 - mean_absolute_error: 0.2831\n",
            "Epoch 76: val_loss improved from 0.13740 to 0.13162, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/76-0.13162_best\n",
            "\n",
            "Epoch 76: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/76-0.13162\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.1486 - mean_absolute_error: 0.2831 - val_loss: 0.1316 - val_mean_absolute_error: 0.2661\n",
            "Epoch 77/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1422 - mean_absolute_error: 0.2794\n",
            "Epoch 77: val_loss did not improve from 0.13162\n",
            "\n",
            "Epoch 77: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/77-0.13324\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1444 - mean_absolute_error: 0.2809 - val_loss: 0.1332 - val_mean_absolute_error: 0.2697\n",
            "Epoch 78/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1431 - mean_absolute_error: 0.2777\n",
            "Epoch 78: val_loss did not improve from 0.13162\n",
            "\n",
            "Epoch 78: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/78-0.13881\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1431 - mean_absolute_error: 0.2777 - val_loss: 0.1388 - val_mean_absolute_error: 0.2723\n",
            "Epoch 79/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1415 - mean_absolute_error: 0.2757\n",
            "Epoch 79: val_loss improved from 0.13162 to 0.12959, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/79-0.12959_best\n",
            "\n",
            "Epoch 79: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/79-0.12959\n",
            "61/61 [==============================] - 4s 65ms/step - loss: 0.1415 - mean_absolute_error: 0.2756 - val_loss: 0.1296 - val_mean_absolute_error: 0.2672\n",
            "Epoch 80/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1434 - mean_absolute_error: 0.2774\n",
            "Epoch 80: val_loss did not improve from 0.12959\n",
            "\n",
            "Epoch 80: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/80-0.13461\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.1437 - mean_absolute_error: 0.2777 - val_loss: 0.1346 - val_mean_absolute_error: 0.2757\n",
            "Epoch 81/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.1431 - mean_absolute_error: 0.2789\n",
            "Epoch 81: val_loss did not improve from 0.12959\n",
            "\n",
            "Epoch 81: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/81-0.14087\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1422 - mean_absolute_error: 0.2779 - val_loss: 0.1409 - val_mean_absolute_error: 0.2758\n",
            "Epoch 82/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1379 - mean_absolute_error: 0.2731\n",
            "Epoch 82: val_loss did not improve from 0.12959\n",
            "\n",
            "Epoch 82: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/82-0.13651\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1372 - mean_absolute_error: 0.2723 - val_loss: 0.1365 - val_mean_absolute_error: 0.2684\n",
            "Epoch 83/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1406 - mean_absolute_error: 0.2755\n",
            "Epoch 83: val_loss improved from 0.12959 to 0.12501, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/83-0.12501_best\n",
            "\n",
            "Epoch 83: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/83-0.12501\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.1404 - mean_absolute_error: 0.2756 - val_loss: 0.1250 - val_mean_absolute_error: 0.2606\n",
            "Epoch 84/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1405 - mean_absolute_error: 0.2751\n",
            "Epoch 84: val_loss did not improve from 0.12501\n",
            "\n",
            "Epoch 84: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/84-0.14009\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1397 - mean_absolute_error: 0.2747 - val_loss: 0.1401 - val_mean_absolute_error: 0.2768\n",
            "Epoch 85/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.1375 - mean_absolute_error: 0.2716\n",
            "Epoch 85: val_loss did not improve from 0.12501\n",
            "\n",
            "Epoch 85: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/85-0.13153\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.1389 - mean_absolute_error: 0.2723 - val_loss: 0.1315 - val_mean_absolute_error: 0.2657\n",
            "Epoch 86/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1339 - mean_absolute_error: 0.2689\n",
            "Epoch 86: val_loss did not improve from 0.12501\n",
            "\n",
            "Epoch 86: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/86-0.13270\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 0.1341 - mean_absolute_error: 0.2690 - val_loss: 0.1327 - val_mean_absolute_error: 0.2643\n",
            "Epoch 87/9999999\n",
            "53/61 [=========================>....] - ETA: 0s - loss: 0.1324 - mean_absolute_error: 0.2672\n",
            "Epoch 87: val_loss did not improve from 0.12501\n",
            "\n",
            "Epoch 87: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/87-0.12676\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.1321 - mean_absolute_error: 0.2671 - val_loss: 0.1268 - val_mean_absolute_error: 0.2560\n",
            "Epoch 88/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1305 - mean_absolute_error: 0.2646\n",
            "Epoch 88: val_loss improved from 0.12501 to 0.12241, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/88-0.12241_best\n",
            "\n",
            "Epoch 88: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/88-0.12241\n",
            "61/61 [==============================] - 3s 52ms/step - loss: 0.1306 - mean_absolute_error: 0.2649 - val_loss: 0.1224 - val_mean_absolute_error: 0.2529\n",
            "Epoch 89/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1368 - mean_absolute_error: 0.2718\n",
            "Epoch 89: val_loss did not improve from 0.12241\n",
            "\n",
            "Epoch 89: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/89-0.13388\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1367 - mean_absolute_error: 0.2717 - val_loss: 0.1339 - val_mean_absolute_error: 0.2700\n",
            "Epoch 90/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1333 - mean_absolute_error: 0.2690\n",
            "Epoch 90: val_loss did not improve from 0.12241\n",
            "\n",
            "Epoch 90: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/90-0.12874\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1333 - mean_absolute_error: 0.2690 - val_loss: 0.1287 - val_mean_absolute_error: 0.2624\n",
            "Epoch 91/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1311 - mean_absolute_error: 0.2665\n",
            "Epoch 91: val_loss improved from 0.12241 to 0.11813, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/91-0.11813_best\n",
            "\n",
            "Epoch 91: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/91-0.11813\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.1304 - mean_absolute_error: 0.2661 - val_loss: 0.1181 - val_mean_absolute_error: 0.2529\n",
            "Epoch 92/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.1263 - mean_absolute_error: 0.2620\n",
            "Epoch 92: val_loss did not improve from 0.11813\n",
            "\n",
            "Epoch 92: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/92-0.12632\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.1267 - mean_absolute_error: 0.2622 - val_loss: 0.1263 - val_mean_absolute_error: 0.2563\n",
            "Epoch 93/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1301 - mean_absolute_error: 0.2636\n",
            "Epoch 93: val_loss did not improve from 0.11813\n",
            "\n",
            "Epoch 93: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/93-0.12146\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1298 - mean_absolute_error: 0.2635 - val_loss: 0.1215 - val_mean_absolute_error: 0.2581\n",
            "Epoch 94/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1244 - mean_absolute_error: 0.2589\n",
            "Epoch 94: val_loss did not improve from 0.11813\n",
            "\n",
            "Epoch 94: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/94-0.12498\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1246 - mean_absolute_error: 0.2592 - val_loss: 0.1250 - val_mean_absolute_error: 0.2527\n",
            "Epoch 95/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1321 - mean_absolute_error: 0.2653\n",
            "Epoch 95: val_loss did not improve from 0.11813\n",
            "\n",
            "Epoch 95: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/95-0.12119\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1310 - mean_absolute_error: 0.2645 - val_loss: 0.1212 - val_mean_absolute_error: 0.2538\n",
            "Epoch 96/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.2590\n",
            "Epoch 96: val_loss improved from 0.11813 to 0.11558, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/96-0.11558_best\n",
            "\n",
            "Epoch 96: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/96-0.11558\n",
            "61/61 [==============================] - 3s 54ms/step - loss: 0.1237 - mean_absolute_error: 0.2584 - val_loss: 0.1156 - val_mean_absolute_error: 0.2534\n",
            "Epoch 97/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2561\n",
            "Epoch 97: val_loss did not improve from 0.11558\n",
            "\n",
            "Epoch 97: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/97-0.11975\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.1211 - mean_absolute_error: 0.2563 - val_loss: 0.1197 - val_mean_absolute_error: 0.2513\n",
            "Epoch 98/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1248 - mean_absolute_error: 0.2595\n",
            "Epoch 98: val_loss did not improve from 0.11558\n",
            "\n",
            "Epoch 98: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/98-0.12156\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.1249 - mean_absolute_error: 0.2597 - val_loss: 0.1216 - val_mean_absolute_error: 0.2540\n",
            "Epoch 99/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1218 - mean_absolute_error: 0.2554\n",
            "Epoch 99: val_loss improved from 0.11558 to 0.11283, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/99-0.11283_best\n",
            "\n",
            "Epoch 99: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/99-0.11283\n",
            "61/61 [==============================] - 4s 61ms/step - loss: 0.1222 - mean_absolute_error: 0.2556 - val_loss: 0.1128 - val_mean_absolute_error: 0.2446\n",
            "Epoch 100/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1167 - mean_absolute_error: 0.2514\n",
            "Epoch 100: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 100: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/100-0.11352\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1165 - mean_absolute_error: 0.2510 - val_loss: 0.1135 - val_mean_absolute_error: 0.2449\n",
            "Epoch 101/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2526\n",
            "Epoch 101: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 101: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/101-0.11624\n",
            "61/61 [==============================] - 4s 59ms/step - loss: 0.1190 - mean_absolute_error: 0.2531 - val_loss: 0.1162 - val_mean_absolute_error: 0.2501\n",
            "Epoch 102/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2526\n",
            "Epoch 102: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 102: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/102-0.11531\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1175 - mean_absolute_error: 0.2526 - val_loss: 0.1153 - val_mean_absolute_error: 0.2443\n",
            "Epoch 103/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2542\n",
            "Epoch 103: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 103: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/103-0.11495\n",
            "61/61 [==============================] - 2s 40ms/step - loss: 0.1202 - mean_absolute_error: 0.2534 - val_loss: 0.1150 - val_mean_absolute_error: 0.2464\n",
            "Epoch 104/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1173 - mean_absolute_error: 0.2527\n",
            "Epoch 104: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 104: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/104-0.11610\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.1172 - mean_absolute_error: 0.2525 - val_loss: 0.1161 - val_mean_absolute_error: 0.2447\n",
            "Epoch 105/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2519\n",
            "Epoch 105: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 105: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/105-0.11417\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.1186 - mean_absolute_error: 0.2515 - val_loss: 0.1142 - val_mean_absolute_error: 0.2438\n",
            "Epoch 106/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1159 - mean_absolute_error: 0.2501\n",
            "Epoch 106: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 106: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/106-0.11611\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1156 - mean_absolute_error: 0.2497 - val_loss: 0.1161 - val_mean_absolute_error: 0.2452\n",
            "Epoch 107/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1151 - mean_absolute_error: 0.2494\n",
            "Epoch 107: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 107: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/107-0.11302\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.1156 - mean_absolute_error: 0.2499 - val_loss: 0.1130 - val_mean_absolute_error: 0.2458\n",
            "Epoch 108/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1353 - mean_absolute_error: 0.2603\n",
            "Epoch 108: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 108: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/108-0.15332\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1373 - mean_absolute_error: 0.2627 - val_loss: 0.1533 - val_mean_absolute_error: 0.2828\n",
            "Epoch 109/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1366 - mean_absolute_error: 0.2728\n",
            "Epoch 109: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 109: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/109-0.11697\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1355 - mean_absolute_error: 0.2712 - val_loss: 0.1170 - val_mean_absolute_error: 0.2487\n",
            "Epoch 110/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2523\n",
            "Epoch 110: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 110: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/110-0.11928\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.1199 - mean_absolute_error: 0.2527 - val_loss: 0.1193 - val_mean_absolute_error: 0.2455\n",
            "Epoch 111/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1136 - mean_absolute_error: 0.2480\n",
            "Epoch 111: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 111: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/111-0.11354\n",
            "61/61 [==============================] - 3s 50ms/step - loss: 0.1132 - mean_absolute_error: 0.2477 - val_loss: 0.1135 - val_mean_absolute_error: 0.2449\n",
            "Epoch 112/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.2489\n",
            "Epoch 112: val_loss did not improve from 0.11283\n",
            "\n",
            "Epoch 112: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/112-0.11812\n",
            "61/61 [==============================] - 3s 42ms/step - loss: 0.1156 - mean_absolute_error: 0.2489 - val_loss: 0.1181 - val_mean_absolute_error: 0.2515\n",
            "Epoch 113/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2493\n",
            "Epoch 113: val_loss improved from 0.11283 to 0.11042, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/113-0.11042_best\n",
            "\n",
            "Epoch 113: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/113-0.11042\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.1164 - mean_absolute_error: 0.2493 - val_loss: 0.1104 - val_mean_absolute_error: 0.2418\n",
            "Epoch 114/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1102 - mean_absolute_error: 0.2444\n",
            "Epoch 114: val_loss improved from 0.11042 to 0.10769, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/114-0.10769_best\n",
            "\n",
            "Epoch 114: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/114-0.10769\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.1103 - mean_absolute_error: 0.2441 - val_loss: 0.1077 - val_mean_absolute_error: 0.2365\n",
            "Epoch 115/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1116 - mean_absolute_error: 0.2446\n",
            "Epoch 115: val_loss did not improve from 0.10769\n",
            "\n",
            "Epoch 115: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/115-0.10838\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1116 - mean_absolute_error: 0.2446 - val_loss: 0.1084 - val_mean_absolute_error: 0.2384\n",
            "Epoch 116/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1120 - mean_absolute_error: 0.2454\n",
            "Epoch 116: val_loss did not improve from 0.10769\n",
            "\n",
            "Epoch 116: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/116-0.11343\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.1125 - mean_absolute_error: 0.2455 - val_loss: 0.1134 - val_mean_absolute_error: 0.2460\n",
            "Epoch 117/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1152 - mean_absolute_error: 0.2487\n",
            "Epoch 117: val_loss improved from 0.10769 to 0.10439, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/117-0.10439_best\n",
            "\n",
            "Epoch 117: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/117-0.10439\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.1151 - mean_absolute_error: 0.2485 - val_loss: 0.1044 - val_mean_absolute_error: 0.2327\n",
            "Epoch 118/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.2451\n",
            "Epoch 118: val_loss did not improve from 0.10439\n",
            "\n",
            "Epoch 118: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/118-0.10879\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.1134 - mean_absolute_error: 0.2461 - val_loss: 0.1088 - val_mean_absolute_error: 0.2365\n",
            "Epoch 119/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1169 - mean_absolute_error: 0.2495\n",
            "Epoch 119: val_loss did not improve from 0.10439\n",
            "\n",
            "Epoch 119: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/119-0.11584\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1156 - mean_absolute_error: 0.2477 - val_loss: 0.1158 - val_mean_absolute_error: 0.2418\n",
            "Epoch 120/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1077 - mean_absolute_error: 0.2409\n",
            "Epoch 120: val_loss did not improve from 0.10439\n",
            "\n",
            "Epoch 120: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/120-0.10978\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1092 - mean_absolute_error: 0.2419 - val_loss: 0.1098 - val_mean_absolute_error: 0.2380\n",
            "Epoch 121/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1126 - mean_absolute_error: 0.2456\n",
            "Epoch 121: val_loss did not improve from 0.10439\n",
            "\n",
            "Epoch 121: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/121-0.11132\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1130 - mean_absolute_error: 0.2461 - val_loss: 0.1113 - val_mean_absolute_error: 0.2444\n",
            "Epoch 122/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.1114 - mean_absolute_error: 0.2459\n",
            "Epoch 122: val_loss did not improve from 0.10439\n",
            "\n",
            "Epoch 122: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/122-0.10792\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.1120 - mean_absolute_error: 0.2463 - val_loss: 0.1079 - val_mean_absolute_error: 0.2338\n",
            "Epoch 123/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1116 - mean_absolute_error: 0.2435\n",
            "Epoch 123: val_loss did not improve from 0.10439\n",
            "\n",
            "Epoch 123: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/123-0.16110\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 0.1115 - mean_absolute_error: 0.2434 - val_loss: 0.1611 - val_mean_absolute_error: 0.2636\n",
            "Epoch 124/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1339 - mean_absolute_error: 0.2619\n",
            "Epoch 124: val_loss did not improve from 0.10439\n",
            "\n",
            "Epoch 124: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/124-0.11879\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.1339 - mean_absolute_error: 0.2619 - val_loss: 0.1188 - val_mean_absolute_error: 0.2453\n",
            "Epoch 125/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.2443\n",
            "Epoch 125: val_loss improved from 0.10439 to 0.09804, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/125-0.09804_best\n",
            "\n",
            "Epoch 125: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/125-0.09804\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.1111 - mean_absolute_error: 0.2428 - val_loss: 0.0980 - val_mean_absolute_error: 0.2203\n",
            "Epoch 126/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1072 - mean_absolute_error: 0.2374\n",
            "Epoch 126: val_loss improved from 0.09804 to 0.09737, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/126-0.09737_best\n",
            "\n",
            "Epoch 126: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/126-0.09737\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.1074 - mean_absolute_error: 0.2376 - val_loss: 0.0974 - val_mean_absolute_error: 0.2256\n",
            "Epoch 127/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1089 - mean_absolute_error: 0.2414\n",
            "Epoch 127: val_loss did not improve from 0.09737\n",
            "\n",
            "Epoch 127: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/127-0.09913\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1074 - mean_absolute_error: 0.2392 - val_loss: 0.0991 - val_mean_absolute_error: 0.2275\n",
            "Epoch 128/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1060 - mean_absolute_error: 0.2371\n",
            "Epoch 128: val_loss improved from 0.09737 to 0.09152, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/128-0.09152_best\n",
            "\n",
            "Epoch 128: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/128-0.09152\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.1052 - mean_absolute_error: 0.2356 - val_loss: 0.0915 - val_mean_absolute_error: 0.2220\n",
            "Epoch 129/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1037 - mean_absolute_error: 0.2340\n",
            "Epoch 129: val_loss did not improve from 0.09152\n",
            "\n",
            "Epoch 129: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/129-0.10163\n",
            "61/61 [==============================] - 2s 41ms/step - loss: 0.1053 - mean_absolute_error: 0.2352 - val_loss: 0.1016 - val_mean_absolute_error: 0.2325\n",
            "Epoch 130/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1146 - mean_absolute_error: 0.2460\n",
            "Epoch 130: val_loss did not improve from 0.09152\n",
            "\n",
            "Epoch 130: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/130-0.09426\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.1133 - mean_absolute_error: 0.2450 - val_loss: 0.0943 - val_mean_absolute_error: 0.2170\n",
            "Epoch 131/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1419 - mean_absolute_error: 0.2635\n",
            "Epoch 131: val_loss did not improve from 0.09152\n",
            "\n",
            "Epoch 131: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/131-0.10317\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.1419 - mean_absolute_error: 0.2635 - val_loss: 0.1032 - val_mean_absolute_error: 0.2326\n",
            "Epoch 132/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.1073 - mean_absolute_error: 0.2393\n",
            "Epoch 132: val_loss did not improve from 0.09152\n",
            "\n",
            "Epoch 132: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/132-0.09371\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1077 - mean_absolute_error: 0.2393 - val_loss: 0.0937 - val_mean_absolute_error: 0.2171\n",
            "Epoch 133/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1018 - mean_absolute_error: 0.2327\n",
            "Epoch 133: val_loss did not improve from 0.09152\n",
            "\n",
            "Epoch 133: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/133-0.09573\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1015 - mean_absolute_error: 0.2326 - val_loss: 0.0957 - val_mean_absolute_error: 0.2217\n",
            "Epoch 134/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0990 - mean_absolute_error: 0.2288\n",
            "Epoch 134: val_loss did not improve from 0.09152\n",
            "\n",
            "Epoch 134: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/134-0.09417\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.0999 - mean_absolute_error: 0.2295 - val_loss: 0.0942 - val_mean_absolute_error: 0.2204\n",
            "Epoch 135/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.1053 - mean_absolute_error: 0.2348\n",
            "Epoch 135: val_loss did not improve from 0.09152\n",
            "\n",
            "Epoch 135: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/135-0.10929\n",
            "61/61 [==============================] - 3s 42ms/step - loss: 0.1050 - mean_absolute_error: 0.2342 - val_loss: 0.1093 - val_mean_absolute_error: 0.2316\n",
            "Epoch 136/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.1080 - mean_absolute_error: 0.2377\n",
            "Epoch 136: val_loss improved from 0.09152 to 0.08926, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/136-0.08926_best\n",
            "\n",
            "Epoch 136: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/136-0.08926\n",
            "61/61 [==============================] - 6s 99ms/step - loss: 0.1079 - mean_absolute_error: 0.2377 - val_loss: 0.0893 - val_mean_absolute_error: 0.2131\n",
            "Epoch 137/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1016 - mean_absolute_error: 0.2300\n",
            "Epoch 137: val_loss did not improve from 0.08926\n",
            "\n",
            "Epoch 137: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/137-0.15085\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1126 - mean_absolute_error: 0.2359 - val_loss: 0.1508 - val_mean_absolute_error: 0.2615\n",
            "Epoch 138/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1189 - mean_absolute_error: 0.2483\n",
            "Epoch 138: val_loss did not improve from 0.08926\n",
            "\n",
            "Epoch 138: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/138-0.09215\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.1178 - mean_absolute_error: 0.2474 - val_loss: 0.0922 - val_mean_absolute_error: 0.2188\n",
            "Epoch 139/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0968 - mean_absolute_error: 0.2260\n",
            "Epoch 139: val_loss did not improve from 0.08926\n",
            "\n",
            "Epoch 139: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/139-0.09698\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0968 - mean_absolute_error: 0.2260 - val_loss: 0.0970 - val_mean_absolute_error: 0.2194\n",
            "Epoch 140/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0980 - mean_absolute_error: 0.2263\n",
            "Epoch 140: val_loss did not improve from 0.08926\n",
            "\n",
            "Epoch 140: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/140-0.09493\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0981 - mean_absolute_error: 0.2266 - val_loss: 0.0949 - val_mean_absolute_error: 0.2160\n",
            "Epoch 141/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0988 - mean_absolute_error: 0.2267\n",
            "Epoch 141: val_loss improved from 0.08926 to 0.08744, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/141-0.08744_best\n",
            "\n",
            "Epoch 141: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/141-0.08744\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.0983 - mean_absolute_error: 0.2263 - val_loss: 0.0874 - val_mean_absolute_error: 0.2090\n",
            "Epoch 142/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0978 - mean_absolute_error: 0.2259\n",
            "Epoch 142: val_loss did not improve from 0.08744\n",
            "\n",
            "Epoch 142: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/142-0.09127\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.0984 - mean_absolute_error: 0.2270 - val_loss: 0.0913 - val_mean_absolute_error: 0.2152\n",
            "Epoch 143/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.2243\n",
            "Epoch 143: val_loss did not improve from 0.08744\n",
            "\n",
            "Epoch 143: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/143-0.09398\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0956 - mean_absolute_error: 0.2243 - val_loss: 0.0940 - val_mean_absolute_error: 0.2158\n",
            "Epoch 144/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0984 - mean_absolute_error: 0.2270\n",
            "Epoch 144: val_loss did not improve from 0.08744\n",
            "\n",
            "Epoch 144: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/144-0.08849\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0980 - mean_absolute_error: 0.2264 - val_loss: 0.0885 - val_mean_absolute_error: 0.2112\n",
            "Epoch 145/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0968 - mean_absolute_error: 0.2252\n",
            "Epoch 145: val_loss did not improve from 0.08744\n",
            "\n",
            "Epoch 145: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/145-0.09460\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0967 - mean_absolute_error: 0.2255 - val_loss: 0.0946 - val_mean_absolute_error: 0.2173\n",
            "Epoch 146/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0963 - mean_absolute_error: 0.2243\n",
            "Epoch 146: val_loss did not improve from 0.08744\n",
            "\n",
            "Epoch 146: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/146-0.08949\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.0964 - mean_absolute_error: 0.2239 - val_loss: 0.0895 - val_mean_absolute_error: 0.2098\n",
            "Epoch 147/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0955 - mean_absolute_error: 0.2225\n",
            "Epoch 147: val_loss did not improve from 0.08744\n",
            "\n",
            "Epoch 147: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/147-0.08822\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.0956 - mean_absolute_error: 0.2225 - val_loss: 0.0882 - val_mean_absolute_error: 0.2100\n",
            "Epoch 148/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0928 - mean_absolute_error: 0.2203\n",
            "Epoch 148: val_loss did not improve from 0.08744\n",
            "\n",
            "Epoch 148: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/148-0.09506\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.0927 - mean_absolute_error: 0.2205 - val_loss: 0.0951 - val_mean_absolute_error: 0.2153\n",
            "Epoch 149/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0959 - mean_absolute_error: 0.2226\n",
            "Epoch 149: val_loss improved from 0.08744 to 0.08631, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/149-0.08631_best\n",
            "\n",
            "Epoch 149: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/149-0.08631\n",
            "61/61 [==============================] - 4s 59ms/step - loss: 0.0962 - mean_absolute_error: 0.2231 - val_loss: 0.0863 - val_mean_absolute_error: 0.2015\n",
            "Epoch 150/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0946 - mean_absolute_error: 0.2230\n",
            "Epoch 150: val_loss did not improve from 0.08631\n",
            "\n",
            "Epoch 150: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/150-0.08934\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0950 - mean_absolute_error: 0.2235 - val_loss: 0.0893 - val_mean_absolute_error: 0.2093\n",
            "Epoch 151/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0943 - mean_absolute_error: 0.2212\n",
            "Epoch 151: val_loss improved from 0.08631 to 0.08594, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/151-0.08594_best\n",
            "\n",
            "Epoch 151: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/151-0.08594\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 0.0954 - mean_absolute_error: 0.2226 - val_loss: 0.0859 - val_mean_absolute_error: 0.2064\n",
            "Epoch 152/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0933 - mean_absolute_error: 0.2199\n",
            "Epoch 152: val_loss improved from 0.08594 to 0.08230, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/152-0.08230_best\n",
            "\n",
            "Epoch 152: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/152-0.08230\n",
            "61/61 [==============================] - 4s 59ms/step - loss: 0.0927 - mean_absolute_error: 0.2193 - val_loss: 0.0823 - val_mean_absolute_error: 0.2012\n",
            "Epoch 153/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0906 - mean_absolute_error: 0.2161\n",
            "Epoch 153: val_loss improved from 0.08230 to 0.07989, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/153-0.07989_best\n",
            "\n",
            "Epoch 153: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/153-0.07989\n",
            "61/61 [==============================] - 5s 75ms/step - loss: 0.0906 - mean_absolute_error: 0.2161 - val_loss: 0.0799 - val_mean_absolute_error: 0.1947\n",
            "Epoch 154/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0923 - mean_absolute_error: 0.2181\n",
            "Epoch 154: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 154: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/154-0.08148\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.0905 - mean_absolute_error: 0.2163 - val_loss: 0.0815 - val_mean_absolute_error: 0.1978\n",
            "Epoch 155/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0902 - mean_absolute_error: 0.2168\n",
            "Epoch 155: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 155: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/155-0.08113\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0900 - mean_absolute_error: 0.2163 - val_loss: 0.0811 - val_mean_absolute_error: 0.1977\n",
            "Epoch 156/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.2188\n",
            "Epoch 156: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 156: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/156-0.09115\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0940 - mean_absolute_error: 0.2188 - val_loss: 0.0911 - val_mean_absolute_error: 0.2091\n",
            "Epoch 157/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.2168\n",
            "Epoch 157: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 157: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/157-0.08264\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.0915 - mean_absolute_error: 0.2166 - val_loss: 0.0826 - val_mean_absolute_error: 0.2023\n",
            "Epoch 158/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0886 - mean_absolute_error: 0.2143\n",
            "Epoch 158: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 158: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/158-0.08419\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 0.0886 - mean_absolute_error: 0.2143 - val_loss: 0.0842 - val_mean_absolute_error: 0.2019\n",
            "Epoch 159/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0890 - mean_absolute_error: 0.2130\n",
            "Epoch 159: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 159: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/159-0.08289\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.0890 - mean_absolute_error: 0.2130 - val_loss: 0.0829 - val_mean_absolute_error: 0.1988\n",
            "Epoch 160/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0895 - mean_absolute_error: 0.2144\n",
            "Epoch 160: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 160: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/160-0.08177\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0894 - mean_absolute_error: 0.2142 - val_loss: 0.0818 - val_mean_absolute_error: 0.2002\n",
            "Epoch 161/9999999\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.0936 - mean_absolute_error: 0.2184\n",
            "Epoch 161: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 161: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/161-0.08281\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0932 - mean_absolute_error: 0.2178 - val_loss: 0.0828 - val_mean_absolute_error: 0.1995\n",
            "Epoch 162/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0901 - mean_absolute_error: 0.2170\n",
            "Epoch 162: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 162: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/162-0.08393\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0900 - mean_absolute_error: 0.2168 - val_loss: 0.0839 - val_mean_absolute_error: 0.2014\n",
            "Epoch 163/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0881 - mean_absolute_error: 0.2138\n",
            "Epoch 163: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 163: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/163-0.08436\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.0881 - mean_absolute_error: 0.2138 - val_loss: 0.0844 - val_mean_absolute_error: 0.2011\n",
            "Epoch 164/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0918 - mean_absolute_error: 0.2183\n",
            "Epoch 164: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 164: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/164-0.08530\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.0905 - mean_absolute_error: 0.2169 - val_loss: 0.0853 - val_mean_absolute_error: 0.2018\n",
            "Epoch 165/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0879 - mean_absolute_error: 0.2125\n",
            "Epoch 165: val_loss did not improve from 0.07989\n",
            "\n",
            "Epoch 165: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/165-0.08004\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.0892 - mean_absolute_error: 0.2138 - val_loss: 0.0800 - val_mean_absolute_error: 0.1940\n",
            "Epoch 166/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0875 - mean_absolute_error: 0.2115\n",
            "Epoch 166: val_loss improved from 0.07989 to 0.07928, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/166-0.07928_best\n",
            "\n",
            "Epoch 166: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/166-0.07928\n",
            "61/61 [==============================] - 5s 75ms/step - loss: 0.0873 - mean_absolute_error: 0.2116 - val_loss: 0.0793 - val_mean_absolute_error: 0.1924\n",
            "Epoch 167/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0941 - mean_absolute_error: 0.2186\n",
            "Epoch 167: val_loss did not improve from 0.07928\n",
            "\n",
            "Epoch 167: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/167-0.08068\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.0938 - mean_absolute_error: 0.2182 - val_loss: 0.0807 - val_mean_absolute_error: 0.1934\n",
            "Epoch 168/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0862 - mean_absolute_error: 0.2094\n",
            "Epoch 168: val_loss did not improve from 0.07928\n",
            "\n",
            "Epoch 168: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/168-0.08489\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.0862 - mean_absolute_error: 0.2094 - val_loss: 0.0849 - val_mean_absolute_error: 0.2053\n",
            "Epoch 169/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0869 - mean_absolute_error: 0.2113\n",
            "Epoch 169: val_loss did not improve from 0.07928\n",
            "\n",
            "Epoch 169: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/169-0.08370\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 0.0869 - mean_absolute_error: 0.2113 - val_loss: 0.0837 - val_mean_absolute_error: 0.2043\n",
            "Epoch 170/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0853 - mean_absolute_error: 0.2094\n",
            "Epoch 170: val_loss did not improve from 0.07928\n",
            "\n",
            "Epoch 170: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/170-0.09129\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.0855 - mean_absolute_error: 0.2094 - val_loss: 0.0913 - val_mean_absolute_error: 0.2069\n",
            "Epoch 171/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0860 - mean_absolute_error: 0.2105\n",
            "Epoch 171: val_loss did not improve from 0.07928\n",
            "\n",
            "Epoch 171: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/171-0.08177\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 0.0860 - mean_absolute_error: 0.2105 - val_loss: 0.0818 - val_mean_absolute_error: 0.1970\n",
            "Epoch 172/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0871 - mean_absolute_error: 0.2113\n",
            "Epoch 172: val_loss did not improve from 0.07928\n",
            "\n",
            "Epoch 172: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/172-0.07978\n",
            "61/61 [==============================] - 3s 43ms/step - loss: 0.0865 - mean_absolute_error: 0.2108 - val_loss: 0.0798 - val_mean_absolute_error: 0.1965\n",
            "Epoch 173/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0863 - mean_absolute_error: 0.2107\n",
            "Epoch 173: val_loss improved from 0.07928 to 0.07821, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/173-0.07821_best\n",
            "\n",
            "Epoch 173: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/173-0.07821\n",
            "61/61 [==============================] - 3s 54ms/step - loss: 0.0863 - mean_absolute_error: 0.2109 - val_loss: 0.0782 - val_mean_absolute_error: 0.1952\n",
            "Epoch 174/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0850 - mean_absolute_error: 0.2093\n",
            "Epoch 174: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 174: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/174-0.08041\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0856 - mean_absolute_error: 0.2103 - val_loss: 0.0804 - val_mean_absolute_error: 0.1968\n",
            "Epoch 175/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0856 - mean_absolute_error: 0.2100\n",
            "Epoch 175: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 175: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/175-0.08103\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0856 - mean_absolute_error: 0.2100 - val_loss: 0.0810 - val_mean_absolute_error: 0.1968\n",
            "Epoch 176/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0849 - mean_absolute_error: 0.2090\n",
            "Epoch 176: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 176: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/176-0.09508\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0851 - mean_absolute_error: 0.2090 - val_loss: 0.0951 - val_mean_absolute_error: 0.2105\n",
            "Epoch 177/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0892 - mean_absolute_error: 0.2151\n",
            "Epoch 177: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 177: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/177-0.08912\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.0900 - mean_absolute_error: 0.2163 - val_loss: 0.0891 - val_mean_absolute_error: 0.2071\n",
            "Epoch 178/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0870 - mean_absolute_error: 0.2127\n",
            "Epoch 178: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 178: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/178-0.08228\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0868 - mean_absolute_error: 0.2126 - val_loss: 0.0823 - val_mean_absolute_error: 0.2015\n",
            "Epoch 179/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0888 - mean_absolute_error: 0.2136\n",
            "Epoch 179: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 179: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/179-0.08408\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0878 - mean_absolute_error: 0.2125 - val_loss: 0.0841 - val_mean_absolute_error: 0.1991\n",
            "Epoch 180/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0849 - mean_absolute_error: 0.2085\n",
            "Epoch 180: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 180: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/180-0.08068\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0846 - mean_absolute_error: 0.2081 - val_loss: 0.0807 - val_mean_absolute_error: 0.1945\n",
            "Epoch 181/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0844 - mean_absolute_error: 0.2083\n",
            "Epoch 181: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 181: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/181-0.08348\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0850 - mean_absolute_error: 0.2088 - val_loss: 0.0835 - val_mean_absolute_error: 0.1975\n",
            "Epoch 182/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0875 - mean_absolute_error: 0.2122\n",
            "Epoch 182: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 182: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/182-0.08712\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0870 - mean_absolute_error: 0.2116 - val_loss: 0.0871 - val_mean_absolute_error: 0.2056\n",
            "Epoch 183/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0840 - mean_absolute_error: 0.2082\n",
            "Epoch 183: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 183: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/183-0.08502\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.0841 - mean_absolute_error: 0.2083 - val_loss: 0.0850 - val_mean_absolute_error: 0.1988\n",
            "Epoch 184/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0832 - mean_absolute_error: 0.2074\n",
            "Epoch 184: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 184: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/184-0.08397\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.0834 - mean_absolute_error: 0.2079 - val_loss: 0.0840 - val_mean_absolute_error: 0.1986\n",
            "Epoch 185/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0853 - mean_absolute_error: 0.2087\n",
            "Epoch 185: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 185: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/185-0.08217\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.0848 - mean_absolute_error: 0.2083 - val_loss: 0.0822 - val_mean_absolute_error: 0.1939\n",
            "Epoch 186/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0879 - mean_absolute_error: 0.2113\n",
            "Epoch 186: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 186: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/186-0.09518\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0885 - mean_absolute_error: 0.2112 - val_loss: 0.0952 - val_mean_absolute_error: 0.2034\n",
            "Epoch 187/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1015 - mean_absolute_error: 0.2248\n",
            "Epoch 187: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 187: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/187-0.08433\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.1011 - mean_absolute_error: 0.2243 - val_loss: 0.0843 - val_mean_absolute_error: 0.2015\n",
            "Epoch 188/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0836 - mean_absolute_error: 0.2061\n",
            "Epoch 188: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 188: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/188-0.08556\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0841 - mean_absolute_error: 0.2067 - val_loss: 0.0856 - val_mean_absolute_error: 0.2047\n",
            "Epoch 189/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0873 - mean_absolute_error: 0.2127\n",
            "Epoch 189: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 189: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/189-0.08774\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0875 - mean_absolute_error: 0.2127 - val_loss: 0.0877 - val_mean_absolute_error: 0.2106\n",
            "Epoch 190/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0848 - mean_absolute_error: 0.2092\n",
            "Epoch 190: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 190: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/190-0.08333\n",
            "61/61 [==============================] - 2s 41ms/step - loss: 0.0848 - mean_absolute_error: 0.2091 - val_loss: 0.0833 - val_mean_absolute_error: 0.2038\n",
            "Epoch 191/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0837 - mean_absolute_error: 0.2072\n",
            "Epoch 191: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 191: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/191-0.08180\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.0834 - mean_absolute_error: 0.2070 - val_loss: 0.0818 - val_mean_absolute_error: 0.1988\n",
            "Epoch 192/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0846 - mean_absolute_error: 0.2087\n",
            "Epoch 192: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 192: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/192-0.08747\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.0854 - mean_absolute_error: 0.2092 - val_loss: 0.0875 - val_mean_absolute_error: 0.2001\n",
            "Epoch 193/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0908 - mean_absolute_error: 0.2150\n",
            "Epoch 193: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 193: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/193-0.08585\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0903 - mean_absolute_error: 0.2144 - val_loss: 0.0859 - val_mean_absolute_error: 0.2010\n",
            "Epoch 194/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0904 - mean_absolute_error: 0.2131\n",
            "Epoch 194: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 194: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/194-0.08898\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0904 - mean_absolute_error: 0.2131 - val_loss: 0.0890 - val_mean_absolute_error: 0.2040\n",
            "Epoch 195/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0854 - mean_absolute_error: 0.2084\n",
            "Epoch 195: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 195: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/195-0.08419\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0855 - mean_absolute_error: 0.2088 - val_loss: 0.0842 - val_mean_absolute_error: 0.2006\n",
            "Epoch 196/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0816 - mean_absolute_error: 0.2049\n",
            "Epoch 196: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 196: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/196-0.08039\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0816 - mean_absolute_error: 0.2049 - val_loss: 0.0804 - val_mean_absolute_error: 0.1954\n",
            "Epoch 197/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0806 - mean_absolute_error: 0.2032\n",
            "Epoch 197: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 197: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/197-0.08180\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.0817 - mean_absolute_error: 0.2044 - val_loss: 0.0818 - val_mean_absolute_error: 0.1980\n",
            "Epoch 198/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0835 - mean_absolute_error: 0.2065\n",
            "Epoch 198: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 198: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/198-0.08591\n",
            "61/61 [==============================] - 3s 48ms/step - loss: 0.0832 - mean_absolute_error: 0.2063 - val_loss: 0.0859 - val_mean_absolute_error: 0.2017\n",
            "Epoch 199/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0817 - mean_absolute_error: 0.2048\n",
            "Epoch 199: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 199: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/199-0.08461\n",
            "61/61 [==============================] - 3s 43ms/step - loss: 0.0817 - mean_absolute_error: 0.2048 - val_loss: 0.0846 - val_mean_absolute_error: 0.1957\n",
            "Epoch 200/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0819 - mean_absolute_error: 0.2052\n",
            "Epoch 200: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 200: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/200-0.08260\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0818 - mean_absolute_error: 0.2052 - val_loss: 0.0826 - val_mean_absolute_error: 0.1979\n",
            "Epoch 201/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0836 - mean_absolute_error: 0.2068\n",
            "Epoch 201: val_loss did not improve from 0.07821\n",
            "\n",
            "Epoch 201: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/201-0.08120\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0833 - mean_absolute_error: 0.2067 - val_loss: 0.0812 - val_mean_absolute_error: 0.1964\n",
            "Epoch 202/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0816 - mean_absolute_error: 0.2050\n",
            "Epoch 202: val_loss improved from 0.07821 to 0.07809, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/202-0.07809_best\n",
            "\n",
            "Epoch 202: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/202-0.07809\n",
            "61/61 [==============================] - 3s 57ms/step - loss: 0.0809 - mean_absolute_error: 0.2042 - val_loss: 0.0781 - val_mean_absolute_error: 0.1929\n",
            "Epoch 203/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0793 - mean_absolute_error: 0.2012\n",
            "Epoch 203: val_loss improved from 0.07809 to 0.07729, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/203-0.07729_best\n",
            "\n",
            "Epoch 203: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/203-0.07729\n",
            "61/61 [==============================] - 7s 116ms/step - loss: 0.0794 - mean_absolute_error: 0.2013 - val_loss: 0.0773 - val_mean_absolute_error: 0.1924\n",
            "Epoch 204/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0811 - mean_absolute_error: 0.2026\n",
            "Epoch 204: val_loss did not improve from 0.07729\n",
            "\n",
            "Epoch 204: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/204-0.08490\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0811 - mean_absolute_error: 0.2026 - val_loss: 0.0849 - val_mean_absolute_error: 0.1950\n",
            "Epoch 205/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0847 - mean_absolute_error: 0.2083\n",
            "Epoch 205: val_loss did not improve from 0.07729\n",
            "\n",
            "Epoch 205: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/205-0.08044\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0847 - mean_absolute_error: 0.2083 - val_loss: 0.0804 - val_mean_absolute_error: 0.1963\n",
            "Epoch 206/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0867 - mean_absolute_error: 0.2103\n",
            "Epoch 206: val_loss did not improve from 0.07729\n",
            "\n",
            "Epoch 206: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/206-0.09110\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0873 - mean_absolute_error: 0.2113 - val_loss: 0.0911 - val_mean_absolute_error: 0.2113\n",
            "Epoch 207/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0835 - mean_absolute_error: 0.2081\n",
            "Epoch 207: val_loss did not improve from 0.07729\n",
            "\n",
            "Epoch 207: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/207-0.08421\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0829 - mean_absolute_error: 0.2073 - val_loss: 0.0842 - val_mean_absolute_error: 0.2017\n",
            "Epoch 208/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0840 - mean_absolute_error: 0.2076\n",
            "Epoch 208: val_loss did not improve from 0.07729\n",
            "\n",
            "Epoch 208: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/208-0.08379\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0840 - mean_absolute_error: 0.2076 - val_loss: 0.0838 - val_mean_absolute_error: 0.1939\n",
            "Epoch 209/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0806 - mean_absolute_error: 0.2018\n",
            "Epoch 209: val_loss did not improve from 0.07729\n",
            "\n",
            "Epoch 209: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/209-0.07875\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.0810 - mean_absolute_error: 0.2022 - val_loss: 0.0787 - val_mean_absolute_error: 0.1955\n",
            "Epoch 210/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0815 - mean_absolute_error: 0.2045\n",
            "Epoch 210: val_loss improved from 0.07729 to 0.07646, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/210-0.07646_best\n",
            "\n",
            "Epoch 210: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/210-0.07646\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 0.0813 - mean_absolute_error: 0.2043 - val_loss: 0.0765 - val_mean_absolute_error: 0.1929\n",
            "Epoch 211/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0805 - mean_absolute_error: 0.2018\n",
            "Epoch 211: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 211: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/211-0.07787\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0806 - mean_absolute_error: 0.2020 - val_loss: 0.0779 - val_mean_absolute_error: 0.1933\n",
            "Epoch 212/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0798 - mean_absolute_error: 0.2019\n",
            "Epoch 212: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 212: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/212-0.07831\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0810 - mean_absolute_error: 0.2031 - val_loss: 0.0783 - val_mean_absolute_error: 0.1929\n",
            "Epoch 213/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0803 - mean_absolute_error: 0.2037\n",
            "Epoch 213: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 213: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/213-0.08107\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0803 - mean_absolute_error: 0.2037 - val_loss: 0.0811 - val_mean_absolute_error: 0.1966\n",
            "Epoch 214/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0818 - mean_absolute_error: 0.2040\n",
            "Epoch 214: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 214: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/214-0.07960\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0815 - mean_absolute_error: 0.2034 - val_loss: 0.0796 - val_mean_absolute_error: 0.1930\n",
            "Epoch 215/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0811 - mean_absolute_error: 0.2035\n",
            "Epoch 215: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 215: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/215-0.07770\n",
            "61/61 [==============================] - 2s 41ms/step - loss: 0.0812 - mean_absolute_error: 0.2040 - val_loss: 0.0777 - val_mean_absolute_error: 0.1908\n",
            "Epoch 216/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0803 - mean_absolute_error: 0.2020\n",
            "Epoch 216: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 216: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/216-0.07678\n",
            "61/61 [==============================] - 3s 51ms/step - loss: 0.0802 - mean_absolute_error: 0.2019 - val_loss: 0.0768 - val_mean_absolute_error: 0.1901\n",
            "Epoch 217/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0809 - mean_absolute_error: 0.2034\n",
            "Epoch 217: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 217: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/217-0.08199\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.0809 - mean_absolute_error: 0.2034 - val_loss: 0.0820 - val_mean_absolute_error: 0.1956\n",
            "Epoch 218/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0807 - mean_absolute_error: 0.2035\n",
            "Epoch 218: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 218: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/218-0.07741\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0804 - mean_absolute_error: 0.2035 - val_loss: 0.0774 - val_mean_absolute_error: 0.1912\n",
            "Epoch 219/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0838 - mean_absolute_error: 0.2050\n",
            "Epoch 219: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 219: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/219-0.08211\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0842 - mean_absolute_error: 0.2056 - val_loss: 0.0821 - val_mean_absolute_error: 0.1991\n",
            "Epoch 220/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0965 - mean_absolute_error: 0.2166\n",
            "Epoch 220: val_loss did not improve from 0.07646\n",
            "\n",
            "Epoch 220: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/220-0.07923\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 0.0951 - mean_absolute_error: 0.2151 - val_loss: 0.0792 - val_mean_absolute_error: 0.1935\n",
            "Epoch 221/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0814 - mean_absolute_error: 0.2031\n",
            "Epoch 221: val_loss improved from 0.07646 to 0.07537, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/221-0.07537_best\n",
            "\n",
            "Epoch 221: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/221-0.07537\n",
            "61/61 [==============================] - 4s 59ms/step - loss: 0.0814 - mean_absolute_error: 0.2031 - val_loss: 0.0754 - val_mean_absolute_error: 0.1901\n",
            "Epoch 222/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0800 - mean_absolute_error: 0.2014\n",
            "Epoch 222: val_loss did not improve from 0.07537\n",
            "\n",
            "Epoch 222: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/222-0.08162\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.0799 - mean_absolute_error: 0.2015 - val_loss: 0.0816 - val_mean_absolute_error: 0.1929\n",
            "Epoch 223/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0823 - mean_absolute_error: 0.2053\n",
            "Epoch 223: val_loss did not improve from 0.07537\n",
            "\n",
            "Epoch 223: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/223-0.07550\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.0823 - mean_absolute_error: 0.2053 - val_loss: 0.0755 - val_mean_absolute_error: 0.1897\n",
            "Epoch 224/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0829 - mean_absolute_error: 0.2019\n",
            "Epoch 224: val_loss did not improve from 0.07537\n",
            "\n",
            "Epoch 224: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/224-0.08495\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.0831 - mean_absolute_error: 0.2022 - val_loss: 0.0849 - val_mean_absolute_error: 0.1958\n",
            "Epoch 225/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0843 - mean_absolute_error: 0.2057\n",
            "Epoch 225: val_loss improved from 0.07537 to 0.07481, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/225-0.07481_best\n",
            "\n",
            "Epoch 225: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/225-0.07481\n",
            "61/61 [==============================] - 3s 56ms/step - loss: 0.0840 - mean_absolute_error: 0.2052 - val_loss: 0.0748 - val_mean_absolute_error: 0.1882\n",
            "Epoch 226/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0807 - mean_absolute_error: 0.2032\n",
            "Epoch 226: val_loss did not improve from 0.07481\n",
            "\n",
            "Epoch 226: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/226-0.07665\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0807 - mean_absolute_error: 0.2034 - val_loss: 0.0767 - val_mean_absolute_error: 0.1907\n",
            "Epoch 227/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0770 - mean_absolute_error: 0.1984\n",
            "Epoch 227: val_loss did not improve from 0.07481\n",
            "\n",
            "Epoch 227: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/227-0.07537\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0783 - mean_absolute_error: 0.2000 - val_loss: 0.0754 - val_mean_absolute_error: 0.1899\n",
            "Epoch 228/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0794 - mean_absolute_error: 0.2007\n",
            "Epoch 228: val_loss did not improve from 0.07481\n",
            "\n",
            "Epoch 228: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/228-0.07742\n",
            "61/61 [==============================] - 6s 92ms/step - loss: 0.0794 - mean_absolute_error: 0.2007 - val_loss: 0.0774 - val_mean_absolute_error: 0.1917\n",
            "Epoch 229/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0805 - mean_absolute_error: 0.2024\n",
            "Epoch 229: val_loss improved from 0.07481 to 0.07471, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/229-0.07471_best\n",
            "\n",
            "Epoch 229: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/229-0.07471\n",
            "61/61 [==============================] - 4s 61ms/step - loss: 0.0806 - mean_absolute_error: 0.2019 - val_loss: 0.0747 - val_mean_absolute_error: 0.1888\n",
            "Epoch 230/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0900 - mean_absolute_error: 0.2064\n",
            "Epoch 230: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 230: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/230-0.13301\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0937 - mean_absolute_error: 0.2084 - val_loss: 0.1330 - val_mean_absolute_error: 0.2363\n",
            "Epoch 231/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1321 - mean_absolute_error: 0.2498\n",
            "Epoch 231: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 231: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/231-0.10258\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.1305 - mean_absolute_error: 0.2488 - val_loss: 0.1026 - val_mean_absolute_error: 0.2233\n",
            "Epoch 232/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.1026 - mean_absolute_error: 0.2296\n",
            "Epoch 232: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 232: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/232-0.09252\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.1018 - mean_absolute_error: 0.2285 - val_loss: 0.0925 - val_mean_absolute_error: 0.2090\n",
            "Epoch 233/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0874 - mean_absolute_error: 0.2119\n",
            "Epoch 233: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 233: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/233-0.07911\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.0874 - mean_absolute_error: 0.2119 - val_loss: 0.0791 - val_mean_absolute_error: 0.1953\n",
            "Epoch 234/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0823 - mean_absolute_error: 0.2060\n",
            "Epoch 234: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 234: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/234-0.07757\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.0824 - mean_absolute_error: 0.2061 - val_loss: 0.0776 - val_mean_absolute_error: 0.1957\n",
            "Epoch 235/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0840 - mean_absolute_error: 0.2075\n",
            "Epoch 235: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 235: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/235-0.08124\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 0.0840 - mean_absolute_error: 0.2075 - val_loss: 0.0812 - val_mean_absolute_error: 0.1964\n",
            "Epoch 236/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0838 - mean_absolute_error: 0.2062\n",
            "Epoch 236: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 236: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/236-0.08584\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0835 - mean_absolute_error: 0.2058 - val_loss: 0.0858 - val_mean_absolute_error: 0.2026\n",
            "Epoch 237/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0828 - mean_absolute_error: 0.2057\n",
            "Epoch 237: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 237: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/237-0.07606\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0826 - mean_absolute_error: 0.2053 - val_loss: 0.0761 - val_mean_absolute_error: 0.1910\n",
            "Epoch 238/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0822 - mean_absolute_error: 0.2054\n",
            "Epoch 238: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 238: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/238-0.08395\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0822 - mean_absolute_error: 0.2054 - val_loss: 0.0840 - val_mean_absolute_error: 0.2092\n",
            "Epoch 239/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0838 - mean_absolute_error: 0.2074\n",
            "Epoch 239: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 239: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/239-0.08306\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0856 - mean_absolute_error: 0.2087 - val_loss: 0.0831 - val_mean_absolute_error: 0.2001\n",
            "Epoch 240/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0943 - mean_absolute_error: 0.2185\n",
            "Epoch 240: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 240: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/240-0.07841\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.0939 - mean_absolute_error: 0.2182 - val_loss: 0.0784 - val_mean_absolute_error: 0.1933\n",
            "Epoch 241/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0822 - mean_absolute_error: 0.2055\n",
            "Epoch 241: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 241: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/241-0.07606\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 0.0821 - mean_absolute_error: 0.2057 - val_loss: 0.0761 - val_mean_absolute_error: 0.1894\n",
            "Epoch 242/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0813 - mean_absolute_error: 0.2049\n",
            "Epoch 242: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 242: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/242-0.07699\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 0.0807 - mean_absolute_error: 0.2041 - val_loss: 0.0770 - val_mean_absolute_error: 0.1940\n",
            "Epoch 243/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0804 - mean_absolute_error: 0.2025\n",
            "Epoch 243: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 243: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/243-0.07582\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0800 - mean_absolute_error: 0.2020 - val_loss: 0.0758 - val_mean_absolute_error: 0.1925\n",
            "Epoch 244/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0831 - mean_absolute_error: 0.2066\n",
            "Epoch 244: val_loss did not improve from 0.07471\n",
            "\n",
            "Epoch 244: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/244-0.07758\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0824 - mean_absolute_error: 0.2056 - val_loss: 0.0776 - val_mean_absolute_error: 0.1932\n",
            "Epoch 245/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0811 - mean_absolute_error: 0.2046\n",
            "Epoch 245: val_loss improved from 0.07471 to 0.07231, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/245-0.07231_best\n",
            "\n",
            "Epoch 245: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/245-0.07231\n",
            "61/61 [==============================] - 3s 57ms/step - loss: 0.0801 - mean_absolute_error: 0.2031 - val_loss: 0.0723 - val_mean_absolute_error: 0.1844\n",
            "Epoch 246/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0777 - mean_absolute_error: 0.1989\n",
            "Epoch 246: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 246: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/246-0.07393\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0781 - mean_absolute_error: 0.1991 - val_loss: 0.0739 - val_mean_absolute_error: 0.1848\n",
            "Epoch 247/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0819 - mean_absolute_error: 0.2035\n",
            "Epoch 247: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 247: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/247-0.08095\n",
            "61/61 [==============================] - 3s 44ms/step - loss: 0.0817 - mean_absolute_error: 0.2033 - val_loss: 0.0810 - val_mean_absolute_error: 0.1988\n",
            "Epoch 248/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0820 - mean_absolute_error: 0.2054\n",
            "Epoch 248: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 248: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/248-0.07612\n",
            "61/61 [==============================] - 3s 48ms/step - loss: 0.0822 - mean_absolute_error: 0.2058 - val_loss: 0.0761 - val_mean_absolute_error: 0.1911\n",
            "Epoch 249/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0805 - mean_absolute_error: 0.2024\n",
            "Epoch 249: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 249: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/249-0.07740\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.0800 - mean_absolute_error: 0.2021 - val_loss: 0.0774 - val_mean_absolute_error: 0.1918\n",
            "Epoch 250/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0812 - mean_absolute_error: 0.2043\n",
            "Epoch 250: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 250: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/250-0.07669\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0808 - mean_absolute_error: 0.2039 - val_loss: 0.0767 - val_mean_absolute_error: 0.1911\n",
            "Epoch 251/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0824 - mean_absolute_error: 0.2061\n",
            "Epoch 251: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 251: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/251-0.07408\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0826 - mean_absolute_error: 0.2061 - val_loss: 0.0741 - val_mean_absolute_error: 0.1900\n",
            "Epoch 252/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0791 - mean_absolute_error: 0.2012\n",
            "Epoch 252: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 252: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/252-0.07688\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0803 - mean_absolute_error: 0.2026 - val_loss: 0.0769 - val_mean_absolute_error: 0.1949\n",
            "Epoch 253/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0833 - mean_absolute_error: 0.2073\n",
            "Epoch 253: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 253: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/253-0.07617\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.0831 - mean_absolute_error: 0.2071 - val_loss: 0.0762 - val_mean_absolute_error: 0.1911\n",
            "Epoch 254/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0794 - mean_absolute_error: 0.2014\n",
            "Epoch 254: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 254: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/254-0.07312\n",
            "61/61 [==============================] - 3s 56ms/step - loss: 0.0792 - mean_absolute_error: 0.2018 - val_loss: 0.0731 - val_mean_absolute_error: 0.1912\n",
            "Epoch 255/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0795 - mean_absolute_error: 0.2015\n",
            "Epoch 255: val_loss did not improve from 0.07231\n",
            "\n",
            "Epoch 255: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/255-0.07520\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.0800 - mean_absolute_error: 0.2023 - val_loss: 0.0752 - val_mean_absolute_error: 0.1894\n",
            "Epoch 256/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0792 - mean_absolute_error: 0.2021\n",
            "Epoch 256: val_loss improved from 0.07231 to 0.07177, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/256-0.07177_best\n",
            "\n",
            "Epoch 256: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/256-0.07177\n",
            "61/61 [==============================] - 4s 65ms/step - loss: 0.0791 - mean_absolute_error: 0.2019 - val_loss: 0.0718 - val_mean_absolute_error: 0.1874\n",
            "Epoch 257/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0798 - mean_absolute_error: 0.2025\n",
            "Epoch 257: val_loss did not improve from 0.07177\n",
            "\n",
            "Epoch 257: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/257-0.07831\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.0798 - mean_absolute_error: 0.2025 - val_loss: 0.0783 - val_mean_absolute_error: 0.1988\n",
            "Epoch 258/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0774 - mean_absolute_error: 0.1999\n",
            "Epoch 258: val_loss did not improve from 0.07177\n",
            "\n",
            "Epoch 258: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/258-0.07288\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0773 - mean_absolute_error: 0.1998 - val_loss: 0.0729 - val_mean_absolute_error: 0.1850\n",
            "Epoch 259/9999999\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0792 - mean_absolute_error: 0.2017\n",
            "Epoch 259: val_loss did not improve from 0.07177\n",
            "\n",
            "Epoch 259: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/259-0.07195\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.0784 - mean_absolute_error: 0.2009 - val_loss: 0.0719 - val_mean_absolute_error: 0.1816\n",
            "Epoch 260/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0815 - mean_absolute_error: 0.2034\n",
            "Epoch 260: val_loss did not improve from 0.07177\n",
            "\n",
            "Epoch 260: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/260-0.07380\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 0.0803 - mean_absolute_error: 0.2023 - val_loss: 0.0738 - val_mean_absolute_error: 0.1877\n",
            "Epoch 261/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0812 - mean_absolute_error: 0.2027\n",
            "Epoch 261: val_loss improved from 0.07177 to 0.06951, saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/261-0.06951_best\n",
            "\n",
            "Epoch 261: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/261-0.06951\n",
            "61/61 [==============================] - 4s 66ms/step - loss: 0.0805 - mean_absolute_error: 0.2022 - val_loss: 0.0695 - val_mean_absolute_error: 0.1834\n",
            "Epoch 262/9999999\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0769 - mean_absolute_error: 0.1990\n",
            "Epoch 262: val_loss did not improve from 0.06951\n",
            "\n",
            "Epoch 262: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/262-0.07534\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.0772 - mean_absolute_error: 0.1990 - val_loss: 0.0753 - val_mean_absolute_error: 0.1910\n",
            "Epoch 263/9999999\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0789 - mean_absolute_error: 0.1997\n",
            "Epoch 263: val_loss did not improve from 0.06951\n",
            "\n",
            "Epoch 263: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/263-0.07318\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.0785 - mean_absolute_error: 0.1994 - val_loss: 0.0732 - val_mean_absolute_error: 0.1873\n",
            "Epoch 264/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0820 - mean_absolute_error: 0.2045\n",
            "Epoch 264: val_loss did not improve from 0.06951\n",
            "\n",
            "Epoch 264: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/264-0.07924\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.0820 - mean_absolute_error: 0.2045 - val_loss: 0.0792 - val_mean_absolute_error: 0.1940\n",
            "Epoch 265/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0778 - mean_absolute_error: 0.2003\n",
            "Epoch 265: val_loss did not improve from 0.06951\n",
            "\n",
            "Epoch 265: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/265-0.07032\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0779 - mean_absolute_error: 0.2003 - val_loss: 0.0703 - val_mean_absolute_error: 0.1831\n",
            "Epoch 266/9999999\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0782 - mean_absolute_error: 0.1992\n",
            "Epoch 266: val_loss did not improve from 0.06951\n",
            "\n",
            "Epoch 266: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/266-0.08025\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 0.0781 - mean_absolute_error: 0.1991 - val_loss: 0.0803 - val_mean_absolute_error: 0.1978\n",
            "Epoch 267/9999999\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0772 - mean_absolute_error: 0.1996\n",
            "Epoch 267: val_loss did not improve from 0.06951\n",
            "\n",
            "Epoch 267: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/267-0.07591\n",
            "61/61 [==============================] - 3s 43ms/step - loss: 0.0772 - mean_absolute_error: 0.1996 - val_loss: 0.0759 - val_mean_absolute_error: 0.1886\n",
            "Epoch 268/9999999\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0779 - mean_absolute_error: 0.1994\n",
            "Epoch 268: val_loss did not improve from 0.06951\n",
            "\n",
            "Epoch 268: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/268-0.07348\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0777 - mean_absolute_error: 0.1991 - val_loss: 0.0735 - val_mean_absolute_error: 0.1852\n",
            "Epoch 269/9999999\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0763 - mean_absolute_error: 0.1973\n",
            "Epoch 269: val_loss did not improve from 0.06951\n",
            "\n",
            "Epoch 269: saving model to /content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/269-0.07108\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-218-f23cb0cec3ab>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m               loss=[keras.losses.MSE], metrics=[keras.losses.MAE])\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyMdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9999999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_data_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_save_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1848\u001b[0m                     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m                 \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1578\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m                         self.model.save(\n\u001b[0m\u001b[1;32m   1581\u001b[0m                             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0malias\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m         \"\"\"\n\u001b[0;32m-> 3079\u001b[0;31m         saving_api.save_model(\n\u001b[0m\u001b[1;32m   3080\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# Legacy case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         return legacy_sm_saving_lib.save_model(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0msave_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tf_saved_model_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             ):\n\u001b[0;32m--> 168\u001b[0;31m                 saved_model_save.save(\n\u001b[0m\u001b[1;32m    169\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated_internal_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0m\u001b[1;32m     99\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1366\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1367\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1368\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1578\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m   \u001b[0;31m# Use _SaveableView to provide a frozen listing of properties and functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m   \u001b[0msaveable_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SaveableView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_graph_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m   \u001b[0mobject_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m   asset_info, exported_graph = _fill_meta_graph_def(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, augmented_graph_view, options)\u001b[0m\n\u001b[1;32m    282\u001b[0m     (self._trackable_objects, self.node_paths, self.node_ids,\n\u001b[1;32m    283\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m          checkpoint_util.objects_ids_and_slot_variables_and_paths(\n\u001b[0m\u001b[1;32m    285\u001b[0m              self.augmented_graph_view))\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/util.py\u001b[0m in \u001b[0;36mobjects_ids_and_slot_variables_and_paths\u001b[0;34m(graph_view)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 object -> node id, slot variables, object_names)\n\u001b[1;32m    156\u001b[0m   \"\"\"\n\u001b[0;32m--> 157\u001b[0;31m   \u001b[0mtrackable_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreadth_first_traversal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0mobject_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/graph_view.py\u001b[0m in \u001b[0;36mbreadth_first_traversal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbreadth_first_traversal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_breadth_first_traversal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_breadth_first_traversal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_breadth_first_traversal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     trackable_objects, _ = (\n\u001b[0;32m--> 155\u001b[0;31m         super(_AugmentedGraphView, self)._breadth_first_traversal())\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0masset_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/graph_view.py\u001b[0m in \u001b[0;36m_breadth_first_traversal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_breadth_first_traversal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m\"\"\"Find shortest paths to all dependencies of self.root.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObjectGraphView\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_descendants_with_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mserialize_object_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveables_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/trackable_view.py\u001b[0m in \u001b[0;36m_descendants_with_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0mcurrent_trackable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_visit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0mbfs_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_trackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_trackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m           node_paths[dependency] = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/graph_view.py\u001b[0m in \u001b[0;36mchildren\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \"\"\"\n\u001b[1;32m     96\u001b[0m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       for name, child in super(_AugmentedGraphView, self).list_children(\n\u001b[0m\u001b[1;32m    190\u001b[0m           \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m           \u001b[0msave_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/graph_view.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     for name, ref in super(ObjectGraphView,\n\u001b[0m\u001b[1;32m     76\u001b[0m                            self).children(obj, save_type, **kwargs).items():\n\u001b[1;32m     77\u001b[0m       \u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/trackable_view.py\u001b[0m in \u001b[0;36mchildren\u001b[0;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m       \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/autotrackable.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenericFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_all_concrete_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Additional dependencies may have been generated during function tracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_list_all_concrete_functions_for_serialization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0mconcrete_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_signatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m       \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m       concrete = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m   1209\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             ):\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return control_flow_util.smart_cond(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     return tf.__internal__.smart_cond.smart_cond(\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     return cond.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_in_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             )\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         return control_flow_util.smart_cond(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/saved_model/save_impl.py\u001b[0m in \u001b[0;36mcall_and_return_conditional_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;34m\"\"\"Returns layer (call_output, conditional losses) tuple.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mcall_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_v1_layer_or_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             conditional_losses = layer.get_losses_for(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/attention/multi_head_attention.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, value, key, attention_mask, return_attention_scores, training, use_causal_mask)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         attention_output, attention_scores = self._compute_attention(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/attention/multi_head_attention.py\u001b[0m in \u001b[0;36m_compute_attention\u001b[0;34m(self, query, key, value, attention_mask, training)\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n\u001b[1;32m    541\u001b[0m         \u001b[0;31m# `context_layer` = [B, T, N, H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         attention_output = tf.einsum(\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_scores_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m       \u001b[0;34m-\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mare\u001b[0m \u001b[0minconsistent\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \"\"\"\n\u001b[0;32m--> 763\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_einsum_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36m_einsum_v2\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mellipsis_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0mresolved_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolved_equation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mellipsis_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_linalg_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolved_equation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;31m# Send fully specified shapes to opt_einsum, since it cannot handle unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(inputs, equation, name)\u001b[0m\n\u001b[1;32m   1131\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m   \u001b[0mequation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"equation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   1134\u001b[0m         \"Einsum\", inputs=inputs, equation=equation, name=name)\n\u001b[1;32m   1135\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m     must_colocate_inputs = [val for arg, val in zip(op_def.input_arg, inputs)\n\u001b[1;32m    792\u001b[0m                             if arg.is_ref]\n\u001b[0;32m--> 793\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_MaybeColocateWith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmust_colocate_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myMdl = tf.keras.models.load_model('/content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/261-0.06951_best')"
      ],
      "metadata": {
        "id": "Sl4Ae9wmyGA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = pd.read_csv('/content/drive/MyDrive/ai_project_2/transformer_model_save/20231214_1999-1modelsave/training.csv')"
      ],
      "metadata": {
        "id": "nEuJsw8xKvYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss curve\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history['loss'][:], 'y', label='train loss')\n",
        "plt.plot(history['val_loss'][:], 'r', label='val loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "qjRAlOWtK1O6",
        "outputId": "e439d9f5-cb13-468f-81bb-cafd53ddde96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e78c2576f20>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = myMdl.predict(x_data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggq3-mOkydM7",
        "outputId": "6048f789-9d16-4d5c-b035-28c5d469c4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터 예측한거임 y값이 들쭉날쭉한 이유는\n",
        "# test는 섞여있기 때문에 x축의 값들은 완전 날짜들이 섞여있음\n",
        "# 예를들어서 6월1일, 8월 5일, 7월 3일, 7월 20일 이렇게 랜덤으로 있기 떄문에 데이터가 들쭉날쭉임\n",
        "# 교수님 가이드 코드처럼 연속된 날짜를 쭉 뽑고싶었지만 그렇게까지 못함\n",
        "plt.figure(figsize=(5,3))\n",
        "fuck1=20\n",
        "fuck2=fuck1+50\n",
        "plt.plot(pred[fuck1:fuck2,-1], 'b', label='Prediction',linewidth=0.5)\n",
        "plt.plot(y_data_test[fuck1:fuck2,-1], 'r', label='Ground truth',linewidth=0.5)\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "jMqNH2sbylTk",
        "outputId": "4715de32-350c-4464-de4a-f6537a77d647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e78c2599840>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#최종 test loss는 mse는 0.0695, mae는 0.1863이 나옴\n",
        "myMdl.evaluate(x_data_test,y_data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLX0iZD_hF_D",
        "outputId": "c4a1e225-3290-4b96-a129-1b2582e2d05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0695 - mean_absolute_error: 0.1863\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06954444199800491, 0.18633542954921722]"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    }
  ]
}